{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4890b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T20:21:22.769620Z",
     "start_time": "2023-01-23T20:21:20.823411Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import argparse\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as tF\n",
    "import pytorch_lightning as pl\n",
    "import tokenizers\n",
    "import datasets\n",
    "\n",
    "\n",
    "DEBUG_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e7dfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T20:21:22.773608Z",
     "start_time": "2023-01-23T20:21:22.770967Z"
    }
   },
   "outputs": [],
   "source": [
    "class HFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hfdf):\n",
    "        self.hfdf = hfdf\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.hfdf[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cae9a71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T20:23:07.367047Z",
     "start_time": "2023-01-23T20:23:07.348680Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitSegmenterBaseline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        tokenizer_uri: str,\n",
    "        dataset_uri: str,\n",
    "        batch_size: int,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        num_classes: int = 4,\n",
    "        pad_token: str = \"[PAD]\",\n",
    "    ):\n",
    "        super(LitSegmenterBaseline, self).__init__()\n",
    "\n",
    "        self.tokenizer = tokenizers.Tokenizer.from_file(tokenizer_uri)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.pad_id = self.tokenizer.get_vocab().get(pad_token, 0)\n",
    "\n",
    "        def fn_pad_sequences(batch):\n",
    "            X = [torch.tensor(x_i[\"input_ids\"], dtype=torch.int) for x_i in batch]\n",
    "            y = [torch.tensor(y_i[\"labels\"]) for y_i in batch]\n",
    "\n",
    "            X = nn.utils.rnn.pad_sequence(X, padding_value=self.pad_id, batch_first=True)\n",
    "            y = nn.utils.rnn.pad_sequence(y, padding_value=-100, batch_first=True)\n",
    "\n",
    "            return X, y\n",
    "\n",
    "        self.fn_pad_sequences = fn_pad_sequences\n",
    "\n",
    "        self.hfdf = datasets.load_from_disk(dataset_uri)\n",
    "\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=self.tokenizer.get_vocab_size(),\n",
    "            embedding_dim=768,\n",
    "            padding_idx=self.pad_id,\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.0 if num_layers == 1 else 0.1,\n",
    "            bidirectional=bidirectional,\n",
    "            proj_size=0,\n",
    "        )\n",
    "\n",
    "        self.lin_out = nn.Linear(\n",
    "            (1 + int(bidirectional)) * hidden_size,\n",
    "            num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "\n",
    "        if isinstance(out, str):\n",
    "            out = self.tokenizer(out, return_tensors=\"pt\")\n",
    "            out = out[\"input_ids\"]\n",
    "\n",
    "        out = self.embeddings(out)\n",
    "        out, *_ = self.lstm(out)\n",
    "        out = self.lin_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_pred_metrics(y_preds, y, phase: str) -> dict[str, float]:\n",
    "        y_preds = y_preds.view(-1, y_preds.shape[-1])\n",
    "        y = y.view(-1).squeeze()\n",
    "\n",
    "        loss = F.cross_entropy(input=y_preds, target=y, ignore_index=-100)\n",
    "\n",
    "        non_pad_inds = [i for i, cls_i in enumerate(y) if cls_i != -100]\n",
    "\n",
    "        per_cls_recall = tF.recall(\n",
    "            preds=y_preds[non_pad_inds, ...],\n",
    "            target=y[non_pad_inds],\n",
    "            num_classes=4,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "        per_cls_precision = tF.precision(\n",
    "            preds=y_preds[non_pad_inds, ...],\n",
    "            target=y[non_pad_inds],\n",
    "            num_classes=4,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "        macro_precision = float(per_cls_precision.mean().item())\n",
    "        macro_recall = float(per_cls_recall.mean().item())\n",
    "        macro_f1_score = (\n",
    "            2.0 * macro_precision * macro_recall / (1e-8 + macro_precision + macro_recall)\n",
    "        )\n",
    "\n",
    "        out = {\n",
    "            f\"{(phase + '_') if phase != 'train' else ''}loss\": loss,\n",
    "            **{f\"{phase}_cls_{i}_precision\": float(val) for i, val in enumerate(per_cls_precision)},\n",
    "            **{f\"{phase}_cls_{i}_recall\": float(val) for i, val in enumerate(per_cls_recall)},\n",
    "            f\"{phase}_macro_precision\": macro_precision,\n",
    "            f\"{phase}_macro_recall\": macro_recall,\n",
    "            f\"{phase}_macro_f1_score\": macro_f1_score,\n",
    "        }\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _agg_stats(step_outputs):\n",
    "        out = {}\n",
    "        agg_items = collections.defaultdict(list)\n",
    "\n",
    "        for items in step_outputs:\n",
    "            for key, val in items.items():\n",
    "                if not isinstance(val, torch.Tensor):\n",
    "                    val = torch.tensor(val)\n",
    "\n",
    "                agg_items[key].append(val)\n",
    "\n",
    "        for key, vals in agg_items.items():\n",
    "            avg_vals = float(torch.stack(vals).mean().item())\n",
    "            out[f\"avg_{key}\"] = avg_vals\n",
    "\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        X, y = batch\n",
    "        y_preds = self.forward(X)\n",
    "\n",
    "        out = self._compute_pred_metrics(y_preds, y, phase=\"train\")\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        return out\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        out = self._agg_stats(training_step_outputs)\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx: int):\n",
    "#         X, y = batch\n",
    "#         y_preds = self.forward(X)\n",
    "\n",
    "#         out = self._compute_pred_metrics(y_preds, y, phase=\"val\")\n",
    "\n",
    "#         self.log_dict(\n",
    "#             out,\n",
    "#             on_step=False,\n",
    "#             on_epoch=True,\n",
    "#             logger=True,\n",
    "#         )\n",
    "\n",
    "#         return out\n",
    "\n",
    "#     def validation_epoch_end(self, validation_step_outputs):\n",
    "#         out = self._agg_stats(validation_step_outputs)\n",
    "\n",
    "#         self.log_dict(\n",
    "#             out,\n",
    "#             on_step=False,\n",
    "#             on_epoch=True,\n",
    "#             logger=True,\n",
    "#         )\n",
    "\n",
    "    def test_step(self, batch, batch_idx: int):\n",
    "        X, y = batch\n",
    "        y_preds = self.forward(X)\n",
    "\n",
    "        out = self._compute_pred_metrics(y_preds, y, phase=\"test\")\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        return out\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        out = self._agg_stats(test_step_outputs)\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        df_train = HFDataset(self.hfdf[\"train\"])\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset=df_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            collate_fn=self.fn_pad_sequences,\n",
    "        )\n",
    "\n",
    "        return train_dataloader\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         df_eval = HFDataset(self.hfdf[\"eval\"])\n",
    "\n",
    "#         eval_dataloader = torch.utils.data.DataLoader(\n",
    "#             dataset=df_eval,\n",
    "#             batch_size=self.batch_size,\n",
    "#             shuffle=False,\n",
    "#             num_workers=8,\n",
    "#             collate_fn=self.fn_pad_sequences,\n",
    "#         )\n",
    "\n",
    "#         return eval_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        df_test = HFDataset(self.hfdf[\"test\"])\n",
    "\n",
    "        test_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset=df_test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            collate_fn=self.fn_pad_sequences,\n",
    "        )\n",
    "\n",
    "        return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de7693b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T07:22:25.843623Z",
     "start_time": "2023-01-23T20:23:14.463624Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | embeddings | Embedding | 4.6 M \n",
      "1 | lstm       | LSTM      | 5.3 M \n",
      "2 | lin_out    | Linear    | 4.1 K \n",
      "-----------------------------------------\n",
      "9.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 M     Total params\n",
      "39.453    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fb9cc6e11e4b58aa81c5b7084a16bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nvme/segmentador/venvs/env3.9.10/lib/python3.9/site-packages/pytorch_lightning/callbacks/progress/base.py:207: UserWarning: The progress bar already tracks a metric with the name(s) 'loss' and `self.log('loss', ..., prog_bar=True)` will overwrite this value.  If this is undesired, change the name or override `get_metrics()` in the progress bar callback.\n",
      "  rank_zero_warn(\n",
      "/media/nvme/segmentador/venvs/env3.9.10/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1398: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /media/nvme/segmentador/notebooks/lightning_logs/version_3/checkpoints/epoch=2-step=3737.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /media/nvme/segmentador/notebooks/lightning_logs/version_3/checkpoints/epoch=2-step=3737.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfa52ba674e4753b7cff0e894c092c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | embeddings | Embedding | 4.6 M \n",
      "1 | lstm       | LSTM      | 2.1 M \n",
      "2 | lin_out    | Linear    | 2.1 K \n",
      "-----------------------------------------\n",
      "6.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 M     Total params\n",
      "26.845    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_cls_0_precision': 0.9982461929321289,\n",
      " 'avg_test_cls_0_recall': 0.9994046688079834,\n",
      " 'avg_test_cls_1_precision': 0.986571729183197,\n",
      " 'avg_test_cls_1_recall': 0.9582132697105408,\n",
      " 'avg_test_cls_2_precision': 0.9132260084152222,\n",
      " 'avg_test_cls_2_recall': 0.8215959072113037,\n",
      " 'avg_test_cls_3_precision': 0.7250827550888062,\n",
      " 'avg_test_cls_3_recall': 0.535641610622406,\n",
      " 'avg_test_loss': 0.010228903032839298,\n",
      " 'avg_test_macro_f1_score': 0.8643761277198792,\n",
      " 'avg_test_macro_precision': 0.905781626701355,\n",
      " 'avg_test_macro_recall': 0.8287138938903809,\n",
      " 'test_cls_0_precision': 0.9982464909553528,\n",
      " 'test_cls_0_recall': 0.9994055032730103,\n",
      " 'test_cls_1_precision': 0.9865930676460266,\n",
      " 'test_cls_1_recall': 0.9582584500312805,\n",
      " 'test_cls_2_precision': 0.9132982492446899,\n",
      " 'test_cls_2_recall': 0.8214690089225769,\n",
      " 'test_cls_3_precision': 0.7250284552574158,\n",
      " 'test_cls_3_recall': 0.5351755023002625,\n",
      " 'test_loss': 0.010232209227979183,\n",
      " 'test_macro_f1_score': 0.8643065094947815,\n",
      " 'test_macro_precision': 0.9057917594909668,\n",
      " 'test_macro_recall': 0.8285772800445557}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb89c251ca846b28daba7a92bfa46e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /media/nvme/segmentador/notebooks/lightning_logs/version_4/checkpoints/epoch=2-step=4982.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /media/nvme/segmentador/notebooks/lightning_logs/version_4/checkpoints/epoch=2-step=4982.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52cf5f810b047b5b9811b1369b3b99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | embeddings | Embedding | 4.6 M \n",
      "1 | lstm       | LSTM      | 919 K \n",
      "2 | lin_out    | Linear    | 1.0 K \n",
      "-----------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.114    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_cls_0_precision': 0.9983312487602234,\n",
      " 'avg_test_cls_0_recall': 0.9993693232536316,\n",
      " 'avg_test_cls_1_precision': 0.9855096340179443,\n",
      " 'avg_test_cls_1_recall': 0.9620329737663269,\n",
      " 'avg_test_cls_2_precision': 0.9168782830238342,\n",
      " 'avg_test_cls_2_recall': 0.8202478289604187,\n",
      " 'avg_test_cls_3_precision': 0.7135547995567322,\n",
      " 'avg_test_cls_3_recall': 0.5649248957633972,\n",
      " 'avg_test_loss': 0.01007597055286169,\n",
      " 'avg_test_macro_f1_score': 0.8680000305175781,\n",
      " 'avg_test_macro_precision': 0.9035684466362,\n",
      " 'avg_test_macro_recall': 0.8366436958312988,\n",
      " 'test_cls_0_precision': 0.998330295085907,\n",
      " 'test_cls_0_recall': 0.999370276927948,\n",
      " 'test_cls_1_precision': 0.9855092763900757,\n",
      " 'test_cls_1_recall': 0.9620238542556763,\n",
      " 'test_cls_2_precision': 0.9171323776245117,\n",
      " 'test_cls_2_recall': 0.8202000856399536,\n",
      " 'test_cls_3_precision': 0.7137227058410645,\n",
      " 'test_cls_3_recall': 0.5646311640739441,\n",
      " 'test_loss': 0.010080181993544102,\n",
      " 'test_macro_f1_score': 0.8680046200752258,\n",
      " 'test_macro_precision': 0.9036736488342285,\n",
      " 'test_macro_recall': 0.8365563750267029}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb35af786ed4190ae7ae1489b8667af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /media/nvme/segmentador/notebooks/lightning_logs/version_5/checkpoints/epoch=2-step=3737.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /media/nvme/segmentador/notebooks/lightning_logs/version_5/checkpoints/epoch=2-step=3737.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b5cfed29004897a7c28c1ee055b6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_cls_0_precision': 0.99830561876297,\n",
      " 'avg_test_cls_0_recall': 0.999434769153595,\n",
      " 'avg_test_cls_1_precision': 0.9863963723182678,\n",
      " 'avg_test_cls_1_recall': 0.960133969783783,\n",
      " 'avg_test_cls_2_precision': 0.9214738011360168,\n",
      " 'avg_test_cls_2_recall': 0.8192890286445618,\n",
      " 'avg_test_cls_3_precision': 0.7188460826873779,\n",
      " 'avg_test_cls_3_recall': 0.5316470861434937,\n",
      " 'avg_test_loss': 0.008982779458165169,\n",
      " 'avg_test_macro_f1_score': 0.8646918535232544,\n",
      " 'avg_test_macro_precision': 0.9062554240226746,\n",
      " 'avg_test_macro_recall': 0.8276262879371643,\n",
      " 'test_cls_0_precision': 0.9983052611351013,\n",
      " 'test_cls_0_recall': 0.9994353652000427,\n",
      " 'test_cls_1_precision': 0.9863983988761902,\n",
      " 'test_cls_1_recall': 0.9601314067840576,\n",
      " 'test_cls_2_precision': 0.9216869473457336,\n",
      " 'test_cls_2_recall': 0.8193143010139465,\n",
      " 'test_cls_3_precision': 0.7187364101409912,\n",
      " 'test_cls_3_recall': 0.5313534736633301,\n",
      " 'test_loss': 0.008986305445432663,\n",
      " 'test_macro_f1_score': 0.8646671175956726,\n",
      " 'test_macro_precision': 0.9062817692756653,\n",
      " 'test_macro_recall': 0.8275586366653442}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    configs = [\n",
    "#         (512, 32),\n",
    "#         (256, 48),\n",
    "#         (128, 64),\n",
    "        (64, 128),\n",
    "    ]\n",
    "\n",
    "    for hidden_size, batch_size in configs:\n",
    "        accumulate_grad_batches = 128 // batch_size\n",
    "\n",
    "        model = LitSegmenterBaseline(\n",
    "            hidden_size=hidden_size,\n",
    "            batch_size=batch_size,\n",
    "            tokenizer_uri=\"../tokenizers/6000_subwords/tokenizer.json\",\n",
    "            dataset_uri=\"./final_curated_dataset_for_training\",\n",
    "        )\n",
    "\n",
    "        trainer = pl.Trainer.from_argparse_args(\n",
    "            args,\n",
    "            overfit_batches=0.001 if DEBUG_RUN else 0.0,\n",
    "            accumulate_grad_batches=accumulate_grad_batches,\n",
    "        )\n",
    "\n",
    "        trainer.fit(model)\n",
    "\n",
    "        if not DEBUG_RUN:\n",
    "            trainer.test()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    args = parser.parse_args(\n",
    "        \"\"\"\n",
    "        --gpu 1\n",
    "        --max_epochs 3\n",
    "        --log_every_n_steps 1000\n",
    "        --precision 32\n",
    "    \"\"\".split()\n",
    "    )\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89522187",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## 512 hidden units\n",
    "{'avg_test_cls_0_precision': 0.9982461929321289,\n",
    " 'avg_test_cls_0_recall': 0.9994046688079834,\n",
    " 'avg_test_cls_1_precision': 0.986571729183197,\n",
    " 'avg_test_cls_1_recall': 0.9582132697105408,\n",
    " 'avg_test_cls_2_precision': 0.9132260084152222,\n",
    " 'avg_test_cls_2_recall': 0.8215959072113037,\n",
    " 'avg_test_cls_3_precision': 0.7250827550888062,\n",
    " 'avg_test_cls_3_recall': 0.535641610622406,\n",
    " 'avg_test_loss': 0.010228903032839298,\n",
    " 'avg_test_macro_f1_score': 0.8643761277198792,\n",
    " 'avg_test_macro_precision': 0.905781626701355,\n",
    " 'avg_test_macro_recall': 0.8287138938903809,\n",
    " 'test_cls_0_precision': 0.9982464909553528,\n",
    " 'test_cls_0_recall': 0.9994055032730103,\n",
    " 'test_cls_1_precision': 0.9865930676460266,\n",
    " 'test_cls_1_recall': 0.9582584500312805,\n",
    " 'test_cls_2_precision': 0.9132982492446899,\n",
    " 'test_cls_2_recall': 0.8214690089225769,\n",
    " 'test_cls_3_precision': 0.7250284552574158,\n",
    " 'test_cls_3_recall': 0.5351755023002625,\n",
    " 'test_loss': 0.010232209227979183,\n",
    " 'test_macro_f1_score': 0.8643065094947815,\n",
    " 'test_macro_precision': 0.9057917594909668,\n",
    " 'test_macro_recall': 0.8285772800445557}\n",
    "\n",
    "## 256 hidden units\n",
    "{'avg_test_cls_0_precision': 0.9983312487602234,\n",
    " 'avg_test_cls_0_recall': 0.9993693232536316,\n",
    " 'avg_test_cls_1_precision': 0.9855096340179443,\n",
    " 'avg_test_cls_1_recall': 0.9620329737663269,\n",
    " 'avg_test_cls_2_precision': 0.9168782830238342,\n",
    " 'avg_test_cls_2_recall': 0.8202478289604187,\n",
    " 'avg_test_cls_3_precision': 0.7135547995567322,\n",
    " 'avg_test_cls_3_recall': 0.5649248957633972,\n",
    " 'avg_test_loss': 0.01007597055286169,\n",
    " 'avg_test_macro_f1_score': 0.8680000305175781,\n",
    " 'avg_test_macro_precision': 0.9035684466362,\n",
    " 'avg_test_macro_recall': 0.8366436958312988,\n",
    " 'test_cls_0_precision': 0.998330295085907,\n",
    " 'test_cls_0_recall': 0.999370276927948,\n",
    " 'test_cls_1_precision': 0.9855092763900757,\n",
    " 'test_cls_1_recall': 0.9620238542556763,\n",
    " 'test_cls_2_precision': 0.9171323776245117,\n",
    " 'test_cls_2_recall': 0.8202000856399536,\n",
    " 'test_cls_3_precision': 0.7137227058410645,\n",
    " 'test_cls_3_recall': 0.5646311640739441,\n",
    " 'test_loss': 0.010080181993544102,\n",
    " 'test_macro_f1_score': 0.8680046200752258,\n",
    " 'test_macro_precision': 0.9036736488342285,\n",
    " 'test_macro_recall': 0.8365563750267029}\n",
    "\n",
    "\n",
    "## 128 hidden units\n",
    "{'avg_test_cls_0_precision': 0.99830561876297,\n",
    " 'avg_test_cls_0_recall': 0.999434769153595,\n",
    " 'avg_test_cls_1_precision': 0.9863963723182678,\n",
    " 'avg_test_cls_1_recall': 0.960133969783783,\n",
    " 'avg_test_cls_2_precision': 0.9214738011360168,\n",
    " 'avg_test_cls_2_recall': 0.8192890286445618,\n",
    " 'avg_test_cls_3_precision': 0.7188460826873779,\n",
    " 'avg_test_cls_3_recall': 0.5316470861434937,\n",
    " 'avg_test_loss': 0.008982779458165169,\n",
    " 'avg_test_macro_f1_score': 0.8646918535232544,\n",
    " 'avg_test_macro_precision': 0.9062554240226746,\n",
    " 'avg_test_macro_recall': 0.8276262879371643,\n",
    " 'test_cls_0_precision': 0.9983052611351013,\n",
    " 'test_cls_0_recall': 0.9994353652000427,\n",
    " 'test_cls_1_precision': 0.9863983988761902,\n",
    " 'test_cls_1_recall': 0.9601314067840576,\n",
    " 'test_cls_2_precision': 0.9216869473457336,\n",
    " 'test_cls_2_recall': 0.8193143010139465,\n",
    " 'test_cls_3_precision': 0.7187364101409912,\n",
    " 'test_cls_3_recall': 0.5313534736633301,\n",
    " 'test_loss': 0.008986305445432663,\n",
    " 'test_macro_f1_score': 0.8646671175956726,\n",
    " 'test_macro_precision': 0.9062817692756653,\n",
    " 'test_macro_recall': 0.8275586366653442}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
