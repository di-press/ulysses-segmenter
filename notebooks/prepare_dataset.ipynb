{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T00:49:02.713396Z",
     "start_time": "2022-02-24T00:49:01.434728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "No test cases found at './test_cases/60001_90000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "random.seed(72)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "TESTS_DIR = \"test_cases\"\n",
    "DATASET_ROW_START = 60001\n",
    "DATASET_ROW_END = 90000\n",
    "TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T00:49:09.105574Z",
     "start_time": "2022-02-24T00:49:04.791594Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T01:30:25.967350Z",
     "start_time": "2022-02-24T01:30:25.933166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ❌s__ 3_NOISE 1  ❌e__ 3_NOISE  ❌s__ 5_SPECIAL * 9 2 7 C 9 8 B E 0 0 * 9 2 7 C 9 8 B E 0 0   ❌e__ 5_SPECIAL ✓ 0_SPECIAL  ✓ 1_SPECIAL  ✓ 2_SPECIAL REQUERIMENTO DE INFORMAÇÕES NO , DE 2013 ( Da Sra. Luiza Erundina ) ✓ 2_SPECIAL ✓ 1_SPECIAL ✓ 0_SPECIAL Requer informações acerca dos procedimentos de renovação de concessões outorgadas à Globo Comunicação e Participações S.A. para explorar serviço de radiodifusão de sons e imagens nas cidades de São Paulo , Rio de Janeiro , Recife , Brasília e Belo Horizonte , especialmente em relação à situação fiscal da empresa . ✓ 0_SPECIAL ✓ 1_SPECIAL ✓ 2_SPECIAL    Senhor Presidente : Requeiro a V . Exa. , com base no art . 50 da Constituição Federal , e nos arts . 115 e 116 do Regimento Interno que , ouvida a Mesa , sejam solicitadas informações ao Sr. Ministro das Comunicações , no sentido de esclarecer esta Casa quanto aos procedimentos de renovação de concessões outorgadas à Globo Comunicação e Participações S.A. para explorar serviço de radiodifusão de sons e imagens nas cidades de São Paulo , Rio de Janeiro , Recife , Brasília e Belo Horizonte , especialmente em relação à situação fiscal da empresa . - Como foi possível a renovação de concessões outorgadas à Globo Comunicação e Participação S.A. para a exploração do serviço de radiodifusão de sons e imagens nas cidades de São Paulo , Rio de Janeiro , Recife , Brasília e Belo Horizonte , se a empresa alegadamente não cumpria a exigência legal de regularidade perante o fisco federal ? ✓ 6_SPECIAL  - Ao longo do processo de outorga , foi apresentada pela empresa certidão negativa de débitos relativos aos tributos federais e à dívida ativa da União , em atendimento ao que é preconizado pela legislação em vigor ? Em caso positivo , como pode a Receita Federal ter emitido tal documento se a GLOBOPAR , à época , era provável devedora da vultosa 2  ❌s__ 5_SPECIAL * 9 2 7 C 9 8 B E 0 0 * 9 2 7 C 9 8 B E 0 0  ❌e__ 5_SPECIAL quantia de R $ 615 milhões referente a Imposto Sobre a Renda da Pessoa Jurídica ( IRPJ ) não recolhido ? ✓ 6_SPECIAL  - Quais procedimentos estão sendo adotados pelo Ministério das Comunicações no acompanhamento da situação fiscal da GLOBOPAR ? Existe a possibilidade de cancelamento das outorgas de radiodifusão destinadas à empresa frente ao claro descumprimento , pela entidade , da legislação relativa à renovação de outorgas ?\n"
     ]
    }
   ],
   "source": [
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(r\"\\*([\\sA-Z0-9]+)\\*\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(.{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = sorted(set(pseudo_patterns))\n",
    "        \n",
    "        for pseudo_pattern in pseudo_patterns:\n",
    "            pattern = list(cls.RE_BLANK_SPACES.sub(\"\", pseudo_pattern))\n",
    "            pattern.append(\"\")\n",
    "            pattern.insert(0, \"\")\n",
    "            pattern = r\"\\s*\".join(pattern)\n",
    "            \n",
    "            text = regex.sub(r\"(\\*\" + pattern + r\"\\*\" + pattern + \")\", subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        return text\n",
    "\n",
    "\n",
    "VALID_ROMAN_NUM = r\"M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3})\"\n",
    "NRO = r\"[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[o0º°]\"\n",
    "QUOTES = r\"”“\\\"'\"\n",
    "COMMISSIONS = (r\"\"\"\n",
    "    COMISS[AÃ]O\\s*(?:D[EOA]S?)\\s*\n",
    "    (?:\n",
    "    AGRICULTURA[,\\s]*PECU[AÁ]RIA[,\\s]*ABASTECIMENTO[E\\s]*(?:DES\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA[,\\s]*COMUNICA[CÇ][AÃ]O[E\\s]*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*DE\\s*CIDADANIA|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*DO\\s*CONSUMIDOR|\n",
    "    (?:DES\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO[,\\s]*IND[UÚ]STRIA[,\\s]*COM[EÉ]RCIO[E\\s]*SERVI[CÇ]OS|\n",
    "    (?:DES\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS[E\\s]*MINORIAS|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS[E\\s]*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA[E\\s]*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL[,\\s]*(?:DES\\.|DESENVOLVIMENTO)\\s*REGIONAL[E\\s]*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    MEIO\\s*AMBIENTE[E\\s]*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS[E\\s]*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES[E\\s]*DE\\s*DEFESA\\s*NACIONAL|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL[E\\s]*FAMÍLIA|\n",
    "    TRABALHO[,\\s]*ADMINISTRA[CÇ][AÃ]O[E\\s]*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:[-–º°0-9A-Z]+|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+)(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\so0º°]*:\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!Art(?:igo)?s?\\s?\\.?\\s?)\\(?\\s+[0-9]{1,2}[\\s0oº°]*(?:[-–\\)]|\\.(?![0-9]))\",\n",
    ")\n",
    "\n",
    "MONTHS = \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    "))\n",
    "\n",
    "DATE = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[0-9]{,2}\\s*(?:de|em)\\s*(?:\" + MONTHS + r\")\\s*(?:de|em)\\s*[0-9]{4}\"\n",
    ")\n",
    "\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    r\".{,200}$|\" +\n",
    "    DATE + \n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"Sala\\s*d[ea]s?\\s*(?:Sess[oõ]es|comiss[aã]o|Reuni[oõ]es)\" + EOF_OR_DATE,\n",
    "    r\"Senado\\s*Federal\\s*,\" + EOF_OR_DATE,\n",
    "    r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\" + EOF_OR_DATE,\n",
    "    r\"•\",\n",
    ")\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "    regex.compile(\n",
    "        r\"((PL|PDL|PEC)\\s*n[\\.o\\sº]*[\\d\\s]+/[\\s\\d]+)?+\\s*\"\n",
    "        r\"A\\s*p\\s*r\\s*e\\s*s\\s*e\\s*n\\s*t\\s*a\\s*[cç]\\s*[aã]\\s*o\\s*:\"\n",
    "        r\"(\\s*\\d\\s*){2}/(\\s*\\d\\s*){2}/(\\s*\\d\\s*){6}:(\\s*\\d){2}\",\n",
    "        regex.IGNORECASE | regex.MULTILINE,\n",
    "    ),\n",
    "    regex.compile(f\"(?<!{NRO}[\\s0-9]*)\" + r\"([0-9]{9,})\"),\n",
    "    regex.compile(r\"(_{9,})\"),\n",
    "    regex.compile(r\"(^[\\s0-9]+|[\\s0-9]+$)\"),\n",
    "    *[\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, r\"cap[ií]tulo\", r\"t[íi]tulo\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC)\\s*\\)|\" +\n",
    "    f\"[{QUOTES}])\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    r\"(?:\\s*\" + MARKER_NOISE_START + r\".{,300}?\" + MARKER_NOISE_END + r\"\\s*(?:[0-9]+_[A-Z]+)?\\s*)\"\n",
    ")\n",
    "\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in (*BASE_LEGAL_ITEMS, *EXTRA_LEGAL_ITEMS)\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:Sra?|Senhora?)?[\\s\\.]*(?:Deputad[oa]|Dep\\.)|\" +\n",
    "    r\"(?:Sra?|Senhora?)[\\s\\.]*(?:Deputad[oa]|Dep\\.)?|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"MENSAGEM\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" + \n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(]{,100}\\(\\s*(?:D[oa])?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}\\)]\" + r\"{1,100})?\\)\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\".{,100}?D[oa]\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._0-9]+|\" +\n",
    "    NRO +\n",
    "    r\"(?:[^,]*?[,\\.]+\\s*(?:DE\\s*)+?[\\._0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile(\n",
    "        r\"(?<=^.{,250}?)(REQUERIMENTO\\s*DE\\s*INFORMA[cÇ](?:[oÕ]ES|[AÃ]O).{,50}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)(?=(?:Excelent[ií]ssim[oa]|Ex\\.?m[ao]\\s*\\.?)?\\s*(?:Senhora?|Sra?)[\\.\\s]*Presidente)\", regex.IGNORECASE),\n",
    "     fn_lambda_double),\n",
    "    (regex.compile(\n",
    "        r\"(?<=^.{,250}?)(REQUERIMENTO.{,25}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)(?=(?:Excelent[ií]ssim[oa]|Ex\\.?m[ao]\\s*\\.?)?\\s*(?:Senhora?|Sra?)[\\.\\s]*Presidente|Requeiro)\", regex.IGNORECASE),\n",
    "     fn_lambda_double),\n",
    "    (regex.compile(\n",
    "        r\"(REQUERIMENTO.{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        DEPT_EXTENSION_A +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)(?=(?:Excelent[ií]ssim[oa]|Ex\\.?m[ao]\\s*\\.?)?\\s*(?:Senhora?|Sra?)[\\.\\s]*Presidente|Requeiro)\", regex.IGNORECASE),\n",
    "     fn_lambda_double),\n",
    "    (regex.compile(\n",
    "        r\"(INDICA[CÇ][AÃ]O.{,50}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)(?=(?:Excelent[ií]ssim[oa]|Ex\\.?m[ao]\\s*\\.?)?\\s*(?:Senhora?|Sra?)[\\.\\s]*(?:Presidente|Ministr[oa]))\", regex.IGNORECASE),\n",
    "     fn_lambda_double),\n",
    "    (regex.compile(\n",
    "        r\"(?<=^.{,250}?)((?:PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple),\n",
    "    (DetectRecurrentNoise, lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"),\n",
    "    (regex.compile(r\"([:;\\?])(\\s{,10}[-–])\"), lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\"),\n",
    "    (regex.compile(r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"), lambda symb, deb: f\" {symb} {deb} \"),\n",
    "    (regex.compile(\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double),\n",
    "    (regex.compile(\n",
    "        r\"(?<=^.{,250}?)(TVR\\s*\" + DATE_AND_ID + DEPT_EXTENSION + \")\"\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple),\n",
    ")\n",
    "\n",
    "\n",
    "RE_PRE_POST_BLOCKS = (\n",
    "    regex.compile(r\"(ACORDO\\s*DE[-,ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z0-9\\s]+)(?=([OA]\\s+)[A-Z][a-z])\"),\n",
    "    regex.compile(r\"(?<=^[^\\()]{,250}?)(\" + COMMISSIONS + r\")\", regex.IGNORECASE | regex.VERBOSE),\n",
    "    regex.compile(r\"(O\\s*Congresso\\s*Nacional\\s*decreta\\s*:)\", regex.IGNORECASE),\n",
    "    regex.compile(r\"(C[ÂA]MARA\\s*DOS\\s*DEPUTADOS|CONGRESSO\\s*NACIONAL)(?!\\s*[dD][eE][cC][rR][eE][tT][aA])\"),\n",
    "    regex.compile(r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*decreta:)\", regex.IGNORECASE),\n",
    "    regex.compile(r\"(?<=^.{,250}?)(Projeto\\s*de\\s*Lei\\s*\" + DEPT_EXTENSION + r\")\", regex.IGNORECASE),\n",
    "    regex.compile(\n",
    "        r\"(?<=^.{,250}?)(Projeto\\s*de\\s*(?:Decreto\\s*Legislativo\\s*|Resolu[cç][aã]o)\" +\n",
    "        f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(?<=^[^\\(]{,250}?)(Mensagem\\s*\" + DATE_AND_ID + \"\\s*[0-9][0-9\\s]*)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(?<=^.{,250}?)(Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(cap[ií]tulo\\s*\" + f\"{VALID_ROMAN_NUM}\" +\n",
    "        r\"(?:[-–\\sA-Za-zçüúíàáãâéêẽóõô0-9]|\" + \n",
    "        f\"{MARKER_NOISE_END}|{MARKER_NOISE_START}\" +\n",
    "        r\")+?\" +\n",
    "        f\"(?=(?:{MARKER_VALID}|Art)))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(t[ií]tulo\\s*\" + f\"{VALID_ROMAN_NUM}\" +\n",
    "        r\"(?:[-–\\sA-Za-zçàüáéíóúãõẽôâê0-9]|\" + \n",
    "        f\"{MARKER_NOISE_END}|{MARKER_NOISE_START}\" +\n",
    "        r\")+?\" +\n",
    "        f\"(?=(?:{MARKER_VALID}|cap[íi]tulo)))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \", text, concurrent=True)\n",
    "    \n",
    "    for i, (reg, fun) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \" + r\"\\1\" + f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    return text\n",
    "\n",
    "auxaux = \"1 * 9 2 7 C 9 8 B E 0 0 * 9 2 7 C 9 8 B E 0 0 REQUERIMENTO DE INFORMAÇÕES NO , DE 2013 ( Da Sra. Luiza Erundina ) Requer informações acerca dos procedimentos de renovação de concessões outorgadas à Globo Comunicação e Participações S.A. para explorar serviço de radiodifusão de sons e imagens nas cidades de São Paulo , Rio de Janeiro , Recife , Brasília e Belo Horizonte , especialmente em relação à situação fiscal da empresa . Senhor Presidente : Requeiro a V . Exa. , com base no art . 50 da Constituição Federal , e nos arts . 115 e 116 do Regimento Interno que , ouvida a Mesa , sejam solicitadas informações ao Sr. Ministro das Comunicações , no sentido de esclarecer esta Casa quanto aos procedimentos de renovação de concessões outorgadas à Globo Comunicação e Participações S.A. para explorar serviço de radiodifusão de sons e imagens nas cidades de São Paulo , Rio de Janeiro , Recife , Brasília e Belo Horizonte , especialmente em relação à situação fiscal da empresa . - Como foi possível a renovação de concessões outorgadas à Globo Comunicação e Participação S.A. para a exploração do serviço de radiodifusão de sons e imagens nas cidades de São Paulo , Rio de Janeiro , Recife , Brasília e Belo Horizonte , se a empresa alegadamente não cumpria a exigência legal de regularidade perante o fisco federal ? - Ao longo do processo de outorga , foi apresentada pela empresa certidão negativa de débitos relativos aos tributos federais e à dívida ativa da União , em atendimento ao que é preconizado pela legislação em vigor ? Em caso positivo , como pode a Receita Federal ter emitido tal documento se a GLOBOPAR , à época , era provável devedora da vultosa 2 * 9 2 7 C 9 8 B E 0 0 * 9 2 7 C 9 8 B E 0 0 quantia de R $ 615 milhões referente a Imposto Sobre a Renda da Pessoa Jurídica ( IRPJ ) não recolhido ? - Quais procedimentos estão sendo adotados pelo Ministério das Comunicações no acompanhamento da situação fiscal da GLOBOPAR ? Existe a possibilidade de cancelamento das outorgas de radiodifusão destinadas à empresa frente ao claro descumprimento , pela entidade , da legislação relativa à renovação de outorgas ?\"\n",
    "try:\n",
    "    _=preprocess_instance({\"text\": auxaux}, -1, True, True)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T01:28:10.765604Z",
     "start_time": "2022-02-24T01:26:59.046202Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ad4335b1c75052af\n",
      "Reusing dataset csv (../cache/datasets/csv/default-ad4335b1c75052af/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fda089a049457ab78cba7f825be71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-ad4335b1c75052af/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-45bf8e61d6bddb7e.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-ad4335b1c75052af/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-145b2fda40184cf8.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-ad4335b1c75052af/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-86cd00fbcb51e409.arrow\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START,\n",
    "    nrows=DATASET_ROW_END - DATASET_ROW_START + 1,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[A-Z])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÃ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aã]\\s*o\\s+(?=[A-Z])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "def preprocess_instance(item, ind, print_preprocessed: bool = False, debug: bool = False):\n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug)\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(preprocessed_text)\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            token = tokens.pop(i)\n",
    "            labels.pop(i)\n",
    "            labels[i] = SPECIAL_SYMBOLS[token]\n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "        labels[0] = 0\n",
    "    \n",
    "    if tokens[-1] in SPECIAL_SYMBOLS:\n",
    "        labels.pop()\n",
    "        tokens.pop()\n",
    "\n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T01:03:50.436087Z",
     "start_time": "2022-02-24T01:03:50.433351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 29988}\n"
     ]
    }
   ],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T01:30:08.686592Z",
     "start_time": "2022-02-24T01:29:08.728916Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct proportion: 100.00% (6 of 6)\n",
      "\n",
      "\n",
      "\n",
      "Chosen id: 8524\n",
      "COMISSÃO DE CIÊNCIA E TECNOLOGIA , COMUNICAÇÃO E INFORMÁTICA PROJETO DE DECRETO LEGISLATIVO Nº , DE 2013 Aprova o ato que outorga permissão à V.P.D . Empresa de Radiodifusão Ltda. - ME . para explorar serviço de radiodifusão sonora em frequência modulada , no Município de Bom Jardim , Estado do Rio de Janeiro . O CONGRESSO NACIONAL decreta : Art . 1º É aprovado o ato constante da Portaria nº 1153 , de 23 de novembro de 2010 , que outorga permissão à V.P.D . Empresa de Radiodifusão Ltda. - ME . para explorar , pelo prazo de dez anos , sem direito de exclusividade , serviço de radiodifusão sonora em frequência modulada , no Município de Bom Jardim , Estado do Rio de Janeiro . Art . 2º Este decreto legislativo entra em vigor na data de sua publicação . Sala da Comissão , em 21 de agosto de 2013 . Deputado PAULO ABI-ACKEL Presidente\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[97m 1 \u001b[39m COMISSÃO DE CIÊNCIA E TECNOLOGIA , COMUNICAÇÃO E INFORMÁTICA\n",
      "\n",
      "\u001b[97m 2 \u001b[39m PROJETO DE DECRETO LEGISLATIVO Nº , DE 2013\n",
      "\n",
      "\u001b[97m 3 \u001b[39m Aprova o ato que outorga permissão à V.P.D . Empresa de Radiodifusão Ltda.\n",
      "\n",
      "\u001b[97m 4 \u001b[39m - ME . para explorar serviço de radiodifusão sonora em frequência modulada , no Município de Bom Jardim , Estado do Rio de Janeiro .\n",
      "\n",
      "\u001b[97m 5 \u001b[39m O CONGRESSO NACIONAL decreta :\n",
      "\n",
      "\u001b[97m 6 \u001b[39m Art . 1º É aprovado o ato constante da Portaria nº 1153 , de 23 de novembro de 2010 , que outorga permissão à V.P.D . Empresa de Radiodifusão Ltda.\n",
      "\n",
      "\u001b[97m 7 \u001b[39m - ME . para explorar , pelo prazo de dez anos , sem direito de exclusividade , serviço de radiodifusão sonora em frequência modulada , no Município de Bom Jardim , Estado do Rio de Janeiro .\n",
      "\n",
      "\u001b[97m 8 \u001b[39m Art . 2º Este decreto legislativo entra em vigor na data de sua publicação .\n",
      "\n",
      "\u001b[97m 9 \u001b[39m Sala da Comissão , em 21 de agosto de 2013 . Deputado PAULO ABI-ACKEL Presidente\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   8524: 9, 0\n",
      "Is it correct? [y/N]: N\n"
     ]
    }
   ],
   "source": [
    "# id_ = 23600\n",
    "# print(tests.TEST_CASES[id_])\n",
    "# tests.print_results(df, id_, print_full_text=True)\n",
    "tests.run_tests(df[\"train\"][\"labels\"])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "document_idx = 9966\n",
    "while tests.test_case_exists(document_idx):\n",
    "    document_idx = random.randint(0, 1 + df[\"train\"].num_rows)\n",
    "\n",
    "print(\"Chosen id:\", document_idx)\n",
    "expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "inp = input()\n",
    "if inp == \"y\":\n",
    "    tests.update_test_case(document_idx, expected_test_case_values)\n",
    "    print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T00:44:21.379257Z",
     "start_time": "2022-02-24T00:44:21.372432Z"
    }
   },
   "outputs": [],
   "source": [
    "tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
