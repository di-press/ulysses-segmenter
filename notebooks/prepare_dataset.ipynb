{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T06:23:29.941077Z",
     "start_time": "2022-03-02T06:23:29.931722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "Loaded 13 test cases from './test_cases/110001_120000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "DEV_RUN = True\n",
    "\n",
    "\n",
    "random.seed(499)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "DATASET_ROW_START = None\n",
    "DATASET_ROW_END = None\n",
    "if DEV_RUN:\n",
    "    TESTS_DIR = \"test_cases\"\n",
    "    DATASET_ROW_START = 110001\n",
    "    DATASET_ROW_END = 120000\n",
    "    TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "    tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T06:23:35.774434Z",
     "start_time": "2022-03-02T06:23:32.092280Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=DEV_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T06:44:53.377240Z",
     "start_time": "2022-03-02T06:44:52.957726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m ✓ 4_PRE_POS PROJETO DE LEI N°______, DE 2020. (DOS/AS SRS/AS. ERIKA KOKAY, GLAUBER BRAGA, HELDER SALOMÃO, MARIA DO ROSÁRIO, NILTO TATTO, PAULO FERNANDO DOS SANTOS, PAULO TEIXEIRA e NATÁLIA BONAVIDES) ✓ 4_PRE_POS  Amplia o prazo para o trabalhador em situação de rua requerer o auxílio emergencial de que trata a Lei n° 13.982, de 2020, até 30 de setembro de 2020, e dá outras providências.  ✓ 2_PRE_POS O CONGRESSO NACIONAL decreta: ✓ 2_PRE_POS  ✓ 1_PRE  Art. 1º O art.2° da lei nº 13.982, de 2 de abril de 2020, passa a vigorar acrescido dos seguintes parágrafos: “ ✓ 1_PRE Art.2°. ..................................................................................................... .................................................................................................................... ✓ 0_PRE  § 14. O trabalhador que se encontre em situação de rua poderá requerer o auxílio de que trata o caput até 30 de setembro de 2020, garantindo-se àqueles que cumpram cumulativamente os requisitos estabelecidos nos incisos I a VI o pagamento do mesmo número de prestações mensais concedidas aos demais beneficiários. ✓ 0_PRE  § 15. O trabalhador que se encontre em situação de rua poderá realizar a autodeclaração na plataforma digital de que trata o § 4º nos equipamentos da assistência social ou em organizações da sociedade civil sem fins lucrativos credenciadas no conselho de assistência social local, sendo que não haverá restrição ao número de autodeclarações que podem ser feitas em um mesmo aparelho informático ou telefônico de propriedade ou posse desses equipamentos e organizações. ✓ 0_PRE  § 16. O poder público, em conjunto com órgãos e entidades vinculados ao Sistema Único de Assistência Social, realizará busca ativa e assistirá os trabalhadores que se encontrem em situação de rua na utilização da plataforma digital de que trata o § 4º.” ✓ 1_PRE   ✓ 12_PRE_POS Art. 2º Esta lei entra em vigor na data de sua publicação. ✓ 12_PRE_POS \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DEBUG_PATTERN = \"(?:\\s*[0-9]{1,3}_[A-Z]{1,30}\\s*)\"\n",
    "ALL_SPECIAL_MARKERS = f\"(?:{MARKER_INTENDED_CORRUPTION}|{MARKER_NOISE_START}|{MARKER_NOISE_END}|{MARKER_VALID})\"\n",
    "\n",
    "COMMISSION_LIST = (r\"\"\"\n",
    "    (?:\n",
    "    AGRICULTURA[,\\s]*PECU[AÁ]RIA[,\\s]*ABASTECIMENTO[E\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA[,\\s]*COMUNICA[CÇ][AÃ]O(?:[E\\s]|DA)*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*DE\\s*CIDADANIA|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*(?:DO|AO)\\s*CONSUMIDOR|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO[,\\s]*IND[UÚ]STRIA[,\\s]*COM[EÉ]RCIO(?:[E\\s]|DE)*SERVI[CÇ]OS|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS(?:[E\\s]|DAS)*MINORIAS|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS[E\\s]*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA[E\\s]*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL[,\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*REGIONAL(?:[E\\s]|DA)*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    (?:MEIO\\s*)?AMBIENTE[E\\s]*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS(?:[E\\s]|DA)*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES(?:[E\\s]|DE)*\\s*DEFESA\\s*NACIONAL|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL(?:[E\\s]|DA)*FAMÍLIA|\n",
    "    TRABALHO[,\\s]*ADMINISTRA[CÇ][AÃ]O[E\\s]*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES|\n",
    "    INQUÉRITO\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "COMMISSIONS = (\n",
    "    r\"COMISS[AÃ]O\\s*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:D[EOA]S?|[,;\\s]*E|[;,]\\s*E?|PARLAMENTAR)\\s*)+\" +\n",
    "    COMMISSION_LIST +\n",
    "    r\"\\s*)+\"\n",
    ")\n",
    "\n",
    "\n",
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(r\"\\*([\\sA-Z0-9]+)\\*\")\n",
    "    RE_BARCODE_2 = regex.compile(r\"(((?:[0-9A-F]{2}\\s*?){7})\\s*\\2)\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(.{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_CAMARA_REPEATED = regex.compile(\n",
    "        r\"(?:\" +\n",
    "        r\"(C[AÂ]MARA\\s*|CONGRES)(DOS\\s*|SO\\s*NAC)\" +\n",
    "        r\"(DEPUTADOS|IONAL)\" +\n",
    "        r\"([\\s0-9]+(?![\\s0-9]*[-–\\.\\)]))?\" +\n",
    "        r\"(?!\\s*[dD][eE][cC][rR][eE][tT][aA])\" +\n",
    "        r\")\",\n",
    "    )\n",
    "    RE_COMMISSIONS_REPEATED = regex.compile(\n",
    "        f\"({COMMISSIONS})\"\n",
    "    )\n",
    "    RE_SALA_DAS_SESSOES_CODE = regex.compile(\n",
    "        r\"(?<=Sala\\s*das\\s*sess[oõ]es\\s*.{,150}?)([0-9]{1,5}\\s*_\\s*(?:\" +\n",
    "        MARKER_NOISE_START +\n",
    "        r\")?\\s*[0-9]{1,5})\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    FN_PAGE_NUMBER = lambda page_num: (\n",
    "        r\"(P[aá]g(?:ina)?[\\.\\s:]*)?\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        f\"(\\s*0?{page_num}\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*(?:[\\\\/-]|de)\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]+\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\"\n",
    "    )\n",
    "    RE_PAGE_NUMBER_01 = regex.compile( #Pág: 1 de 3\n",
    "        f\"^\\s*{FN_PAGE_NUMBER(1)}|(P[aá]g(?:ina)?[\\.\\s:]*){FN_PAGE_NUMBER(1)}\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = sorted(set(pseudo_patterns))\n",
    "        \n",
    "        for pseudo_pattern in pseudo_patterns:\n",
    "            pattern = list(cls.RE_BLANK_SPACES.sub(\"\", pseudo_pattern))\n",
    "            pattern.append(\"\")\n",
    "            pattern.insert(0, \"\")\n",
    "            pattern = (r\"(?:\\s*(?:\" + MARKER_NOISE_START + r\")?\\s*\" + DEBUG_PATTERN + r\"*\\s*)\").join(pattern)\n",
    "            pattern = (\n",
    "                r\"(\\*\" +\n",
    "                pattern +\n",
    "                r\"\\*\\s*\" +\n",
    "                r\"(?:\" +\n",
    "                r\"(?:\" + MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*)?\\s*\" +\n",
    "                pattern +\n",
    "                r\")?\" +\n",
    "                r\")\"\n",
    "            )\n",
    "            \n",
    "            text = regex.sub(pattern, subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara(cls, subpattern, text):\n",
    "        occurrences = cls.RE_CAMARA_REPEATED.findall(text)\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\\4\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_REPEATED.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_commissions(cls, subpattern, text):\n",
    "        freqs = collections.Counter(map(str.strip, cls.RE_COMMISSIONS_REPEATED.findall(text)))\n",
    "        \n",
    "        for commission_name, freq in freqs.items():\n",
    "            if freq <= 2:\n",
    "                continue\n",
    "            \n",
    "            mod_subpattern = f\" {MARKER_INTENDED_CORRUPTION}\".join(cls.RE_BLANK_SPACES.split(commission_name))\n",
    "            mod_subpattern = subpattern.replace(r\"\\1\", mod_subpattern)\n",
    "            \n",
    "            text = text.replace(commission_name, mod_subpattern)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_page_number(cls, subpattern, text):\n",
    "        match = cls.RE_PAGE_NUMBER_01.search(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        last_page = int(match.group(4) or match.group(9))\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(r\"\\1\", r\"\\1\\2\\3\\4\")\n",
    "        \n",
    "        for i in range(1, 1 + last_page):\n",
    "            text = regex.sub(cls.FN_PAGE_NUMBER(i), mod_subpattern, text, flags=regex.IGNORECASE)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_page_number(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        text = cls.RE_SALA_DAS_SESSOES_CODE.sub(subpattern, text)\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        text = cls._detect_repeated_commissions(subpattern, text)\n",
    "        text = cls.RE_BARCODE_2.sub(subpattern, text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "UPPERCASE_LETTERS = r\"ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z\"\n",
    "UPPERCASE_LETTERS_OR_NUM = UPPERCASE_LETTERS + r\"0-9\"\n",
    "VALID_ROMAN_NUM = r\"M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3})\"\n",
    "NRO_SMALL = r\"[nN]\\s*[oO0º°\\.]{1,3}\"\n",
    "NRO = (\n",
    "    r\"(?:\" +\n",
    "    r\"[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[oO0º°]\" +\n",
    "    r\"(?=[^\" + UPPERCASE_LETTERS + UPPERCASE_LETTERS.lower() + r\"])|\" +\n",
    "    r\"(?<=\\s)\" + NRO_SMALL +\n",
    "    r\")\"\n",
    ")\n",
    "QUOTES = r\"”“”\\\"'‘\"\n",
    "QUOTES_CLASS = f\"[{QUOTES}]\"\n",
    "\n",
    "\n",
    "class AgreementList:\n",
    "    ITEMS = (\n",
    "        r\"(\\s*(?:\" +\n",
    "        r\"(?:[ÓO]rg[aã]o\\s*)?(?:Superior|[cC]oncedente|[cC]onve(?:nente|niada))|\" +\n",
    "        NRO + r\"\\s*(?:SIAFI|Original|Do\\s*conv[eê]nio)|\" +\n",
    "        r\"Valor\\s*(?:do\\s*conv[eê]nio)?|\" +\n",
    "        r\"(?:In[ií]cio|Fim)\\s*(?:d[ea]\\s*vig[eê]ncia)?|\" +\n",
    "        r\"Objeto|\" +\n",
    "        r\"Conv[eê]nio|\" +\n",
    "        r\"Processo|\" +\n",
    "        r\"Total\\s*de\\s*itens\\s*Licitados|\" +\n",
    "        r\"Fundamento\\s*legal|\"+\n",
    "        r\"Contratada|\" +\n",
    "        r\"Questionamentos|\" +\n",
    "        r\"Justificativa\"\n",
    "        r\")\\s*)\"\n",
    "    )\n",
    "    RE_ITEMS = regex.compile(ITEMS + r\"(\\s*:)\", regex.IGNORECASE)\n",
    "    REG_GET_LIST = regex.compile(\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + ITEMS + r\":\\s*[^:]{,150}?){2,10}\" +\n",
    "        ITEMS + r\":\\s*[^:]{,150}\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    @classmethod\n",
    "    def sub(cls, subpattern, text: str, *args, **kwargs):\n",
    "        re_match = cls.REG_GET_LIST.search(text)\n",
    "        if re_match is None:\n",
    "            return text\n",
    "        s_start, s_end = re_match.span()\n",
    "        text_slice = text[s_start:s_end]\n",
    "        subpattern = subpattern.replace(r\"\\1\", r\"\\1\" + f\" {MARKER_INTENDED_CORRUPTION} \" + r\"\\2\")\n",
    "        text_slice = cls.RE_ITEMS.sub(\n",
    "            subpattern,\n",
    "            text_slice,\n",
    "        )\n",
    "        text = f\"{text[:s_start]}{text_slice}{text[s_end:]}\"\n",
    "        return text\n",
    "\n",
    "    \n",
    "STATES_ACRONYM = r\"\"\"\n",
    "(?:\n",
    "AC|\n",
    "AL|\n",
    "AP|\n",
    "AM|\n",
    "BA|\n",
    "CE|\n",
    "DF|\n",
    "ES|\n",
    "GO|\n",
    "MA|\n",
    "MT|\n",
    "MS|\n",
    "MG|\n",
    "PA|\n",
    "PB|\n",
    "PR|\n",
    "PE|\n",
    "PI|\n",
    "RJ|\n",
    "RN|\n",
    "RS|\n",
    "RO|\n",
    "RR|\n",
    "SC|\n",
    "SP|\n",
    "SE|\n",
    "TO\n",
    ")\n",
    "\"\"\".replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "\n",
    "DOC_ABBVR_LIST = (\n",
    "    \"COM\", \"DCR\", \"DEN\", \"DTQ\", \"DVS\", \"DVT\", \"EMC\", \"EMD\", \"EML\", \"LDO\", \"EMO\",\n",
    "    \"EMP\", \"EMR\", \"ERD\", \"ESB\", \"EXP\", \"INA\", \"INC\", \"MPV\", \"MSC\", \"PAR\", \"PDC\",\n",
    "    \"PEC\", \"PET\", \"PFC\", \"PLP\", \"PLV\", \"PRC\", \"PRF\", \"PRN\", \"PRO\", \"RCP\", \"REC\",\n",
    "    \"REL\", \"REM\", \"REP\", \"REQ\", \"RIC\", \"RPR\", \"SBE\", \"SBT\", \"SDL\", \"LDO\", \"SIT\",\n",
    "    \"TCU\", \"SOA\", \"STF\", \"SUG\", \"SUM\", \"CCJ\", \"TER\", \"TVR\", \"VTS\", \"PL\",\n",
    ")\n",
    "\n",
    "DOC_ABBVR = r\"(?:\" + \"|\".join(DOC_ABBVR_LIST) + r\")\"\n",
    "\n",
    "DOC_ABBVR_WITH_SPACES = (\n",
    "    r\"(?:\" +\n",
    "    r\"|\".join(map(lambda item: r\"\\s*\".join([\"\", *item, \"\"]), DOC_ABBVR_LIST)) +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "RAW_NUMBER_PREFIXES = (\n",
    "    r\"Art(?:igo)?s?\\s?\\.?\\s?|\" + NRO_SMALL + r\"|\\$|p[aá]g\\s*\\.|cep\\s*\\.\"\n",
    ")\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:(?:[-–º°0-9]+|[A-Z]{1,2})|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+|\" + QUOTES_CLASS + r\")(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\so0º°]*:\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\(?\\s+[0-9]{1,2}[\\s0oOº°]*(?:[-–\\)]|\\.(?![\\.0-9]))\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\s+[0-9]{1,2}\\s*(?:\\.[0-9]+){1,2}(?![\\.0-9]*,)\",\n",
    ")\n",
    "\n",
    "MONTHS = \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    ")).upper()\n",
    "\n",
    "DATE = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[0-9]{,2}\\s*(?:de|em)\\s*(?:\" + MONTHS + r\")\\s*(?:de|em)\\s*[0-9]{4}\"\n",
    ")\n",
    "\n",
    "DATE_OR_UNDERSCORES = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,\\.0-9\\s]*){1,3}(?:[0-9]{4}|[\\._]+)|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*(?:[0-9]{,2}|[\\._]+)\\s*(?:de|em)\\s*(?:\" + MONTHS +\n",
    "    r\"|_+)\\s*(?:de|em)\\s*(?:[0-9]{4}|[\\._]+)\"\n",
    ")\n",
    "\n",
    "UPPERCASE_DATE_OR_UNDERSCORES = DATE_OR_UNDERSCORES.replace(\"em\", \"EM\").replace(\"de\", \"DE\")\n",
    "\n",
    "EOF = r\".{,300}$\"\n",
    "\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    EOF +\n",
    "    r\"|\" +\n",
    "    DATE_OR_UNDERSCORES + \n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"030|Daniel|[eE]ss|Jaa|ac[fgp]|afpa|cmrv|(da[-–])?conle|[Cc]rps|\" +\n",
    "    r\"dennn?er|dpsl?|drb|epo|faa|‘?[Gg]ab|gsl|jaa|jbs|kvp|lgl|mlcl?|\" +\n",
    "    r\"mm|pnf|rpb|tksa|[Vv][Pp][Ll][cf]?|wgl\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_CORE = r\"(?:pls|mpv|plc|pec|pds|plv|prn|plp|pdl|tema)\"\n",
    "\n",
    "RE_DOC_CODE_SUFFIX = (\n",
    "    r\"(?:(?:\"\n",
    "    r\"c(?:ompleme?ntar)?|eme(?:nda)?s?|\" +\n",
    "    r\"rev(?:is)?|sub(?:st\\.?(?:itutivo)?)?|sust|tt?\" +\n",
    "    r\")\\s*?)*\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_FULL = (\n",
    "    r\"(\" +\n",
    "    r\"(?<=\\s)\" +\n",
    "    RE_DOC_CODE_PREFIX +\n",
    "    \"/\" +\n",
    "    RE_DOC_CODE_CORE +\n",
    "    \"(?:[-–0-9]+)\" +\n",
    "    f\"(?:{RE_DOC_CODE_SUFFIX}[-–\\s]*?)+\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"Sala\\s*d[ea]s?\\s*(?:sess|comiss|reuni)(?:[õo]es|[ãa]o)\" + EOF_OR_DATE,\n",
    "    r\"Senado\\s*Federal\\s*,\" + EOF_OR_DATE,\n",
    "    r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\" + EOF_OR_DATE,\n",
    "    r\"Bras[ií]lia\\s*,\\s*(?:\" + DATE_OR_UNDERSCORES + \")\\s*\",\n",
    "    r\"•\",\n",
    "    r\"●\",\n",
    "    \"\\uF0B7\",\n",
    "    r\"As?\\s*mesas?\\s*da\\s*c[aâ]mara\\s*dos\\s*deputados[^:]{,300}?:\",\n",
    "    r\"Atenciosamente\\s*,\",\n",
    ")\n",
    "\n",
    "CEP = r\"(?:CEP[-–\\s\\.:]*)?[0-9]{2}\\.?[0-9]{3}[-–\\s]*[0-9]{3}\"\n",
    "BRASILIA = r\"Bras[ií]lia.{,5}?DF\"\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "    regex.compile( #0\n",
    "        r\"((?:C[aâ]mara\\s*dos\\s*Deputados\\s*.{,15}?\\s*)?\" +\n",
    "        r\"Anexo\\s*\" + VALID_ROMAN_NUM + r\".{,30}?\" + \"Gab(?:inete)?.{,10}?\" + NRO + \"?[0-9]+\" +\n",
    "        r\"|\" +\n",
    "        r\"Gab(?:inete).{,10}?\" + NRO + r\"?[0-9]+.{,30}?\" + r\"Anexo\\s*\" + VALID_ROMAN_NUM +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(f\"(?<!{NRO}[_\\s\\.0-9]*)\" + r\"([0-9]{11,})\"), #1\n",
    "    regex.compile(r\"(_{9,}\\s*)+\"), #2\n",
    "    regex.compile(r\"(^[\\s0-9]+|(?<!:[\\s0-9_]*)(?:[0-9]+_+)?[\\s0-9]+$)\"), #3\n",
    "    regex.compile( #4\n",
    "        r\"(^(?:\\s*[^\\s\" + \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM + r\"]\\s*)+|\" +\n",
    "        r\"(?:\\s*[^\\s\\.\\)\\?\" + \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM + r\"]\\s*)+$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #5\n",
    "        r\"((?:(?:E[-–\\s]*mails?|Endere[cç]os?\\s*eletr[oô]nicos?)[\\s:]*)?\" +\n",
    "        r\"[-–a-zA-Z0-9\\._]{,40}\\s*@\\s*(?:[a-zA-Z]{1,15}\\.?){1,3})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #6, 7, 8, 9, 10, 11, 12, 13, 14\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, r\"cap[ií]tulo\", r\"t[íi]tulo\")\n",
    "    ],\n",
    "    regex.compile( # 15\n",
    "        r\"((?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)CPI\\s*(?:da\\s*Petrobr[áa]s)?\\s*[-–]\\s*\" +\n",
    "        r\"(LEI\\s*ROUANET|Relat[oó]rio\\s*Final|EXPLORA[CÇ][AÃ]O\\s*SEXUAL\\s*DE\\s*CRIAN[CÇ]AS\\s*E\\s*ADOLESCENTES))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(f\"({CEP}[-–\\s]*{BRASILIA}|{BRASILIA}[-–\\s]*{CEP})\", regex.IGNORECASE), #16\n",
    "    regex.compile( #17\n",
    "        r\"(Gabinete\\s*d[eoa]\\s*deputad[oa]\\s*[^0-9]{,50}?[-–\\\\/]\\s*\" +\n",
    "        STATES_ACRONYM +\n",
    "        \"(?=\\s|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #18\n",
    "        r\"(c[âa]mara\\s*dos\\s*deputados\\s*.{,10}?\\s*pra[çc]a\\s*dos\\s*tr[êe]s\\s*poderes)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC|\\.{3,})\\s*\\)\\s*|\" +\n",
    "    f\"[{QUOTES}])\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    r\"(?:(?:\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    r\"[^\" + MARKER_VALID + r\"]{,900}?\" +\n",
    "    MARKER_NOISE_END + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    r\"))\"\n",
    ")\n",
    "\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in (\n",
    "        *BASE_LEGAL_ITEMS,\n",
    "        *EXTRA_LEGAL_ITEMS,\n",
    "        r\"D[eê][-–]se\\s*ao\\s*Projeto\\s*a\\s*seguinte\\s*reda[cç][aã]o\\s*:\",\n",
    "    )\n",
    ")\n",
    "\n",
    "ADDITIONAL_TITLES = (\n",
    "    r\"(?:\" \n",
    "    r\"Ju[ií]z[ea]?s?|M[\\.\\s]*M[aª]?[\\s\\.]*|\" +\n",
    "    r\"Doutor[ea]?s?|D\\.?r[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Professor[ea]?s?|Prof[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Advogad[ao]s?|Adv[\\s\\.]*\" +\n",
    "    r\")*\"\n",
    ")\n",
    "\n",
    "ABBVR_EXMO = r\"Ex\\.?m[aªoº]s?\\s*\\.?\"\n",
    "ABBVR_EX = r\"Ex\\.?[aªoº]?s?\\s*\\.\\s*[ºªᵉ]?\"\n",
    "ABBVR_SR = r\"S\\.?r\\.?[aªeᵉ]?s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\"\n",
    "\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)?[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)?\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"(?:MENSAGEM|\" + DOC_ABBVR + \")\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" +\n",
    "    r\"CPI|\" +\n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "\n",
    "#DOS/AS SRS/AS\n",
    "\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(]{,100}\\(\\s*(?:D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}\\)]\" + r\"{1,200})?\\)\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\".{,100}?D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._0-9]+|\" +\n",
    "    f\"(?:{NRO}\" + r\"[_\\s\\.0-9]*)?\\s*(?:\" + UPPERCASE_DATE_OR_UNDERSCORES + r\")|\" +\n",
    "    NRO + r\"[_\\s\\.0-9]*\" + r\"(?:[^,]{,30}?[,\\.]+\\s*(?:DE\\s*)+?[\\._0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "# DATE\n",
    "\n",
    "fn_lambda_single = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" \n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "fn_lambda_quad = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \" + r\"\\4\" + f\" {symb} {deb} \"\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY = (\n",
    "    r\"(?:Excelent[ií]ssim[oa]s?|\" + ABBVR_EXMO + r\"|(?:Vossa|V\\s*\\.)\\*(?:excel[eê]ncias?|\" + ABBVR_EX + r\"))?\" +\n",
    "    r\"\\s*(?:Senhor[ae]?s?|\" + ABBVR_SR + r\")[\\.\\s]*\" +\n",
    "    r\"\\s*(?:Primeir[oa]s?|Vices?|[-–\\s])*\" +\n",
    "    r\"(?:Pres(?:id(?:ent[ae])?)?s?|Min(?:istr[oa])?s?|Advogad[ao]s?\\s*Geral\\s*da\\s*Uni[aã]o|Secret[aá]ri[oa]s?)\" +\n",
    "    r\"[^,:;\\.]{,75}?[,:;\\.]\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<=(?<!\" + f\"{ABBVR_EXMO}|{ABBVR_EX}|{ABBVR_SR}\" + \")\\s*\\..{,10}?|\\).{,10}?)\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY + \"|\" +\n",
    "    r\"(?:(?<=\\.\\s*)(\\s+O\\s*)?Requeiro|Solicito)\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile( #0\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,15}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #1\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #2\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        DEPT_EXTENSION_A +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #3\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #4\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #5\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #6\n",
    "        r\"(MEDIDA\\s*PROVIS[ÓO]RIA.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,1200}?)([OA]\\s*President[ea]\\s*da\\s*rep[úu]blica[^:]+?com\\s*for[cç]a\\s*de\\s*lei\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #7 #PL n .1 31 1/ 20 20 Ap re se nt aç ão : 3 1/ 03 /2 02 0 13 : 0 4\n",
    "        r\"(\" +\n",
    "        r\"(?:\" +\n",
    "        r\"\\s*\".join([\"\", *\"LexEdit\", \"\"]) +\n",
    "        r\")?\" +\n",
    "        r\"\\s*\".join([\"\", *\"Documentoeletr\", r\"[oô]\", *\"nico\", \"\"]) +\n",
    "        r\"\\s*.{,400}?\" +\n",
    "        r\")?\" +\n",
    "        r\"(\\s*\" +\n",
    "        r\"(?:\" + DOC_ABBVR_WITH_SPACES + \"\\s*\" + f\"(?:{NRO})*\" + r\"\\s*[\\d\\s]+/[\\s\\d]+)?+\\s*\" +\n",
    "        r\"\\s*\".join([\"\", *\"Apresenta\", \"[çc]\", \"[aã]\", *\"o:\", \"\"]) +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){4}\" + r\"\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*:\\s*\" +\n",
    "        r\")\" +\n",
    "        f\"({MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        f\"({MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        r\"([-–]*)\" +\n",
    "        r\"(\" + r\"\\s*\".join([\"\", *\"Mesa\", \"\"]) + r\")?\" +\n",
    "        r\"([\\s0-9]+(?=[\\s0-9]*(?:[§\" + UPPERCASE_LETTERS + r\"]|$)))?\"\n",
    "        , regex.IGNORECASE | regex.MULTILINE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\4\\6\" + MARKER_INTENDED_CORRUPTION + r\"\\7\" + MARKER_INTENDED_CORRUPTION + r\"\\8\\9\" + f\" {symb_end} {deb} \", None),\n",
    "    (DetectRecurrentNoise, #8\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #9\n",
    "        r\"([:;\" + QUOTES + r\"\\?])(\\s{,10}[-–])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #10\n",
    "        r\"((?<!S\\s*\\.\\s*A\\s*)\\.)(\\s{,10}[-–])(?=\\s*[\" + UPPERCASE_LETTERS + \"])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #11\n",
    "        r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"),\n",
    "     lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #12\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double, None),\n",
    "    (regex.compile( #13\n",
    "        r\"((?:TVR|(?:Ato\\s*de\\s*)?Concess[aã]o(?:e|\\s)*Renova[cç][ãa]o(?:de|\\s)*Concess[aã]o(?:de|\\s)*Emissora(?:de|\\s)*Rádio(?:e|de|\\s)*Televisão)\\s*\" + DATE_AND_ID + DEPT_EXTENSION + \")\"\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #14\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR)?|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)?\" +\n",
    "        f\"(?!{DEPT_EXTENSION})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #15\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)\" +\n",
    "        f\"(?:{UPPERCASE_DATE_OR_UNDERSCORES})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #16\n",
    "        r\"(?<=[\" + UPPERCASE_LETTERS + \"]{3,}\\s+)([0-9]{1,2}\\s*\\.\\s+[0-9]+)\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None\n",
    "    ),\n",
    "    (regex.compile( #17\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*|ou|,)\\s*)\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2,}\\s*)(\\)))?(\\s*[0-9]{4,}\\s*[-–\\.\\s]?\\s*[0-9]{4,}(?:\\s*/\\s*[0-9]{4})?)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #18\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #19\n",
    "        r\"(OF[IÍ]CIO\\s*\" + NRO + r\".{,110}?\\s*)\" +\n",
    "        r\"((?:Bras[ií]lia|Senado\\s*Federal)?[,\\s]*(?:\" + DATE_OR_UNDERSCORES + r\")[\\.\\s]*)\" +\n",
    "        r\"(.{,300}?\\s*)\" +\n",
    "        r\"(Assunto\\s*:\\s*.{,300}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE\n",
    "    ),\n",
    "    fn_lambda_quad, None),\n",
    "    (regex.compile( #20\n",
    "        r\"(Atenciosamente\\s*),\" +\n",
    "        r\"(\\s*.{,250}?\" +\n",
    "        RE_DOC_CODE_FULL +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\",\\2\" + f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #21\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,10}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        r\"([ÀÁA]\\s*sua\\s*excel[eê]ncia.{,100}?)\" +\n",
    "        r\"(?=(?:\" + REQUEST_PRESIDENT_OR_MINISTRY + \"[,\\s]*)?(?:Requeiro|Solicito))\", regex.IGNORECASE),\n",
    "     fn_lambda_triple, None),\n",
    "    (regex.compile( # 22\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*)([^\\s\" + UPPERCASE_LETTERS + r\"])((?:\\s|\\2)*)(\\s*)\" +\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)\",\n",
    "        regex.IGNORECASE),\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\\4\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #23\n",
    "        r\"(Autora?\\s*:\\s*.{,200}?)(\\s*Relatora?\\s*:)\", regex.IGNORECASE),\n",
    "     lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #24\n",
    "        r\"(?<=(?:Relatora?|Autora?)\\s*:.{,200}?\\s+)(\" + VALID_ROMAN_NUM + r\"[-–\\s]+RELAT[OÓ]RIO\\s+)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (AgreementList, #25\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (regex.compile(r\"(?=Reiterando\\s*os\\s*votos\\s*de\\s*apre[cç]o\\s*e\\s*considera[cç][aã]o)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #26\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*)\\s*)?\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2,}\\s*)(\\)))(\\s*[0-9]{4,}\\s*[-–\\.\\s]?\\s*[0-9]{4,}(?:\\s*/\\s*[0-9]{4})?)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \", None),\n",
    ")\n",
    "\n",
    "LARGER_BLOCKS_HIERARCHY = (\n",
    "    \"LIVRO\",\n",
    "    \"T[IÍ]TULO\",\n",
    "    \"CAP[IÍ]TULO\",\n",
    "    \"(?:Sub)?[sS]e[cç][aã]o\",\n",
    "    BASE_LEGAL_ITEMS[1] + r\"(?=\\s*[^\" + UPPERCASE_LETTERS_OR_NUM + r\"])\",\n",
    ")\n",
    "\n",
    "RE_PRE_POST_BLOCKS = (\n",
    "    regex.compile( #0\n",
    "        r\"(ACORDO\\s*DE\\s*[-,\"\n",
    "        + UPPERCASE_LETTERS_OR_NUM\n",
    "        + r\"\\s]+)(?=(?:[OA]\\s+)?[\"\n",
    "        + UPPERCASE_LETTERS\n",
    "        + r\"][a-z])\"\n",
    "    ),\n",
    "    regex.compile(r\"(?<!\\(.{,50}?)(\" + COMMISSIONS + \")\"), #1\n",
    "    regex.compile(r\"(O\\s*Congresso\\s*Nacional\\s*decreta\\s*.{,40}?\\s*:)\", regex.IGNORECASE), #2\n",
    "    regex.compile(r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*decreta\\s*.{,40}?\\s*:)\", regex.IGNORECASE), #3\n",
    "    regex.compile( #4\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Lei\\s*(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*)*\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" + r\"\\s*\"+ DEPT_EXTENSION + r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #5\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*(?:Decreto\\s*Legislativo|Resolu[cç][aã]o)\\s*\" +\n",
    "        f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #6\n",
    "        r\"(?<=^[^\\(]{,500}?)(Mensagem\\s*\" + DATE_AND_ID + \"\\s*[0-9][0-9\\s]*)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #7\n",
    "        r\"((?:SUBSTITUTIV[AO]\\s*[ÁÀA]\\s*)?\" +\n",
    "        r\"Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #8, 9, 10\n",
    "        regex.compile(\n",
    "            r\"(\" +\n",
    "            f\"{LARGER_BLOCKS_HIERARCHY[i]}\" + r\"\\s*\" + f\"(?:{VALID_ROMAN_NUM}|[0-9]+)\" +\n",
    "            r\"(?:[-–\\.\\s,\" + UPPERCASE_LETTERS_OR_NUM + r\"])+?\" +\n",
    "            r\"(?:\\s*\" +\n",
    "            MARKER_NOISE_START + r\".{,600}?\" + MARKER_NOISE_END + r\"\\s*\" + f\"{DEBUG_PATTERN}*\" +\n",
    "            r\"\\s*)?\" +\n",
    "            f\"(?={MARKER_VALID}|\" + r\"|\".join(LARGER_BLOCKS_HIERARCHY[i + 1:]) + r\")\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for i in range(len(LARGER_BLOCKS_HIERARCHY) - 1)\n",
    "    ],\n",
    "    regex.compile( #11, Esta lei entra em vigor cento e oitenta dias após a data de sua publicação\n",
    "        r\"(Art.{,10}?Esta\\s*\" +\n",
    "        r\"(?:lei|EC|Emenda\\s*(?:Constitucional|[àaá\\s]*constitui[cç][aã]o)|resolu[cç][aã]o)\\s*\" +\n",
    "        r\"entr[ea]\\s*em\\s*vigor\\s*.{,100}?\\s*(?:data\\s*de\\s*)sua\\s*publica[cç][aã]o\\s*.{,50}?(?:\\.|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "RE_POST_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={pattern})\", regex.IGNORECASE)\n",
    "    for pattern in []\n",
    ")\n",
    "\n",
    "COALESCE_NOISE = regex.compile(\n",
    "    f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*\"\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False, coalesce_noise: bool = True) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(\n",
    "            f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \",\n",
    "            text,\n",
    "            concurrent=True)\n",
    "    \n",
    "    for i, (reg, fun, fun_post) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=True)\n",
    "        \n",
    "        if fun_post is not None:\n",
    "            text = fun_post(text)\n",
    "\n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \" + r\"\\1\" + f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_instance(item, ind, print_preprocessed: bool = False, debug: bool = False, coalesce_noise: bool = True):    \n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug, coalesce_noise=coalesce_noise)\n",
    "    preprocessed_text = preprocessed_text.replace(MARKER_INTENDED_CORRUPTION, \"@\" if debug else \"\")\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(colorama.Fore.WHITE, colorama.Style.DIM, preprocessed_text, colorama.Style.RESET_ALL, sep=\"\")\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            cur_token = tokens.pop(i)\n",
    "            cur_label = labels.pop(i)\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_START]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_END:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_NOISE_END:\n",
    "                # labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            labels[i] = SPECIAL_SYMBOLS[cur_token]\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels:\n",
    "        maybe_erase_pool = []\n",
    "        noise_on = False\n",
    "\n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                labels[i] = labels[i + 1] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                maybe_erase_pool.clear()\n",
    "                continue\n",
    "\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                while maybe_erase_pool:\n",
    "                    ind = maybe_erase_pool.pop()\n",
    "                    labels[ind] = 0\n",
    "\n",
    "            if labels[i] > 0:\n",
    "                maybe_erase_pool.append(i)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                if noise_on:\n",
    "                    labels[i] = 0\n",
    "                else:\n",
    "                    noise_on = True\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                if noise_on:\n",
    "                    noise_on = False\n",
    "                else:\n",
    "                    labels[i] = 0\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                noise_on = False\n",
    "            \n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                labels[i] = 0\n",
    "            \n",
    "        while tokens and tokens[0] in SPECIAL_SYMBOLS:\n",
    "            labels.pop(0)\n",
    "            tokens.pop(0)\n",
    "\n",
    "        while tokens and tokens[-1] in SPECIAL_SYMBOLS:\n",
    "            labels.pop()\n",
    "            tokens.pop()\n",
    "        \n",
    "        if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "            labels[0] = 0\n",
    "    \n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "if DEV_RUN:\n",
    "    auxaux = \"\"\"\n",
    "PROJETO DE LEI N°______, DE 2020.\n",
    "(DOS/AS SRS/AS. ERIKA KOKAY, GLAUBER BRAGA, HELDER SALOMÃO,\n",
    "MARIA DO ROSÁRIO, NILTO TATTO, PAULO FERNANDO DOS SANTOS,\n",
    "PAULO TEIXEIRA e NATÁLIA BONAVIDES)\n",
    "Amplia o prazo para o trabalhador em situação\n",
    "de  rua  requerer  o  auxílio  emergencial  de  que\n",
    "trata  a  Lei  n°  13.982,  de  2020,  até  30  de\n",
    "setembro de 2020, e dá outras providências.\n",
    "                       O CONGRESSO NACIONAL decreta: \n",
    "    Art. 1º O art.2° da lei nº 13.982, de 2 de abril de 2020, passa a vigorar\n",
    "acrescido dos seguintes parágrafos:\n",
    "“Art.2°. .....................................................................................................\n",
    "....................................................................................................................\n",
    "§ 14. O trabalhador que se encontre em situação de rua poderá requerer o\n",
    "auxílio de que trata o caput até 30 de setembro de 2020, garantindo-se àqueles que\n",
    "cumpram cumulativamente os requisitos estabelecidos nos incisos I a VI o pagamento\n",
    "do mesmo número de prestações mensais concedidas aos demais beneficiários.\n",
    "§ 15. O trabalhador que se encontre em situação de rua poderá realizar a\n",
    "autodeclaração na plataforma digital de que trata o § 4º nos equipamentos da assistência\n",
    "social  ou  em  organizações  da  sociedade  civil  sem  fins  lucrativos  credenciadas no\n",
    "conselho  de  assistência  social  local,  sendo  que  não  haverá  restrição  ao  número  de\n",
    "autodeclarações que podem ser feitas em um mesmo aparelho informático ou telefônico\n",
    "de propriedade ou posse desses equipamentos e organizações. \n",
    "§ 16. O poder público, em conjunto com órgãos e entidades vinculados\n",
    "ao Sistema Único de Assistência Social, realizará busca ativa e assistirá os trabalhadores\n",
    "que se encontrem em situação de rua na utilização da plataforma digital de que trata o §\n",
    "4º.” \n",
    "Art. 2º Esta lei entra em vigor na data de sua publicação.\n",
    "\"\"\".replace(\" , \", \", \").replace(\" . \", \". \")\n",
    "\n",
    "res=preprocess_instance({\"text\": auxaux}, -1, True, debug=True, coalesce_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T06:46:31.686812Z",
     "start_time": "2022-03-02T06:45:24.221882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5b320216a3724f28\n",
      "Reusing dataset csv (../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f26fd8e65a480299c6b4110ebd0e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-bb5915d731cb52ba.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-f3969ddb1a6939e3.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-ff0502c9f340dda0.arrow\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START if DEV_RUN else None,\n",
    "    nrows=(DATASET_ROW_END - DATASET_ROW_START + 1) if DEV_RUN else None,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A?\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[\" + UPPERCASE_LETTERS + r\"])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÂÃÀÁ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aãâàá]\\s*o\\s+(?=[\" + UPPERCASE_LETTERS + r\"])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=None if DEV_RUN else \"text\")\n",
    "\n",
    "rerun_tests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T23:10:42.107649Z",
     "start_time": "2022-03-01T23:10:42.102286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 4645}\n"
     ]
    }
   ],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T06:50:13.005461Z",
     "start_time": "2022-03-02T06:50:04.659919Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChosen id:\u001b[39m 4437\n",
      "\n",
      "\u001b[37m\u001b[2mPROJETO DE DECRETO LEGISLATIVO Nº           , DE  2020.\n",
      "(Do Sr. Rogério Correia)\n",
      "Susta  o  Decreto  10.530/2020,  que\n",
      "“Dispõe sobre a qualificação da política\n",
      "de fomento ao setor de atenção primária\n",
      "à  saúde  no  âmbito  do  Programa  de\n",
      "Parcerias  de  Investimentos  da\n",
      "Presidência  da  República,  para  fins  de\n",
      "elaboração de estudos de alternativas de\n",
      "parcerias com a iniciativa privada”. \n",
      "O CONGRESSO NACIONAL decreta:\n",
      "Art. 1º Ficam sustados integralmente os efeitos do Decreto\n",
      "10.530/2020, que “Dispõe sobre a qualificação da política de fomento\n",
      "ao setor  de atenção primária  à  saúde no âmbito do Programa de\n",
      "Parcerias de Investimentos da Presidência da República, para fins de\n",
      "elaboração de estudos de alternativas de parcerias com a iniciativa\n",
      "privada”. \n",
      "Art. 2º Este Decreto Legislativo entra em vigor na data da\n",
      "sua publicação.\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[0m\u001b[97m 1 \u001b[39m PROJETO DE DECRETO LEGISLATIVO Nº , DE 2020 . ( Do Sr. Rogério Correia )\n",
      "\n",
      "\u001b[97m 2 \u001b[39m Susta o Decreto 10.530/2020 , que “ Dispõe sobre a qualificação da política de fomento ao setor de atenção primária à saúde no âmbito do Programa de Parcerias de Investimentos da Presidência da República , para fins de elaboração de estudos de alternativas de parcerias com a iniciativa privada ” .\n",
      "\n",
      "\u001b[97m 3 \u001b[39m O CONGRESSO NACIONAL decreta :\n",
      "\n",
      "\u001b[97m 4 \u001b[39m Art . 1º Ficam sustados integralmente os efeitos do Decreto 10.530/2020 , que “ Dispõe sobre a qualificação da política de fomento ao setor de atenção primária à saúde no âmbito do Programa de Parcerias de Investimentos da Presidência da República , para fins de elaboração de estudos de alternativas de parcerias com a iniciativa privada ” .\n",
      "\n",
      "\u001b[97m 5 \u001b[39m Art . 2º Este Decreto Legislativo entra em vigor na data da sua publicação .\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   4437: 5, 0\n",
      "Is it correct? [y/N]: y\n",
      "Added to test cases.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    id_ = None\n",
    "    \n",
    "    if id_ is not None:\n",
    "        print(tests.TEST_CASES[id_])\n",
    "        tests.print_results(df, id_, print_full_text=True)\n",
    "        # tests.update_test_case(id_, (14, 1))\n",
    "    \n",
    "    if rerun_tests:\n",
    "        try:\n",
    "            tests.run_tests(df[\"train\"][\"labels\"])\n",
    "            rerun_tests = False\n",
    "\n",
    "        except AssertionError as e:\n",
    "            raise AssertionError from e\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    document_idx = min(2466, df[\"train\"].num_rows - 1)\n",
    "    while tests.test_case_exists(document_idx):\n",
    "        document_idx = random.randint(0, df[\"train\"].num_rows)\n",
    "\n",
    "    print(colorama.Fore.YELLOW + \"Chosen id:\" + colorama.Fore.RESET, document_idx, end=\"\\n\\n\")\n",
    "\n",
    "    expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "    print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "    inp = input()\n",
    "    if inp == \"y\":\n",
    "        tests.update_test_case(document_idx, expected_test_case_values)\n",
    "        print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T06:50:16.672691Z",
     "start_time": "2022-03-02T06:50:16.665760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 20 test cases at './test_cases/110001_120000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
