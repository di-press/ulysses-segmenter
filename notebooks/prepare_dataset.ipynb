{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T14:58:33.912864Z",
     "start_time": "2022-02-27T14:58:33.855618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "Loaded 30 test cases from './test_cases/30001_60000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "DEV_RUN = True\n",
    "\n",
    "\n",
    "random.seed(72)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "DATASET_ROW_START = None\n",
    "DATASET_ROW_END = None\n",
    "if DEV_RUN:\n",
    "    TESTS_DIR = \"test_cases\"\n",
    "    DATASET_ROW_START = 30001\n",
    "    DATASET_ROW_END = 60000\n",
    "    TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "    tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T14:41:21.498490Z",
     "start_time": "2022-02-27T14:41:16.105531Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=DEV_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:24:16.609479Z",
     "start_time": "2022-02-27T20:24:16.212784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m ✓ 1_PRE_POS COMISSÃO DE FINANÇAS E TRIBUTAÇÃO  ✓ 1_PRE_POS  ✓ 5_PRE_POS PROJETO DE LEI COMPLEMENTAR N° 144, DE 2004 (PLP nº 336, de 2006, apensado) ✓ 5_PRE_POS  Dispõe sobre o tempo máximo de espera para atendimento nos estabelecimentos bancários.  ✓ 23_SPECIAL Autora: Deputada ALICE PORTUGAL ✓ 23_SPECIAL  Relator: Deputado JOSÉ PIMENTEL SUBSTITUTIVO DO RELATOR\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DEBUG_PATTERN = \"(?:\\s*[0-9]{1,3}_[A-Z]{1,30}\\s*)\"\n",
    "\n",
    "\n",
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(r\"\\*([\\sA-Z0-9]+)\\*\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(.{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_CAMARA_REPEATED = regex.compile(\n",
    "        r\"(?:(C[AÂ]MARA\\s*)(DOS\\s*)(DEPUTADOS[\\s0-9]*(?!\\s*[-–\\.\\)])))\",\n",
    "    )\n",
    "    RE_SALA_DAS_SESSOES_CODE = regex.compile(\n",
    "        r\"(?<=Sala\\s*das\\s*sess[oõ]es\\s*.{,150}?)([0-9]{1,5}\\s*_\\s*(?:\" +\n",
    "        MARKER_NOISE_START +\n",
    "        r\")?\\s*[0-9]{1,5})\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = sorted(set(pseudo_patterns))\n",
    "        \n",
    "        for pseudo_pattern in pseudo_patterns:\n",
    "            pattern = list(cls.RE_BLANK_SPACES.sub(\"\", pseudo_pattern))\n",
    "            pattern.append(\"\")\n",
    "            pattern.insert(0, \"\")\n",
    "            pattern = (r\"(?:\\s*(?:\" + MARKER_NOISE_START + r\")?\\s*\" + DEBUG_PATTERN + r\"*\\s*)\").join(pattern)\n",
    "            pattern = (\n",
    "                r\"(?:(\\s*C[AÂ]MARA\\s*)(DOS\\s*)(DEPUTADOS\\s*)([0-9][\\s0-9]*)?)?\" +\n",
    "                r\"(\\*\" +\n",
    "                pattern +\n",
    "                r\"\\*\\s*\" +\n",
    "                r\"(?:\" + MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*)?\\s*\" +\n",
    "                f\"(?:{pattern})?\" +\n",
    "                r\")\" +\n",
    "                r\"(?:(\\s*C[AÂ]MARA\\s*)(DOS\\s*)(DEPUTADOS))?\"\n",
    "            )\n",
    "            \n",
    "            mod_subpattern = (\n",
    "                f\" {MARKER_NOISE_START} \" +\n",
    "                MARKER_INTENDED_CORRUPTION.join([r\"\\1\", r\"\\2\", r\"\\3\", r\"\\4\"]) +\n",
    "                subpattern.replace(r\"\\1\", r\"\\5\") +\n",
    "                MARKER_INTENDED_CORRUPTION.join([r\"\\6\", r\"\\7\", r\"\\8\"]) +\n",
    "                \"\"\n",
    "            )\n",
    "            \n",
    "            text = regex.sub(pattern, mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara(cls, subpattern, text):\n",
    "        occurrences = cls.RE_CAMARA_REPEATED.findall(text)\n",
    "        \n",
    "        if len(occurrences) <= 2:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_REPEATED.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        text = cls.RE_SALA_DAS_SESSOES_CODE.sub(subpattern, text)\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "VALID_ROMAN_NUM = r\"M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3})\"\n",
    "NRO_SMALL = r\"[nN]\\s*[oO0º°\\.]{1,3}\"\n",
    "NRO = r\"(?:[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[oO0º°]|\" + NRO_SMALL + r\"\\s*(?=[0-9]))\"\n",
    "QUOTES = r\"”“”\\\"'‘\"\n",
    "UPPERCASE_LETTERS = r\"ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z\"\n",
    "UPPERCASE_LETTERS_OR_NUM = UPPERCASE_LETTERS + r\"0-9\"\n",
    "\n",
    "ANNEX = r\"(?:Anexo\\s*\" + f\"(?:{VALID_ROMAN_NUM})\" + r\")\"\n",
    "CABINET = r\"(?:Gab(?:inete)?[\\.\\s]*[0-9]{1,5})\"\n",
    "NOISE_ANNEX_CABINET = (\n",
    "    r\"C[âa]mara\\s*dos\\s*Deputados\\s*.{,20}?\\s*\" +\n",
    "    r\"(\" +\n",
    "    ANNEX + r\"\\s*.{,20}?\\s*\" + CABINET +\n",
    "    r\"|\" +\n",
    "    CABINET + r\"\\s*.{,20}?\\s*\" + ANNEX +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "\n",
    "class AgreementList:\n",
    "    ITEMS = (\n",
    "        r\"(\\s*(?:\" +\n",
    "        r\"(?:[ÓO]rg[aã]o\\s*)?(?:Superior|[cC]oncedente|[cC]onve(?:nente|niada))|\" +\n",
    "        NRO + r\"\\s*(?:SIAFI|Original|Do\\s*conv[eê]nio)|\" +\n",
    "        r\"Valor\\s*(?:do\\s*conv[eê]nio)?|\" +\n",
    "        r\"(?:In[ií]cio|Fim)\\s*(?:d[ea]\\s*vig[eê]ncia)?|\" +\n",
    "        r\"Objeto|\" +\n",
    "        r\"Conv[eê]nio|\" +\n",
    "        r\"Processo|\" +\n",
    "        r\"Total\\s*de\\s*itens\\s*Licitados|\" +\n",
    "        r\"Fundamento\\s*legal|\"+\n",
    "        r\"Contratada|\" +\n",
    "        r\"Questionamentos|\" +\n",
    "        r\"Justificativa\"\n",
    "        r\")\\s*)\"\n",
    "    )\n",
    "    RE_ITEMS = regex.compile(ITEMS + r\"(\\s*:)\", regex.IGNORECASE)\n",
    "    REG_GET_LIST = regex.compile(\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + ITEMS + r\":\\s*[^:]{,150}?){2,10}\" +\n",
    "        ITEMS + r\":\\s*[^:]{,150}\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    @classmethod\n",
    "    def sub(cls, subpattern, text: str, *args, **kwargs):\n",
    "        re_match = cls.REG_GET_LIST.search(text)\n",
    "        if re_match is None:\n",
    "            return text\n",
    "        s_start, s_end = re_match.span()\n",
    "        text_slice = text[s_start:s_end]\n",
    "        subpattern = subpattern.replace(r\"\\1\", r\"\\1\" + f\" {MARKER_INTENDED_CORRUPTION} \" + r\"\\2\")\n",
    "        text_slice = cls.RE_ITEMS.sub(\n",
    "            subpattern,\n",
    "            text_slice,\n",
    "        )\n",
    "        text = f\"{text[:s_start]}{text_slice}{text[s_end:]}\"\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "COMMISSION_LIST = (r\"\"\"\n",
    "    (?:\n",
    "    AGRICULTURA[,\\s]*PECU[AÁ]RIA[,\\s]*ABASTECIMENTO[E\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA[,\\s]*COMUNICA[CÇ][AÃ]O[E\\s]*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*DE\\s*CIDADANIA|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*DO\\s*CONSUMIDOR|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO[,\\s]*IND[UÚ]STRIA[,\\s]*COM[EÉ]RCIO[E\\s]*SERVI[CÇ]OS|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS[E\\s]*MINORIAS|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS[E\\s]*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA[E\\s]*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL[,\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*REGIONAL[E\\s]*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    MEIO\\s*AMBIENTE[E\\s]*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS[E\\s]*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES[E\\s]*DE\\s*DEFESA\\s*NACIONAL|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL[E\\s]*FAMÍLIA|\n",
    "    TRABALHO[,\\s]*ADMINISTRA[CÇ][AÃ]O[E\\s]*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "COMMISSIONS = (\n",
    "    r\"COMISS[AÃ]O\\s*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"(?:D[EOA]S?|[,;\\s]*E|[;,]\\s*E?)+\\s*\" +\n",
    "    COMMISSION_LIST +\n",
    "    r\"\\s*)+\"\n",
    ")\n",
    "\n",
    "DOC_ABBVR = r\"(?:\" + \"|\".join((\n",
    "    \"COM\", \"DCR\", \"DEN\", \"DTQ\", \"DVS\", \"DVT\", \"EMC\", \"EMD\", \"EML\", \"LDO\", \"EMO\",\n",
    "    \"EMP\", \"EMR\", \"ERD\", \"ESB\", \"EXP\", \"INA\", \"INC\", \"MPV\", \"MSC\", \"PAR\", \"PDC\",\n",
    "    \"PEC\", \"PET\", \"PFC\", \"PLP\", \"PLV\", \"PRC\", \"PRF\", \"PRN\", \"PRO\", \"RCP\", \"REC\",\n",
    "    \"REL\", \"REM\", \"REP\", \"REQ\", \"RIC\", \"RPR\", \"SBE\", \"SBT\", \"SDL\", \"LDO\", \"SIT\",\n",
    "    \"TCU\", \"SOA\", \"STF\", \"SUG\", \"SUM\", \"CCJ\", \"TER\", \"TVR\", \"VTS\",\n",
    ")) + r\")\"\n",
    "\n",
    "\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:[-–º°0-9A-Z]+|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+)(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\so0º°]*:\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!Art(?:igo)?s?\\s?\\.?\\s?)\\(?\\s+[0-9]{1,2}[\\s0oOº°]*(?:[-–\\)]|\\.(?![0-9]))\",\n",
    "    r\"(?<!Art(?:igo)?s?\\s?\\.?\\s?|\" + NRO_SMALL + r\"|\\$)\\s+[0-9]{1,2}\\s*(?:\\.[0-9]+){1,2}(?![\\.0-9]*,)\",\n",
    ")\n",
    "\n",
    "MONTHS = \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    ")).upper()\n",
    "\n",
    "DATE = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[0-9]{,2}\\s*(?:de|em)\\s*(?:\" + MONTHS + r\")\\s*(?:de|em)\\s*[0-9]{4}\"\n",
    ")\n",
    "\n",
    "DATE_OR_UNDERSCORES = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,\\._0-9\\s]*){1,3}[\\._0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[\\._0-9]{,2}\\s*(?:de|em)\\s*(?:\" + MONTHS + r\"|_+)\\s*(?:de|em)\\s*[\\._0-9]{4}\"\n",
    ")\n",
    "\n",
    "UPPERCASE_DATE_OR_UNDERSCORES = DATE_OR_UNDERSCORES.replace(\"em\", \"EM\").replace(\"de\", \"DE\")\n",
    "\n",
    "EOF = r\".{,300}$\"\n",
    "\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    EOF +\n",
    "    r\"|\" +\n",
    "    DATE + \n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"030|Daniel|[eE]ss|Jaa|ac[fgp]|afpa|cmrv|(da[-–])?conle|[Cc]rps|\" +\n",
    "    r\"dennn?er|dpsl?|drb|epo|faa|‘?[Gg]ab|gsl|jaa|jbs|kvp|lgl|mlcl?|\" +\n",
    "    r\"mm|pnf|rpb|tksa|[Vv][Pp][Ll][cf]?|wgl\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_CORE = r\"(?:pls|mpv|plc|pec|pds|plv|prn|plp|pdl|tema)\"\n",
    "\n",
    "RE_DOC_CODE_SUFFIX = (\n",
    "    r\"(?:(?:\"\n",
    "    r\"c(?:ompleme?ntar)?|eme(?:nda)?s?|\" +\n",
    "    r\"rev(?:is)?|sub(?:st\\.?(?:itutivo)?)?|sust|tt?\" +\n",
    "    r\")\\s*?)*\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_FULL = (\n",
    "    r\"(\" +\n",
    "    r\"(?<=\\s)\" +\n",
    "    RE_DOC_CODE_PREFIX +\n",
    "    \"/\" +\n",
    "    RE_DOC_CODE_CORE +\n",
    "    \"(?:[-–0-9]+)\" +\n",
    "    RE_DOC_CODE_SUFFIX +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"Sala\\s*d[ea]s?\\s*(?:sess|comiss|reuni)(?:[õo]es|[ãa]o)\" + EOF_OR_DATE,\n",
    "    r\"Senado\\s*Federal\\s*,\" + EOF_OR_DATE,\n",
    "    r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\" + EOF_OR_DATE,\n",
    "    r\"Bras[ií]lia\\s*,\\s*(?:\" + DATE_OR_UNDERSCORES + \")\\s*\",\n",
    "    r\"•\",\n",
    "    r\"As?\\s*mesas?\\s*da\\s*c[aâ]mara\\s*dos\\s*deputados[^:]{,300}?:\",\n",
    "    r\"Atenciosamente\\s*,\",\n",
    ")\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "    regex.compile(\n",
    "        r\"((?:(?:PL|PDL|PEC)\\s*n[\\.o\\sº]*[\\d\\s]+/[\\s\\d]+)?+\\s*\"\n",
    "        r\"A\\s*p\\s*r\\s*e\\s*s\\s*e\\s*n\\s*t\\s*a\\s*[cç]\\s*[aã]\\s*o\\s*:\"\n",
    "        r\"(?:\\s*\\d\\s*){2}/(?:\\s*\\d\\s*){2}/(?:\\s*\\d\\s*){6}:(?:\\s*\\d){2})\",\n",
    "        regex.IGNORECASE | regex.MULTILINE,\n",
    "    ),\n",
    "    regex.compile(f\"({NOISE_ANNEX_CABINET})\", regex.IGNORECASE),\n",
    "    regex.compile(f\"(?<!{NRO}[_\\s\\.0-9]*)\" + r\"([0-9]{11,})\"),\n",
    "    regex.compile(r\"(_{9,}\\s*)+\"),\n",
    "    regex.compile(r\"(^[\\s0-9]+|(?:[0-9]+_+)?[\\s0-9]+$)\"),\n",
    "    regex.compile(\n",
    "        r\"((?:E[-–\\s]*mails?[\\s:]*)?[-–a-zA-Z0-9\\._]{,40}\\s*@\\s*(?:[a-zA-Z]{1,15}\\.?){1,3})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(r\"(IN\\s*C\\s*\" + NRO + r\"\\s*[\\s0-9]{3,8}/\\s*[\\s0-9]{4,8})\", regex.IGNORECASE),\n",
    "    *[\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, r\"cap[ií]tulo\", r\"t[íi]tulo\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC)\\s*\\)\\s*|\" +\n",
    "    f\"[{QUOTES}])\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    f\"(?:[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN +\n",
    "    r\"*.{,300}?\" +\n",
    "    MARKER_NOISE_END + r\"\\s*\" + DEBUG_PATTERN +\n",
    "    f\"*[\\s{MARKER_INTENDED_CORRUPTION}]*)\"\n",
    ")\n",
    "\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in (\n",
    "        *BASE_LEGAL_ITEMS,\n",
    "        *EXTRA_LEGAL_ITEMS,\n",
    "        r\"D[eê][-–]se\\s*ao\\s*Projeto\\s*a\\s*seguinte\\s*reda[cç][aã]o\\s*:\",\n",
    "    )\n",
    ")\n",
    "\n",
    "ADDITIONAL_TITLES = (\n",
    "    r\"(?:\" \n",
    "    r\"Ju[ií]za?s?|M[\\.\\s]*Ma?[\\s\\.]*|\" +\n",
    "    r\"Doutora?s?|Dra?s?[\\s\\.]*|\" +\n",
    "    r\"Professora?s?|Profa?s?[\\s\\.]*|\" +\n",
    "    r\"Advogad[ao]|Adv[\\s\\.]*\"\n",
    "    r\")*\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:Sra?s?|Senhora?s?)?[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"(?:Sra?s?|Senhora?s?)[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)?\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"(?:MENSAGEM|\" + DOC_ABBVR + \")\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" +\n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(]{,100}\\(\\s*(?:D[oa]s?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}\\)]\" + r\"{1,100})?\\)\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\".{,100}?D[oa]s?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._0-9]+|\" +\n",
    "    f\"(?:{NRO}\" + r\"[_\\s\\.0-9]*)?\\s*(?:\" + UPPERCASE_DATE_OR_UNDERSCORES + r\")|\" +\n",
    "    NRO + r\"[_\\s\\.0-9]*\" +\n",
    "    r\"(?:[^,]{,30}?[,\\.]+\\s*(?:DE\\s*)+?[\\._0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "# DATE\n",
    "\n",
    "fn_lambda_single = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" \n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "fn_lambda_quad = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \" + r\"\\4\" + f\" {symb} {deb} \"\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY = (\n",
    "    r\"(?:Excelent[ií]ssim[oa]|Ex\\.?m[ao]\\s*\\.?|(?:Vossa|V\\s*\\.)\\*(?:excel[eê]ncia|Exa?\\s*\\.\\s*ª?))?\" +\n",
    "    r\"\\s*(?:Senhora?|Sra?)[\\.\\s]*\" +\n",
    "    r\"\\s*(?:Primeir[oa]|Vice|[-–\\s])*\" +\n",
    "    r\"(?:Pres(?:id(?:ente)?)?|Min(?:istr[oa])?|Advogad[ao]\\s*Geral\\s*da\\s*Uni[aã]o|Secret[aá]ri[oa])\" +\n",
    "    r\"[^,:]{,75}?[,:]\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<=(?<!Exm[ao]|Exa|Sra?)\\s*\\..{,10}?|\\).{,10}?)\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY + \"|\" +\n",
    "    r\"(?:(?<=\\.\\s*)Requeiro|Solicito)\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile( #0\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,50}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #1\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #2\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        DEPT_EXTENSION_A +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #3\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #4\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #5\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #6\n",
    "        r\"(MEDIDA\\s*PROVIS[ÓO]RIA.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,1200}?)([OA]\\s*President[ea]\\s*da\\s*rep[úu]blica[^:]+?com\\s*for[cç]a\\s*de\\s*lei\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (DetectRecurrentNoise, #7\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #8\n",
    "        r\"([:;\" + QUOTES + r\"\\?])(\\s{,10}[-–])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #9\n",
    "        r\"((?<!S\\s*\\.\\s*A\\s*)\\.)(\\s{,10}[-–])(?=\\s*[\" + UPPERCASE_LETTERS + \"])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #10\n",
    "        r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"),\n",
    "     lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #11\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double, None),\n",
    "    (regex.compile( #12\n",
    "        r\"(TVR\\s*\" + DATE_AND_ID + DEPT_EXTENSION + \")\"\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #13\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR)?|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)?\" +\n",
    "        f\"(?!{DEPT_EXTENSION})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #14\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR)?|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)\" +\n",
    "        f\"(?:{UPPERCASE_DATE_OR_UNDERSCORES})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #15\n",
    "        r\"(?<=[\" + UPPERCASE_LETTERS + \"]{3,}\\s+)([0-9]{1,2}\\s*\\.\\s+[0-9]+)\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None\n",
    "    ),\n",
    "    (regex.compile( #16\n",
    "        r\"(?<=\\s)((?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s]*:|ou)\\s*)\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2}\\s*)(\\)))?(\\s*[0-9]{4}\\s*[-–\\.\\s]?\\s*[0-9]{4})\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \",\n",
    "    None,\n",
    "    ),\n",
    "    (regex.compile( #17\n",
    "        r\"(?<=\\s)(Bras[ií]lia[-–/\\s]*DF.{,10}?)?(CEP[\\.\\s:]*[0-9]{2}[\\s\\.]*[0-9]{3}\\s*[-–]\\s*[0-9]{3})(.{,10}?Bras[ií]lia[-–/\\s]*DF)?\"),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\" + f\" {symb_end} {deb} \",\n",
    "    None,\n",
    "    ),\n",
    "    (regex.compile( #18\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #19\n",
    "        r\"(OF[IÍ]CIO\\s*\" + NRO + r\".{,110}?\\s*)\" +\n",
    "        r\"((?:Bras[ií]lia|Senado\\s*Federal)?[,\\s]*(?:\" + DATE_OR_UNDERSCORES + r\")[\\.\\s]*)\" +\n",
    "        r\"(.{,300}?\\s*)\" +\n",
    "        r\"(Assunto\\s*:\\s*.{,300}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE\n",
    "    ),\n",
    "    fn_lambda_quad, None),\n",
    "    (regex.compile( #20\n",
    "        r\"(Atenciosamente\\s*),\" +\n",
    "        r\"(\\s*.{,250}?\" +\n",
    "        RE_DOC_CODE_FULL +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\",\\2\" + f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #21\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,10}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        r\"([ÀÁA]\\s*sua\\s*excel[eê]ncia.{,100}?)\" +\n",
    "        r\"(?=(?:\" + REQUEST_PRESIDENT_OR_MINISTRY + \"[,\\s]*)?(?:Requeiro|Solicito))\", regex.IGNORECASE),\n",
    "     fn_lambda_triple, None),\n",
    "    (regex.compile( # 22\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*[^\" + UPPERCASE_LETTERS + \"]\\s*)\" +\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)\",\n",
    "        regex.IGNORECASE),\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #23\n",
    "        r\"(Autora?\\s*:\\s*.{,200}?)(\\s*Relatora?\\s*:)\", regex.IGNORECASE),\n",
    "     lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #24\n",
    "        r\"(?<=(?:Relatora?|Autora?)\\s*:.{,200}?\\s+)(\" + VALID_ROMAN_NUM + r\"[-–\\s]+RELAT[OÓ]RIO\\s+)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (AgreementList, #25\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (regex.compile(r\"(?=Reiterando\\s*os\\s*votos\\s*de\\s*apre[cç]o\\s*e\\s*considera[cç][aã]o)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    ")\n",
    "\n",
    "\n",
    "RE_PRE_POST_BLOCKS = (\n",
    "    regex.compile(\n",
    "        r\"(ACORDO\\s*DE\\s*[-,\"\n",
    "        + UPPERCASE_LETTERS_OR_NUM\n",
    "        + r\"\\s]+)(?=(?:[OA]\\s+)?[\"\n",
    "        + UPPERCASE_LETTERS\n",
    "        + r\"][a-z])\"\n",
    "    ),\n",
    "    regex.compile(r\"(?<!\\(.{,50}?)(\" + COMMISSIONS + \")\"),\n",
    "    regex.compile(r\"(O\\s*Congresso\\s*Nacional\\s*decreta\\s*:)\", regex.IGNORECASE),\n",
    "    regex.compile(r\"(C[ÂA]MARA\\s*DOS\\s*DEPUTADOS|CONGRESSO\\s*NACIONAL)(?!\\s*[dD][eE][cC][rR][eE][tT][aA])\"),\n",
    "    regex.compile(r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*decreta\\s*:)\", regex.IGNORECASE),\n",
    "    regex.compile(\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Lei\\s*(?:\\s*COMPLEMENTAR)?\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" + r\"\\s*\"+ DEPT_EXTENSION + r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*(?:Decreto\\s*Legislativo|Resolu[cç][aã]o)\\s*\" +\n",
    "        f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(?<=^[^\\(]{,500}?)(Mensagem\\s*\" + DATE_AND_ID + \"\\s*[0-9][0-9\\s]*)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"((?:SUBSTITUTIV[AO]\\s*[ÁÀA]\\s*)?\" +\n",
    "        r\"Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(cap[ií]tulo\\s*\" + f\"(?:{VALID_ROMAN_NUM})\" +\n",
    "        r\"(?:[-–\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]|\" + \n",
    "        f\"{MARKER_NOISE_END}|{MARKER_NOISE_START}\" +\n",
    "        r\")+?\" +\n",
    "        f\"(?=(?:{MARKER_VALID}|Art)))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(t[ií]tulo\\s*\" + f\"(?:{VALID_ROMAN_NUM})\" +\n",
    "        r\"(?:[-–\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]|\" + \n",
    "        f\"{MARKER_NOISE_END}|{MARKER_NOISE_START}\" +\n",
    "        r\")+?\" +\n",
    "        f\"(?=(?:{MARKER_VALID}|cap[íi]tulo)))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "RE_POST_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={pattern})\", regex.IGNORECASE)\n",
    "    for pattern in []\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \", text, concurrent=True)\n",
    "    \n",
    "    for i, (reg, fun, fun_post) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=True)\n",
    "        \n",
    "        if fun_post is not None:\n",
    "            text = fun_post(text)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \" + r\"\\1\" + f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_instance(item, ind, print_preprocessed: bool = False, debug: bool = False):    \n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug)\n",
    "    preprocessed_text = preprocessed_text.replace(MARKER_INTENDED_CORRUPTION, \"@\" if debug else \"\")\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(colorama.Fore.WHITE, colorama.Style.DIM, preprocessed_text, colorama.Style.RESET_ALL, sep=\"\")\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            cur_token = tokens.pop(i)\n",
    "            cur_label = labels.pop(i)\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_START]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_END:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = 0\n",
    "            else:\n",
    "                labels[i] = SPECIAL_SYMBOLS[cur_token]\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels:\n",
    "        if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "            labels[0] = 0\n",
    "\n",
    "        if tokens[-1] in SPECIAL_SYMBOLS:\n",
    "            labels.pop()\n",
    "            tokens.pop()\n",
    "\n",
    "        maybe_erase_pool = []\n",
    "        noise_on = False\n",
    "\n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                labels[i] = labels[i + 1] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                maybe_erase_pool.clear()\n",
    "                continue\n",
    "\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                while maybe_erase_pool:\n",
    "                    ind = maybe_erase_pool.pop()\n",
    "                    labels[ind] = 0\n",
    "\n",
    "            if labels[i] > 0:\n",
    "                maybe_erase_pool.append(i)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                if noise_on:\n",
    "                    labels[i] = 0\n",
    "                else:\n",
    "                    noise_on = True\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                if noise_on:\n",
    "                    noise_on = False\n",
    "                else:\n",
    "                    labels[i] = 0\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                noise_on = False\n",
    "            \n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "if DEV_RUN:\n",
    "    auxaux = \"\"\"\n",
    "COMISSÃO DE FINANÇAS E TRIBUTAÇÃO \n",
    " \n",
    "  \n",
    "PROJETO DE LEI COMPLEMENTAR N° 144, DE 2004 \n",
    "(PLP nº 336, de 2006, apensado) \n",
    " \n",
    " \n",
    "Dispõe sobre o tempo máximo de \n",
    "espera para atendimento nos \n",
    "estabelecimentos bancários. \n",
    " \n",
    " \n",
    "Autora: Deputada ALICE PORTUGAL  \n",
    "Relator: Deputado JOSÉ PIMENTEL  \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "SUBSTITUTIVO DO RELATOR \n",
    "\"\"\".replace(\" , \", \", \").replace(\" . \", \". \")\n",
    "    try:\n",
    "        _=preprocess_instance({\"text\": auxaux}, -1, True, True)\n",
    "    except NameError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:27:01.819522Z",
     "start_time": "2022-02-27T20:24:53.590385Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-394a116aec9ab689\n",
      "Reusing dataset csv (../cache/datasets/csv/default-394a116aec9ab689/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6a537466f44db2914b328a2783c70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-394a116aec9ab689/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-ddc105094903137f.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-394a116aec9ab689/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-0ce287bca6262ac8.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-394a116aec9ab689/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-51ea5e0c95e108dc.arrow\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START if DEV_RUN else None,\n",
    "    nrows=(DATASET_ROW_END - DATASET_ROW_START + 1) if DEV_RUN else None,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[A-Z])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÃ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aã]\\s*o\\s+(?=[A-Z])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=None if DEV_RUN else \"text\")\n",
    "\n",
    "rerun_tests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T15:01:20.192328Z",
     "start_time": "2022-02-27T15:01:20.188383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 29991}\n"
     ]
    }
   ],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:30:38.017516Z",
     "start_time": "2022-02-27T20:30:33.840818Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 0)\n",
      "\u001b[37m\u001b[2mPROJETO DE LEI No           , DE 2011 \n",
      "(Do Sr. ROBERTO SANTIAGO) \n",
      "Dispõe sobre a vedação na \n",
      "comercialização de alimentos e produtos em \n",
      "geral destinados ao consumo e uso por \n",
      "crianças, a oferta de brinquedos, brinde ou \n",
      "prêmio a título de bonificação. \n",
      "O Congresso Nacional decreta: \n",
      "Art. 1º Esta Lei dispõe sobre a vedação, na promoção e \n",
      "na comercialização de alimentos e de produtos em geral destinados ao \n",
      "consumo e uso por crianças, a oferta de brinquedos, brinde ou prêmio a título \n",
      "de bonificação, operação também conhecida como venda casada.  \n",
      "Art. 2º Fica vedada, na promoção e na comercialização \n",
      "de alimentos e de produtos em geral destinados ao consumo e uso por \n",
      "crianças, a oferta conjunta de brinquedos, brinde, prêmio ou congêneres a \n",
      "título de bonificação.  \n",
      "Parágrafo único. A vedação de que trata o caput deste \n",
      "artigo aplica-se também a todos os alimentos e produtos em geral que, embora \n",
      "não destinados especificamente ao consumo e uso por crianças, de qualquer \n",
      "forma alcancem prioritariamente esse grupo populacional. \n",
      "Art. 3º A propaganda de alimentos para crianças, por \n",
      "qualquer meio de comunicação, deve se sujeitar ao parecer de nutricionista \n",
      "devidamente registrado no órgão regulamentador da profissão. \n",
      "Parágrafo único. O nome e número de registro \n",
      "profissional do nutricionista devem ser incluídos, em corpo menor, em toda \n",
      "propaganda impressa. \n",
      "Art. 4º Para os efeitos desta Lei considera-se como \n",
      "criança, a pessoa até doze anos de idade incompletos, de acordo com o que \n",
      "dispõe a Lei nº 8.069, de 13 de julho de 1990.   \n",
      "Art. 5º O descumprimento do disposto nesta Lei sujeitará \n",
      "os infratores às penalidades previstas na Lei n.º 8.078, de 11 de setembro de \n",
      "1990. \n",
      "Art. 6º Esta Lei entra em vigor 90 (noventa) dias após a \n",
      "data de sua publicação.\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[0m\u001b[97m 1 \u001b[39m PROJETO DE LEI No , DE 2011 ( Do Sr. ROBERTO SANTIAGO )\n",
      "\n",
      "\u001b[97m 2 \u001b[39m Dispõe sobre a vedação na comercialização de alimentos e produtos em geral destinados ao consumo e uso por crianças , a oferta de brinquedos , brinde ou prêmio a título de bonificação .\n",
      "\n",
      "\u001b[97m 3 \u001b[39m O Congresso Nacional decreta :\n",
      "\n",
      "\u001b[97m 4 \u001b[39m Art . 1º Esta Lei dispõe sobre a vedação , na promoção e na comercialização de alimentos e de produtos em geral destinados ao consumo e uso por crianças , a oferta de brinquedos , brinde ou prêmio a título de bonificação , operação também conhecida como venda casada .\n",
      "\n",
      "\u001b[97m 5 \u001b[39m Art . 2º Fica vedada , na promoção e na comercialização de alimentos e de produtos em geral destinados ao consumo e uso por crianças , a oferta conjunta de brinquedos , brinde , prêmio ou congêneres a título de bonificação .\n",
      "\n",
      "\u001b[97m 6 \u001b[39m Parágrafo único . A vedação de que trata o caput deste artigo aplica-se também a todos os alimentos e produtos em geral que , embora não destinados especificamente ao consumo e uso por crianças , de qualquer forma alcancem prioritariamente esse grupo populacional .\n",
      "\n",
      "\u001b[97m 7 \u001b[39m Art . 3º A propaganda de alimentos para crianças , por qualquer meio de comunicação , deve se sujeitar ao parecer de nutricionista devidamente registrado no órgão regulamentador da profissão .\n",
      "\n",
      "\u001b[97m 8 \u001b[39m Parágrafo único . O nome e número de registro profissional do nutricionista devem ser incluídos , em corpo menor , em toda propaganda impressa .\n",
      "\n",
      "\u001b[97m 9 \u001b[39m Art . 4º Para os efeitos desta Lei considera-se como criança , a pessoa até doze anos de idade incompletos , de acordo com o que dispõe a Lei nº 8.069 , de 13 de julho de 1990 .\n",
      "\n",
      "\u001b[97m 10 \u001b[39m Art . 5º O descumprimento do disposto nesta Lei sujeitará os infratores às penalidades previstas na Lei n.º 8.078 , de 11 de setembro de 1990 .\n",
      "\n",
      "\u001b[97m 11 \u001b[39m Art . 6º Esta Lei entra em vigor 90 ( noventa ) dias após a data de sua publicação .\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   25329: 11, 0\n",
      "Correct proportion: 93.33% (28 of 30)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mtests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     rerun_tests \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/nvme/segmentador/notebooks/tests/test_data_labeling_regex.py:51\u001b[0m, in \u001b[0;36mrun_tests\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrect proportion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100.\u001b[39m \u001b[38;5;241m*\u001b[39m correct_prop\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_tests\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskipped\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tests skipped.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m correct \u001b[38;5;241m==\u001b[39m n_tests \u001b[38;5;241m-\u001b[39m skipped, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(incorrect_cases_inds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Incorrect: 15907, 23943",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         rerun_tests \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m document_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m6426\u001b[39m, df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    # 25329\n",
    "    id_ = 25329\n",
    "    \n",
    "    if id_ is not None:\n",
    "        print(tests.TEST_CASES[id_])\n",
    "        tests.print_results(df, id_, print_full_text=True)\n",
    "        \n",
    "    tests.update_test_case(id_, (11, 0))\n",
    "    \n",
    "    if rerun_tests:\n",
    "        try:\n",
    "            tests.run_tests(df[\"train\"][\"labels\"])\n",
    "            rerun_tests = False\n",
    "\n",
    "        except AssertionError as e:\n",
    "            raise AssertionError from e\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    document_idx = min(6426, df[\"train\"].num_rows - 1)\n",
    "    while tests.test_case_exists(document_idx):\n",
    "        document_idx = random.randint(0, 1 + df[\"train\"].num_rows)\n",
    "\n",
    "    print(colorama.Fore.YELLOW + \"Chosen id:\" + colorama.Fore.RESET, document_idx, end=\"\\n\\n\")\n",
    "\n",
    "    expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "    print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "    inp = input()\n",
    "    if inp == \"y\":\n",
    "        tests.update_test_case(document_idx, expected_test_case_values)\n",
    "        print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:30:46.511005Z",
     "start_time": "2022-02-27T20:30:46.470936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 30 test cases at './test_cases/30001_60000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
