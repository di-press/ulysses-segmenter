{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T20:44:53.492371Z",
     "start_time": "2022-03-02T20:44:53.447681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "Loaded 19 test cases from './test_cases/0_30000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "DEV_RUN = True\n",
    "\n",
    "\n",
    "random.seed(499)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "DATASET_ROW_START = None\n",
    "DATASET_ROW_END = None\n",
    "if DEV_RUN:\n",
    "    TESTS_DIR = \"test_cases\"\n",
    "    DATASET_ROW_START = 0\n",
    "    DATASET_ROW_END = 30000\n",
    "    TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "    tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T15:35:03.810069Z",
     "start_time": "2022-03-02T15:34:58.381937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=DEV_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T20:35:13.992073Z",
     "start_time": "2022-03-02T20:35:13.818586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m ❌s__ 4_NOISE *  C D2 05 04 85 21 30 0 *  C D205 0 4 85 2130 0  Le xE di tD oc um en to e le tr ôn ic o as sin ad o po r L oe st er T ru tis ( P SL /M S ), a tr av és d o po nt o SD R_ 56 43 9, na fo rm a do a rt. 1 02, § 1 º, d o RI CD c /c o a rt. 2 º, d o At o da M es a n. 8 0 de 2 01 6.  PL n .2 25 3/ 20 20 Ap re se nt aç ão : 2 8/ 04 /2 02 0 16 :@1 9 @@ * C D2 05 04 85 21 30 0 *  Le xE di tD oc um en to e le tr ôn ic o as sin ad o po r L oe st er T ru tis ( P SL /M S ), a tr av és d o po nt o SD R_ 56 43 9, na fo rm a do a rt. 1 02, § 1 º, d o RI CD c /c o a rt. 2 º, d o At o da M es a n. 8 0 de 2 01 6.  PL n .2 25 3/ 20 20 Ap re se nt aç ão : 2 8/ 04 /2 02 0 16 :@1 9 @@ * C D2 05 04 85 21 30 0 *  Le xE di tD oc um en to e le tr ôn ic o as sin ad o po r L oe st er T ru tis ( P SL /M S ), a tr av és d o po nt o SD R_ 56 43 9, na fo rm a do a rt. 1 02, § 1 º, d o RI CD c /c o a rt. 2 º, d o At o da M es a n. 8 0 de 2 01 6.  PL n .2 25 3/ 20 20 Ap re se nt aç ão : 2 8/ 04 /2 02 0 16 :@1 9@@ ❌e__ 8_SPECIAL \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DEBUG_PATTERN = \"(?:\\s*[0-9]{1,3}_[A-Z]{1,30}\\s*)\"\n",
    "ALL_SPECIAL_MARKERS = f\"(?:{MARKER_INTENDED_CORRUPTION}|{MARKER_NOISE_START}|{MARKER_NOISE_END}|{MARKER_VALID})\"\n",
    "\n",
    "COMMISSION_LIST = (r\"\"\"\n",
    "    (?:\n",
    "    AGRICULTURA[,\\s]*PECU[AÁ]RIA[,\\s]*ABASTECIMENTO[E\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA[,\\s]*COMUNICA[CÇ][AÃ]O(?:[E\\s]|DA)*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*DE\\s*CIDADANIA|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*(?:DO|AO)\\s*CONSUMIDOR|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO[,\\s]*IND[UÚ]STRIA[,\\s]*COM[EÉ]RCIO(?:[E\\s]|DE)*SERVI[CÇ]OS|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS(?:[E\\s]|DAS)*MINORIAS|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS[E\\s]*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA[E\\s]*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL[,\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*REGIONAL(?:[E\\s]|DA)*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    (?:MEIO\\s*)?AMBIENTE[E\\s]*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS(?:[E\\s]|DA)*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES(?:[E\\s]|DE)*\\s*DEFESA\\s*NACIONAL|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL(?:[E\\s]|DA)*FAMÍLIA|\n",
    "    TRABALHO[,\\s]*ADMINISTRA[CÇ][AÃ]O[E\\s]*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES|\n",
    "    INQUÉRITO\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "COMMISSIONS = (\n",
    "    r\"COMISS[AÃ]O\\s*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:D[EOA]S?|[,;\\s]*E|[;,]\\s*E?|PARLAMENTAR)\\s*)+\" +\n",
    "    COMMISSION_LIST +\n",
    "    r\"\\s*)+\"\n",
    ")\n",
    "\n",
    "\n",
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(\n",
    "        r\"\\*\" +\n",
    "        f\"(?:\\s*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"([\\sA-Z0-9]+)\" +\n",
    "        r\"\\*\",\n",
    "    )\n",
    "    RE_BARCODE_2 = regex.compile(r\"(((?:[0-9A-F]{2}\\s*?){7})\\s*\\2)\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(.{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_CAMARA_REPEATED = regex.compile(\n",
    "        r\"(?:\" +\n",
    "        r\"(C[AÂ]MARA\\s*|CONGRES)(DOS\\s*|SO\\s*NAC)\" +\n",
    "        r\"(DEPUTADOS|IONAL)\" +\n",
    "        r\"([\\s0-9]+(?![\\s0-9]*[-–\\.\\)]))?\" +\n",
    "        r\"(?!\\s*[dD][eE][cC][rR][eE][tT][aA])\" +\n",
    "        r\")\",\n",
    "    )\n",
    "    RE_CAMARA_LOWERCASE = regex.compile(\n",
    "        f\"(?<=^|{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*[cC][âa]mara)(\\s*[dD]os\\s*)([dD]eputados)\" +\n",
    "        r\"(?!\\s*[dD][eE][cC][rR][eE][tT][aA])\"\n",
    "    )\n",
    "    RE_COMMISSIONS_REPEATED = regex.compile(\n",
    "        f\"({COMMISSIONS})\"\n",
    "    )\n",
    "    RE_SALA_DAS_SESSOES_CODE = regex.compile(\n",
    "        r\"(?<=Sala\\s*das\\s*sess[oõ]es\\s*.{,150}?)([0-9]{1,5}\\s*_\\s*(?:\" +\n",
    "        MARKER_NOISE_START +\n",
    "        r\")?\\s*[0-9]{1,5})\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    FN_PAGE_NUMBER = lambda page_num: (\n",
    "        r\"(P[aá]g(?:ina)?[\\.\\s:]*)?\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        f\"(\\s*0?{page_num}\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*(?:[\\\\/-]|de)\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]+\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\"\n",
    "    )\n",
    "    RE_PAGE_NUMBER_01 = regex.compile( #Pág: 1 de 3\n",
    "        f\"^\\s*{FN_PAGE_NUMBER(1)}|(P[aá]g(?:ina)?[\\.\\s:]*){FN_PAGE_NUMBER(1)}\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = map(lambda item: r\"\\s*\".join(cls.RE_BLANK_SPACES.sub(\"\", item)), pseudo_patterns)\n",
    "        pseudo_patterns = set(pseudo_patterns)\n",
    "        \n",
    "        for barcode in sorted(pseudo_patterns):\n",
    "            text = regex.sub(f\"([\\*\\s]*{barcode}[\\*\\s]*)\", subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara(cls, subpattern, text):        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\\4\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_REPEATED.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara_lowercase(cls, subpattern, text):\n",
    "        match = cls.RE_CAMARA_LOWERCASE.match(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_LOWERCASE.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_commissions(cls, subpattern, text):\n",
    "        freqs = collections.Counter(map(str.strip, cls.RE_COMMISSIONS_REPEATED.findall(text)))\n",
    "        \n",
    "        for commission_name, freq in freqs.items():\n",
    "            if freq <= 2:\n",
    "                continue\n",
    "            \n",
    "            mod_subpattern = f\" {MARKER_INTENDED_CORRUPTION}\".join(cls.RE_BLANK_SPACES.split(commission_name))\n",
    "            mod_subpattern = subpattern.replace(r\"\\1\", mod_subpattern)\n",
    "            \n",
    "            text = text.replace(commission_name, mod_subpattern)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_page_number(cls, subpattern, text):\n",
    "        match = cls.RE_PAGE_NUMBER_01.search(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        last_page = int(match.group(4) or match.group(9))\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(r\"\\1\", r\"\\1\\2\\3\\4\")\n",
    "        \n",
    "        for i in range(1, 1 + last_page):\n",
    "            text = regex.sub(cls.FN_PAGE_NUMBER(i), mod_subpattern, text, flags=regex.IGNORECASE)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_page_number(subpattern, text)\n",
    "        text = cls._detect_repeated_camara_lowercase(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        text = cls.RE_SALA_DAS_SESSOES_CODE.sub(subpattern, text)\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        text = cls._detect_repeated_commissions(subpattern, text)\n",
    "        text = cls.RE_BARCODE_2.sub(subpattern, text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "UPPERCASE_LETTERS = r\"ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z\"\n",
    "UPPERCASE_LETTERS_OR_NUM = UPPERCASE_LETTERS + r\"0-9\"\n",
    "VALID_ROMAN_NUM = r\"M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3})\"\n",
    "NRO_SMALL = r\"[nN]\\s*[oO0º°\\.]{1,3}\"\n",
    "NRO = (\n",
    "    r\"(?:\" +\n",
    "    r\"[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[oO0º°]\" +\n",
    "    r\"(?=[^\" + UPPERCASE_LETTERS + UPPERCASE_LETTERS.lower() + r\"])|\" +\n",
    "    r\"(?<=\\s)\" + NRO_SMALL +\n",
    "    r\")\"\n",
    ")\n",
    "QUOTES = r\"”“”\\\"'‘\"\n",
    "QUOTES_CLASS = f\"[{QUOTES}]\"\n",
    "\n",
    "\n",
    "class AgreementList:\n",
    "    ITEMS = (\n",
    "        r\"(\\s*(?:\" +\n",
    "        r\"(?:[ÓO]rg[aã]o\\s*)?(?:Superior|[cC]oncedente|[cC]onve(?:nente|niada))|\" +\n",
    "        NRO + r\"\\s*(?:SIAFI|Original|Do\\s*conv[eê]nio)|\" +\n",
    "        r\"Valor\\s*(?:do\\s*conv[eê]nio)?|\" +\n",
    "        r\"(?:In[ií]cio|Fim)\\s*(?:d[ea]\\s*vig[eê]ncia)?|\" +\n",
    "        r\"Objeto|\" +\n",
    "        r\"Conv[eê]nio|\" +\n",
    "        r\"Processo|\" +\n",
    "        r\"Total\\s*de\\s*itens\\s*Licitados|\" +\n",
    "        r\"Fundamento\\s*legal|\"+\n",
    "        r\"Contratada|\" +\n",
    "        r\"Questionamentos|\" +\n",
    "        r\"Justificativa\"\n",
    "        r\")\\s*)\"\n",
    "    )\n",
    "    RE_ITEMS = regex.compile(ITEMS + r\"(\\s*:)\", regex.IGNORECASE)\n",
    "    REG_GET_LIST = regex.compile(\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + ITEMS + r\":\\s*[^:]{,150}?){2,10}\" +\n",
    "        ITEMS + r\":\\s*[^:]{,150}\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    @classmethod\n",
    "    def sub(cls, subpattern, text: str, *args, **kwargs):\n",
    "        re_match = cls.REG_GET_LIST.search(text)\n",
    "        if re_match is None:\n",
    "            return text\n",
    "        s_start, s_end = re_match.span()\n",
    "        text_slice = text[s_start:s_end]\n",
    "        subpattern = subpattern.replace(r\"\\1\", r\"\\1\" + f\" {MARKER_INTENDED_CORRUPTION} \" + r\"\\2\")\n",
    "        text_slice = cls.RE_ITEMS.sub(\n",
    "            subpattern,\n",
    "            text_slice,\n",
    "        )\n",
    "        text = f\"{text[:s_start]}{text_slice}{text[s_end:]}\"\n",
    "        return text\n",
    "\n",
    "    \n",
    "STATES_ACRONYM = r\"\"\"\n",
    "(?:\n",
    "AC|\n",
    "AL|\n",
    "AP|\n",
    "AM|\n",
    "BA|\n",
    "CE|\n",
    "DF|\n",
    "ES|\n",
    "GO|\n",
    "MA|\n",
    "MT|\n",
    "MS|\n",
    "MG|\n",
    "PA|\n",
    "PB|\n",
    "PR|\n",
    "PE|\n",
    "PI|\n",
    "RJ|\n",
    "RN|\n",
    "RS|\n",
    "RO|\n",
    "RR|\n",
    "SC|\n",
    "SP|\n",
    "SE|\n",
    "TO\n",
    ")\n",
    "\"\"\".replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "\n",
    "DOC_ABBVR_LIST = (\n",
    "    \"COM\", \"DCR\", \"DEN\", \"DTQ\", \"DVS\", \"DVT\", \"EMC\", \"EMD\", \"EML\", \"LDO\", \"EMO\",\n",
    "    \"EMP\", \"EMR\", \"ERD\", \"ESB\", \"EXP\", \"INA\", \"INC\", \"MPV\", \"MSC\", \"PAR\", \"PDC\",\n",
    "    \"PEC\", \"PET\", \"PFC\", \"PLP\", \"PLV\", \"PRC\", \"PRF\", \"PRN\", \"PRO\", \"RCP\", \"REC\",\n",
    "    \"REL\", \"REM\", \"REP\", \"REQ\", \"RIC\", \"RPR\", \"SBE\", \"SBT\", \"SDL\", \"LDO\", \"SIT\",\n",
    "    \"TCU\", \"SOA\", \"STF\", \"SUG\", \"SUM\", \"CCJ\", \"TER\", \"TVR\", \"VTS\", \"PL\", \"PDL\",\n",
    ")\n",
    "\n",
    "DOC_ABBVR = r\"(?:\" + \"|\".join(DOC_ABBVR_LIST) + r\")\"\n",
    "\n",
    "DOC_ABBVR_WITH_SPACES = (\n",
    "    r\"(?:\" +\n",
    "    r\"|\".join(map(lambda item: r\"\\s*\".join([\"\", *item, \"\"]), DOC_ABBVR_LIST)) +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "RAW_NUMBER_PREFIXES = (\n",
    "    r\"Art(?:igo)?s?\\s?\\.?\\s?|\" + NRO_SMALL + r\"|\\$|p[aá]g\\s*\\.|cep\\s*\\.\"\n",
    ")\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:(?:[-–º°0-9]+|[A-Z]{1,2})|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+|\" + QUOTES_CLASS + r\")(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\so0º°]*:\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\(?\\s+[0-9]{1,2}[\\s0oOº°]*(?:[-–\\)]|\\.(?![\\.0-9]))\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\s+[0-9]{1,2}\\s*(?:\\.[0-9]+){1,2}(?![\\.0-9]*,)\",\n",
    ")\n",
    "\n",
    "MONTHS = \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    ")).upper()\n",
    "\n",
    "DATE = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[0-9]{,2}\\s*(?:de|em)\\s*(?:\" + MONTHS + r\")\\s*(?:de|em)\\s*[0-9]{4}\"\n",
    ")\n",
    "\n",
    "DATE_OR_UNDERSCORES = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,\\.0-9\\s]*){1,3}(?:[0-9]{4}|[\\._]+)|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*(?:[0-9]{,2}|[\\._]+)\\s*(?:de|em)\\s*(?:\" + MONTHS +\n",
    "    r\"|_+)\\s*(?:de|em)\\s*(?:[0-9]{4}|[\\._]+)\"\n",
    ")\n",
    "\n",
    "UPPERCASE_DATE_OR_UNDERSCORES = DATE_OR_UNDERSCORES.replace(\"em\", \"EM\").replace(\"de\", \"DE\")\n",
    "\n",
    "EOF = r\".{,300}$\"\n",
    "\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    EOF +\n",
    "    r\"|\" +\n",
    "    DATE_OR_UNDERSCORES + \n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"030|Daniel|[eE]ss|Jaa|ac[fgp]|afpa|cmrv|(da[-–])?conle|[Cc]rps|\" +\n",
    "    r\"dennn?er|dpsl?|drb|epo|faa|‘?[Gg]ab|gsl|jaa|jbs|kvp|lgl|mlcl?|\" +\n",
    "    r\"mm|pnf|rpb|tksa|[Vv][Pp][Ll][cf]?|wgl\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_CORE = r\"(?:pls|mpv|plc|pec|pds|plv|prn|plp|pdl|tema)\"\n",
    "\n",
    "RE_DOC_CODE_SUFFIX = (\n",
    "    r\"(?:(?:\"\n",
    "    r\"c(?:ompleme?ntar)?|eme(?:nda)?s?|\" +\n",
    "    r\"rev(?:is)?|sub(?:st\\.?(?:itutivo)?)?|sust|tt?\" +\n",
    "    r\")\\s*?)*\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_FULL = (\n",
    "    r\"(\" +\n",
    "    r\"(?<=\\s)\" +\n",
    "    RE_DOC_CODE_PREFIX +\n",
    "    \"/\" +\n",
    "    RE_DOC_CODE_CORE +\n",
    "    \"(?:[-–0-9]+)\" +\n",
    "    f\"(?:{RE_DOC_CODE_SUFFIX}[-–\\s]*?)+\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"Sala\\s*d[ea]s?\\s*(?:sess|comiss|reuni)(?:[õo]es|[ãa]o)\" + EOF_OR_DATE,\n",
    "    r\"Senado\\s*Federal\\s*,\" + EOF_OR_DATE,\n",
    "    r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\" + EOF_OR_DATE,\n",
    "    r\"Bras[ií]lia\\s*,\\s*(?:\" + DATE_OR_UNDERSCORES + \")\\s*\",\n",
    "    r\"•\",\n",
    "    r\"●\",\n",
    "    \"\\uF0B7\",\n",
    "    r\"As?\\s*mesas?\\s*da\\s*c[aâ]mara\\s*dos\\s*deputados[^:]{,300}?:\",\n",
    "    r\"Atenciosamente\\s*,\",\n",
    ")\n",
    "\n",
    "CEP = r\"(?:CEP[-–\\s\\.:]*)?[0-9]{2}\\.?[0-9]{3}[-–\\s]*[0-9]{3}\"\n",
    "BRASILIA = r\"Bras[ií]lia.{,5}?DF\"\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "    regex.compile( #0\n",
    "        r\"((?:C[aâ]mara\\s*dos\\s*Deputados\\s*.{,15}?\\s*)?\" +\n",
    "        r\"Anexo\\s*\" + VALID_ROMAN_NUM + r\".{,30}?\" + \"Gab(?:inete)?.{,10}?\" + NRO + \"?[0-9]+\" +\n",
    "        r\"|\" +\n",
    "        r\"Gab(?:inete).{,10}?\" + NRO + r\"?[0-9]+.{,30}?\" + r\"Anexo\\s*\" + VALID_ROMAN_NUM +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(f\"(?<!{NRO}[_\\s\\.0-9]*)\" + r\"([0-9]{11,})\"), #1\n",
    "    regex.compile(r\"(_{9,}\\s*)+\"), #2\n",
    "    regex.compile(r\"(^[\\s0-9]+|(?<!:[\\s0-9_]*)(?:[0-9]+_+)?[\\s0-9]+$)\"), #3\n",
    "    regex.compile( #4\n",
    "        r\"(^(?:\\s*[^\\s\" + \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM + r\"]\\s*)+|\" +\n",
    "        r\"(?:\\s*[^\\s\\.\\)\\?\" + \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM + r\"]\\s*)+$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #5\n",
    "        r\"((?:(?:E[-–\\s]*mails?|Endere[cç]os?\\s*eletr[oô]nicos?)[\\s:]*)?\" +\n",
    "        r\"[-–a-zA-Z0-9\\._]{,40}\\s*@\\s*(?:[a-zA-Z]{1,15}\\.?){1,3})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #6, 7, 8, 9, 10, 11, 12, 13, 14\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, r\"cap[ií]tulo\", r\"t[íi]tulo\")\n",
    "    ],\n",
    "    regex.compile( # 15\n",
    "        r\"((?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)CPI\\s*(?:da\\s*Petrobr[áa]s)?\\s*[-–]\\s*\" +\n",
    "        r\"(LEI\\s*ROUANET|Relat[oó]rio\\s*Final|EXPLORA[CÇ][AÃ]O\\s*SEXUAL\\s*DE\\s*CRIAN[CÇ]AS\\s*E\\s*ADOLESCENTES))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(f\"({CEP}[-–\\s]*{BRASILIA}|{BRASILIA}[-–\\s]*{CEP})\", regex.IGNORECASE), #16\n",
    "    regex.compile( #17\n",
    "        r\"(Gabinete\\s*d[eoa]\\s*deputad[oa]\\s*[^0-9]{,50}?[-–\\\\/]\\s*\" +\n",
    "        STATES_ACRONYM +\n",
    "        \"(?=\\s|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #18\n",
    "        r\"(c[âa]mara\\s*dos\\s*deputados\\s*.{,10}?\\s*pra[çc]a\\s*dos\\s*tr[êe]s\\s*poderes)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #19\n",
    "        r\"(C:(\\\\[^\\.]+)*\\.[a-z]+)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #20, v=Yrcstx0UYe4&feature=youtu.be& kol=999\n",
    "        r\"(\" +\n",
    "        r\"[\\[\\(\\s]*\" +\n",
    "        r\"[0-9]+\" +\n",
    "        r\"[\\]\\)\\s]*\" +\n",
    "        r\"[\" + UPPERCASE_LETTERS + r\"]{,15}?\" +\n",
    "        r\"(?:(?:\" +\n",
    "        r\"(?:\" +\n",
    "        r\"Dispon[ií]vel|Ler|Leia|mais|Vide|Veja|Fontes?|Extra[ií]do|\" +\n",
    "        r\"Link|URL|Endere[cç]o|Eletr[oô]nico|Dados|Matéria|Material|\" +\n",
    "        r\"Pesquisa|Ver|Publicado|[ÌI]ntegra|Respostas?|Confira|Conferir\" +\n",
    "        r\")\" +\n",
    "        r\"\\s*)+\\s*.{,60}?[\\s:]*)?\" +\n",
    "        r\"[\\<\\s]*\" +\n",
    "        r\"(?:https?://|www){1,2}\" +\n",
    "        r\"(?:[^\\s]+|\\s+\\&(?=[\\sa-z]*=)|\\s*[a-z]+=[^\\&\\s]{,100}\\&|(?<=\\&)\\s*[a-z]+=)*\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #21\n",
    "        r\"(Infoleg[^a-z]{,6}Autenticador)\", regex.IGNORECASE),\n",
    ")\n",
    "\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC|\\.{3,})\\s*\\)\\s*|\" +\n",
    "    f\"[{QUOTES}])\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    r\"(?:(?:\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    r\"[^\" + MARKER_VALID + r\"]{,900}?\" +\n",
    "    MARKER_NOISE_END + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    r\"))\"\n",
    ")\n",
    "\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in (\n",
    "        *BASE_LEGAL_ITEMS,\n",
    "        *EXTRA_LEGAL_ITEMS,\n",
    "        r\"D[eê][-–]se\\s*ao\\s*Projeto\\s*a\\s*seguinte\\s*reda[cç][aã]o\\s*:\",\n",
    "    )\n",
    ")\n",
    "\n",
    "ADDITIONAL_TITLES = (\n",
    "    r\"(?:\" \n",
    "    r\"Ju[ií]z[ea]?s?|M[\\.\\s]*M[aª]?[\\s\\.]*|\" +\n",
    "    r\"Doutor[ea]?s?|D\\.?r[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Professor[ea]?s?|Prof[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Advogad[ao]s?|Adv[\\s\\.]*|\" +\n",
    "    r\"Capit[aã](?:o|es)?|Cap[\\s\\.]*|\" +\n",
    "    r\"Pastor[ea]?s?|Pr[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Sargent[ao]s?|Sarg[\\s\\.]*|\"\n",
    "    r\")*\"\n",
    ")\n",
    "\n",
    "ABBVR_EXMO = r\"Ex\\.?m[aªoº]s?\\s*\\.?\"\n",
    "ABBVR_EX = r\"Ex\\.?[aªoº]?s?\\s*\\.\\s*[ºªᵉ]?\"\n",
    "ABBVR_SR = r\"S\\.?r\\.?[aªeᵉ]?s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\"\n",
    "\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)?[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)?\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"(?:MENSAGEM|\" + DOC_ABBVR + \")\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" +\n",
    "    r\"CPI|\" +\n",
    "    r\"Bancada|\" +\n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "\n",
    "#DOS/AS SRS/AS\n",
    "\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(]{,100}\\(\\s*(?:D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}\\)]\" + r\"{1,200})?\\)\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\".{,100}?D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._0-9]+|\" +\n",
    "    f\"(?:{NRO}\" + r\"[_\\s\\.0-9]*)?\\s*(?:\" + UPPERCASE_DATE_OR_UNDERSCORES + r\")|\" +\n",
    "    NRO + r\"[_\\s\\.0-9]*\" + r\"(?:[^,]{,30}?[,\\.]+\\s*(?:DE\\s*)+?[\\._0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "# DATE\n",
    "\n",
    "fn_lambda_single = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" \n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "fn_lambda_quad = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \" + r\"\\4\" + f\" {symb} {deb} \"\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY = (\n",
    "    r\"(?:Excelent[ií]ssim[oa]s?|\" + ABBVR_EXMO + r\"|(?:Vossa|V\\s*\\.)\\*(?:excel[eê]ncias?|\" + ABBVR_EX + r\"))?\" +\n",
    "    r\"\\s*(?:Senhor[ae]?s?|\" + ABBVR_SR + r\")[\\.\\s]*\" +\n",
    "    r\"\\s*(?:Primeir[oa]s?|Vices?|[-–\\s])*\" +\n",
    "    r\"(?:Pres(?:id(?:ent[ae])?)?s?|Min(?:istr[oa])?s?|Advogad[ao]s?\\s*Geral\\s*da\\s*Uni[aã]o|Secret[aá]ri[oa]s?)\" +\n",
    "    r\"[^,:;\\.]{,75}?[,:;\\.]\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<=(?<!\" + f\"{ABBVR_EXMO}|{ABBVR_EX}|{ABBVR_SR}\" + \")\\s*\\..{,10}?|\\).{,10}?)\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY + \"|\" +\n",
    "    r\"(?:(?<=\\.\\s*)(\\s+O\\s*)?Requeir(?:o|emos)|Solicit(?:o|amos))\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile( #0\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,15}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #1\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #2\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        DEPT_EXTENSION_A +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #3\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #4\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #5\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #6\n",
    "        r\"(MEDIDA\\s*PROVIS[ÓO]RIA.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,1200}?)([OA]\\s*President[ea]\\s*da\\s*rep[úu]blica[^:]+?com\\s*for[cç]a\\s*de\\s*lei\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #7\n",
    "        r\"\\s*\".join([\n",
    "            r\"(\",\n",
    "            r\"(?:\",\n",
    "            *r\"LexEdit\",\n",
    "            r\")?\",\n",
    "            r\"(?:\",\n",
    "            *r\"Documento\",\n",
    "            r\"|\",\n",
    "            *r\"Chancela\",\n",
    "            r\")\",\n",
    "            *r\"eletr\",\n",
    "            r\"[oô]\",\n",
    "            *r\"nic\",\n",
    "            r\"[ao]\",\n",
    "            r\".{,400}?\",\n",
    "            *r\"mesa\",\n",
    "            NRO,\n",
    "            r\"[\\s0-9]+\",\n",
    "            r\"(?:de|/|\\\\)\",\n",
    "            \"(?:\\s*[0-9]\\s*){4}\",\n",
    "            r\"\\.\",\n",
    "            r\")\",\n",
    "        ]),\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #8 #PL n .1 31 1/ 20 20 Ap re se nt aç ão : 3 1/ 03 /2 02 0 13 : 0 4\n",
    "#         r\"(\" +\n",
    "#         r\"(?:\" +\n",
    "#         r\"\\s*\".join([\"\", *\"LexEdit\", \"\"]) +\n",
    "#         r\")?\" +\n",
    "#         r\"\\s*\".join([\"\", *\"Documentoeletr\", r\"[oô]\", *\"nico\", \"\"]) +\n",
    "#         r\"\\s*.{,400}?\" +\n",
    "#         r\")?\" +\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + DOC_ABBVR_WITH_SPACES + \"\\s*\" + f\"(?:{NRO})*\" + r\"\\s*[\\d\\s]+/[\\s\\d]+)?+\\s*\" +\n",
    "        r\"\\s*\".join([\"\", *\"Apresenta\", \"[çc]\", \"[aã]\", *\"o:\", \"\"]) +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){4}\" + r\"\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*:\\s*\" +\n",
    "        r\")\" +\n",
    "        f\"({MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        f\"({MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        r\"(?:\" +\n",
    "        r\"([-–]*)\" +\n",
    "        r\"(\" + r\"\\s*\".join([\"\", *\"Mesa\", \"\"]) + r\")\" +\n",
    "        r\")?\" +\n",
    "        r\"([\\s0-9]+(?=[\\s0-9]*(?:[§\" + UPPERCASE_LETTERS + r\"]|$)))?\"\n",
    "        , regex.IGNORECASE | regex.MULTILINE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\5\" + MARKER_INTENDED_CORRUPTION + r\"\\6\" + MARKER_INTENDED_CORRUPTION + r\"\\7\\8\" + f\" {symb_end} {deb} \", None),\n",
    "    (DetectRecurrentNoise, #9\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #10\n",
    "        r\"([:;\" + QUOTES + r\"\\?]\\s*\" + f\"{PREFIX_EXTENSIONS}?)\" + r\"(\\s{,10}[-–])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #11\n",
    "        r\"((?<!S\\s*\\.\\s*A\\s*)\\.)(\\s{,10}[-–])(?=\\s*[\" + UPPERCASE_LETTERS + \"])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #12\n",
    "        r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"),\n",
    "     lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #13\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double, None),\n",
    "    (regex.compile( #14\n",
    "        r\"((?:TVR|(?:Ato\\s*de\\s*)?Concess[aã]o(?:e|\\s)*Renova[cç][ãa]o(?:de|\\s)*Concess[aã]o(?:de|\\s)*Emissora(?:de|\\s)*Rádio(?:e|de|\\s)*Televisão)\\s*\" + DATE_AND_ID + DEPT_EXTENSION + \")\"\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #15\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR)?|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)?\" +\n",
    "        f\"(?!{DEPT_EXTENSION})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #16\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)\" +\n",
    "        f\"(?:{UPPERCASE_DATE_OR_UNDERSCORES})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #17\n",
    "        r\"(?<=[\" + UPPERCASE_LETTERS + \"]{3,}\\s+)([0-9]{1,2}\\s*\\.\\s+[0-9]+)\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None\n",
    "    ),\n",
    "    (regex.compile( #18\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*|ou|,)\\s*)\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2,}\\s*)(\\)))?(\\s*[0-9]{4,}\\s*[-–\\.\\s]?\\s*[0-9]{4,}(?:\\s*/\\s*[0-9]{4})?)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #19\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #20\n",
    "        r\"(OF[IÍ]CIO\\s*\" + NRO + r\".{,110}?\\s*)\" +\n",
    "        r\"((?:Bras[ií]lia|Senado\\s*Federal)?[,\\s]*(?:\" + DATE_OR_UNDERSCORES + r\")[\\.\\s]*)\" +\n",
    "        r\"(.{,300}?\\s*)\" +\n",
    "        r\"(Assunto\\s*:\\s*.{,300}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE\n",
    "    ),\n",
    "    fn_lambda_quad, None),\n",
    "    (regex.compile( #21\n",
    "        r\"(Atenciosamente\\s*),\" +\n",
    "        r\"(\\s*.{,250}?\" +\n",
    "        RE_DOC_CODE_FULL +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\",\\2\" + f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #22\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,10}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        r\"([ÀÁA]\\s*sua\\s*excel[eê]ncia.{,100}?)\" +\n",
    "        r\"(?=(?:\" + REQUEST_PRESIDENT_OR_MINISTRY + \"[,\\s]*)?(?:Requeiro|Solicito))\", regex.IGNORECASE),\n",
    "     fn_lambda_triple, None),\n",
    "    (regex.compile( #23\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*)([^\\s\" + UPPERCASE_LETTERS + r\"])((?:\\s|\\2)*)(\\s*)\" +\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)\",\n",
    "        regex.IGNORECASE),\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\\4\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #24\n",
    "        r\"(Autora?\\s*:\\s*.{,200}?)(\\s*Relatora?\\s*:)\", regex.IGNORECASE),\n",
    "     lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #25\n",
    "        r\"(?<=(?:Relatora?|Autora?)\\s*:.{,200}?\\s+)(\" + VALID_ROMAN_NUM + r\"[-–\\s]+RELAT[OÓ]RIO\\s+)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (AgreementList, #26\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (regex.compile(r\"(?=Reiterando\\s*os\\s*votos\\s*de\\s*apre[cç]o\\s*e\\s*considera[cç][aã]o)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #27\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*)\\s*)?\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2,}\\s*)(\\)))(\\s*[0-9]{4,}\\s*[-–\\.\\s]?\\s*[0-9]{4,}(?:\\s*/\\s*[0-9]{4})?)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \", None),\n",
    ")\n",
    "\n",
    "LARGER_BLOCKS_HIERARCHY = (\n",
    "    \"(?:PARTE\\s*(?:PRIMEIRA|SEGUNDA|TERCEIRA|QUARTA|QUINTA)\\s*(?:DO\\s*)?)?LIVRO\",\n",
    "    \"T[IÍ]TULO\",\n",
    "    \"CAP[IÍ]TULO\",\n",
    "    \"(?:Sub)?[sS]e[cç][aã]o\",\n",
    "    BASE_LEGAL_ITEMS[1] + r\"(?=\\s*[^\" + UPPERCASE_LETTERS_OR_NUM + r\"])\",\n",
    ")\n",
    "\n",
    "RE_PRE_POST_BLOCKS = (\n",
    "    regex.compile( #0\n",
    "        r\"(ACORDO\\s*DE\\s*[-,\"\n",
    "        + UPPERCASE_LETTERS_OR_NUM\n",
    "        + r\"\\s]+)(?=(?:[OA]\\s+)?[\"\n",
    "        + UPPERCASE_LETTERS\n",
    "        + r\"][a-z])\"\n",
    "    ),\n",
    "    regex.compile(r\"(?<!\\(.{,50}?)(\" + COMMISSIONS + \")\"), #1\n",
    "    regex.compile(r\"(O\\s*Congresso\\s*Nacional\\s*decreta\\s*.{,40}?\\s*:)\", regex.IGNORECASE), #2\n",
    "    regex.compile(r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*decreta\\s*.{,40}?\\s*:)\", regex.IGNORECASE), #3\n",
    "    regex.compile( #4\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Lei\\s*(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*)*\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" + r\"\\s*\"+ DEPT_EXTENSION + r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #5\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*(?:Decreto\\s*Legislativo|Resolu[cç][aã]o)\\s*\" +\n",
    "        f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #6\n",
    "        r\"(?<=^[^\\(]{,500}?)(Mensagem\\s*\" + DATE_AND_ID + \"\\s*[0-9][0-9\\s]*)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #7\n",
    "        r\"((?:SUBSTITUTIV[AO]\\s*[ÁÀA]\\s*)?\" +\n",
    "        r\"Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #8, 9, 10\n",
    "        regex.compile(\n",
    "            r\"(\" +\n",
    "            f\"{LARGER_BLOCKS_HIERARCHY[i]}\" + r\"\\s*\" + f\"(?:{VALID_ROMAN_NUM}|[0-9]+)\" +\n",
    "            r\"(?:[-–\\.\\s,\" + UPPERCASE_LETTERS_OR_NUM + r\"])+?\" +\n",
    "            r\"(?:\\s*\" +\n",
    "            MARKER_NOISE_START + r\".{,600}?\" + MARKER_NOISE_END + r\"\\s*\" + f\"{DEBUG_PATTERN}*\" +\n",
    "            r\"\\s*)?\" +\n",
    "            f\"(?={MARKER_VALID}|\" + r\"|\".join(LARGER_BLOCKS_HIERARCHY[i + 1:]) + r\")\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for i in range(len(LARGER_BLOCKS_HIERARCHY) - 1)\n",
    "    ],\n",
    "    regex.compile( #11, Esta lei entra em vigor cento e oitenta dias após a data de sua publicação\n",
    "        r\"(Art.{,10}?Est[áàãa]\\s*\" +\n",
    "        r\"(?:lei|EC|Emenda\\s*(?:Constitucional|[àaá\\s]*constitui[cç][aã]o)|resolu[cç][aã]o)\\s*\" +\n",
    "        r\"entr[ea]\\s*em\\s*vigor\\s*.{,100}?\\s*(?:data\\s*de\\s*)sua\\s*publica[cç][aã]o\\s*.{,50}?(?:\\.|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "RE_POST_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={pattern})\", regex.IGNORECASE)\n",
    "    for pattern in []\n",
    ")\n",
    "\n",
    "COALESCE_NOISE = regex.compile(\n",
    "    f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*\"\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False, coalesce_noise: bool = True) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(\n",
    "            f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \",\n",
    "            text,\n",
    "            concurrent=True)\n",
    "    \n",
    "    for i, (reg, fun, fun_post) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=True)\n",
    "        \n",
    "        if fun_post is not None:\n",
    "            text = fun_post(text)\n",
    "\n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \" + r\"\\1\" + f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_instance(item, ind, print_preprocessed: bool = False, debug: bool = False, coalesce_noise: bool = True):    \n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug, coalesce_noise=coalesce_noise)\n",
    "    preprocessed_text = preprocessed_text.replace(MARKER_INTENDED_CORRUPTION, \"@\" if debug else \"\")\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(colorama.Fore.WHITE, colorama.Style.DIM, preprocessed_text, colorama.Style.RESET_ALL, sep=\"\")\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            cur_token = tokens.pop(i)\n",
    "            cur_label = labels.pop(i)\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_START]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_END:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_NOISE_END:\n",
    "                # labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            labels[i] = SPECIAL_SYMBOLS[cur_token]\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels:\n",
    "        maybe_erase_pool = []\n",
    "        noise_on = False\n",
    "\n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                labels[i] = labels[i + 1] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                maybe_erase_pool.clear()\n",
    "                continue\n",
    "\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                while maybe_erase_pool:\n",
    "                    ind = maybe_erase_pool.pop()\n",
    "                    labels[ind] = 0\n",
    "\n",
    "            if labels[i] > 0:\n",
    "                maybe_erase_pool.append(i)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                if noise_on:\n",
    "                    labels[i] = 0\n",
    "                else:\n",
    "                    noise_on = True\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                if noise_on:\n",
    "                    noise_on = False\n",
    "                else:\n",
    "                    labels[i] = 0\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                noise_on = False\n",
    "            \n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                labels[i] = 0\n",
    "            \n",
    "        while tokens and tokens[0] in SPECIAL_SYMBOLS:\n",
    "            labels.pop(0)\n",
    "            tokens.pop(0)\n",
    "\n",
    "        while tokens and tokens[-1] in SPECIAL_SYMBOLS:\n",
    "            labels.pop()\n",
    "            tokens.pop()\n",
    "        \n",
    "        if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "            labels[0] = 0\n",
    "    \n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "if DEV_RUN:\n",
    "    auxaux = \"\"\"\n",
    "* C D2 05 04 85 21 30 0 * C D205 0 4 85 2130 0 Le xE di tD oc um en to e le tr ôn ic o as sin ad o po r L oe st er T ru tis ( P SL /M S ) , a tr av és d o po nt o SD R_ 56 43 9 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . PL n .2 25 3/ 20 20 Ap re se nt aç ão : 2 8/ 04 /2 02 0 16 :1 9 * C D2 05 04 85 21 30 0 * Le xE di tD oc um en to e le tr ôn ic o as sin ad o po r L oe st er T ru tis ( P SL /M S ) , a tr av és d o po nt o SD R_ 56 43 9 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . PL n .2 25 3/ 20 20 Ap re se nt aç ão : 2 8/ 04 /2 02 0 16 :1 9 * C D2 05 04 85 21 30 0 * Le xE di tD oc um en to e le tr ôn ic o as sin ad o po r L oe st er T ru tis ( P SL /M S ) , a tr av és d o po nt o SD R_ 56 43 9 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . PL n .2 25 3/ 20 20 Ap re se nt aç ão : 2 8/ 04 /2 02 0 16 :1 9\n",
    "\"\"\".replace(\" , \", \", \").replace(\" . \", \". \")\n",
    "\n",
    "res=preprocess_instance({\"text\": auxaux}, -1, True, debug=True, coalesce_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T20:36:32.437627Z",
     "start_time": "2022-03-02T20:35:27.809584Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5b320216a3724f28\n",
      "Reusing dataset csv (../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d778343cd24fa29707ad0bf27b0cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-bb5915d731cb52ba.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-f3969ddb1a6939e3.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-ff0502c9f340dda0.arrow\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START if DEV_RUN else None,\n",
    "    nrows=(DATASET_ROW_END - DATASET_ROW_START + 1) if DEV_RUN else None,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A?\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[\" + UPPERCASE_LETTERS + r\"])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÂÃÀÁ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aãâàá]\\s*o\\s+(?=[\" + UPPERCASE_LETTERS + r\"])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=None if DEV_RUN else \"text\")\n",
    "\n",
    "rerun_tests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T23:10:42.107649Z",
     "start_time": "2022-03-01T23:10:42.102286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 4645}\n"
     ]
    }
   ],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T20:44:26.343067Z",
     "start_time": "2022-03-02T20:43:27.651145Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChosen id:\u001b[39m 3947\n",
      "\n",
      "\u001b[37m\u001b[2mINDICAÇÃO Nº      , DE 2020\r\n",
      "(Do Sr. DENIS BEZERRA)\r\n",
      "Sugere ao Ministério da Saúde que se\r\n",
      "proceda  à  revisão  dos  protocolos  para\r\n",
      "dispensação  de  análogos  de  insulina  de\r\n",
      "ação rápida pelo Sistema Único de Saúde. \r\n",
      "Excelentíssimo Senhor Ministro da Saúde,\r\n",
      "O  principal  fator  determinante  da  qualidade  de  vida  dos\r\n",
      "pacientes diabéticos é, obviamente, o adequado controle dos níveis glicêmicos.\r\n",
      "Nos  diabéticos  dependentes  de  insulina,  esse  controle  é  mais  difícil,  por\r\n",
      "depender de injeções e da dosagem precisa do medicamento. Nesse afã, é de\r\n",
      "extrema  importância  a  existência  de  diferentes  tipos  ou  preparações  de\r\n",
      "insulina, com tempos de ação mais curtos ou mais prolongados. \r\n",
      "Esse arsenal terapêutico aumentou e melhorou sobremaneira\r\n",
      "com  o  desenvolvimento  das  chamadas  insulinas  análogas,  moléculas\r\n",
      "modificadas com algumas sequências de aminoácidos diferentes da insulina\r\n",
      "natural. Há insulinas análogas de ação muito prolongada, que permitem reduzir\r\n",
      "o número de injeções diárias, e também de ação ultrarrápida, que permitem ao\r\n",
      "paciente descompensado retornar em pouco tempo aos níveis homeostáticos. \r\n",
      "Essas vantagens compensam, nos pacientes de difícil controle,\r\n",
      "o maior custo unitário das insulinas análogas, fato que foi  reconhecido pela\r\n",
      "Comissão  Nacional  de  Incorporação  de  Tecnologias  –  CONITEC,  que\r\n",
      "recomendou a sua incorporação ao Protocolo Clínico e Diretrizes Terapêuticas\r\n",
      "do Diabete Melito Tipo 1.   \r\n",
      "Se,  por  um lado,  o  SUS rapidamente  a  disponibilizar  esses\r\n",
      "novos recursos terapêuticos, a sua novidade ocasionou uma distorção que tem\r\n",
      "dificultado sua obtenção pelos pacientes. De acordo com a Relação Nacional\r\n",
      "de Medicamentos Essenciais – Rename de 2020, as insulinas regular e NPH\r\n",
      "constam  do  componente  básico  da  atenção  farmacêutica;  as  insulinas\r\n",
      "análogas,  por  sua  vez,  foram  incluídas  no  componente  especializado, *C\r\n",
      "D2\r\n",
      "01\r\n",
      "62\r\n",
      "79\r\n",
      "16\r\n",
      "00\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r D\r\n",
      "en\r\n",
      "is \r\n",
      "Be\r\n",
      "ze\r\n",
      "rr\r\n",
      "a \r\n",
      "(P\r\n",
      "SB\r\n",
      "/C\r\n",
      "E)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "09\r\n",
      "1,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "10\r\n",
      "54\r\n",
      "/2\r\n",
      "02\r\n",
      "0\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 2\r\n",
      "8/\r\n",
      "09\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "13\r\n",
      ":4\r\n",
      "0 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "2\r\n",
      "requerendo  um  protocolo  rigorosíssimo  para  sua  dispensação,  que  inclui\r\n",
      "relatórios  periódicos  feitos  por  médico  endocrinologista,  enquadramento  em\r\n",
      "critérios  clínicos  estritos  e  exames  laboratoriais  seriados.  Infelizmente,  a\r\n",
      "realidade da assistência pública à saúde fora dos grandes centros torna quase\r\n",
      "impossível satisfazer a tais exigências, resultando em um grande número de\r\n",
      "pacientes desassistidos.\r\n",
      "Mais além, chegou ao conhecimento deste gabinete, por meio\r\n",
      "de órgãos de imprensa, a possibilidade real do descarte de cerca de 1,4 milhão\r\n",
      "de doses de insulina análoga de ação rápida, dado seu prazo de vencimento\r\n",
      "no  primeiro  semestre  de  2021\r\n",
      "(https://blogs.correiobraziliense.com.br/vicente/ate-14-milhao-de-frascos-de-\r\n",
      "insulina-de-efeito-rapido-podem-ir-para-o-lixo/).\r\n",
      "Vimos, portanto, sugerir a V. Exa. que se proceda à revisão\r\n",
      "dos protocolos de dispensação das insulinas análogas, de modo a simplificá-\r\n",
      "los,  viabilizando sua disponibilização aos pacientes que delas necessitam e\r\n",
      "evitando a perda de medicamentos.\r\n",
      "Sala das Sessões, em 24 de setembro de 2020.\r\n",
      "Deputado DENIS BEZERRA\r\n",
      "PSB/CE\r\n",
      "*C\r\n",
      "D2\r\n",
      "01\r\n",
      "62\r\n",
      "79\r\n",
      "16\r\n",
      "00\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r D\r\n",
      "en\r\n",
      "is \r\n",
      "Be\r\n",
      "ze\r\n",
      "rr\r\n",
      "a \r\n",
      "(P\r\n",
      "SB\r\n",
      "/C\r\n",
      "E)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "09\r\n",
      "1,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "10\r\n",
      "54\r\n",
      "/2\r\n",
      "02\r\n",
      "0\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 2\r\n",
      "8/\r\n",
      "09\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "13\r\n",
      ":4\r\n",
      "0 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "REQUERIMENTO Nº          , DE 2020\r\n",
      "(Do Sr. DENIS BEZERRA)\r\n",
      "Requer o envio de Indicação ao Poder\r\n",
      "Executivo,  relativa  à  revisão  de\r\n",
      "procedimentos no âmbito do Sistema Único\r\n",
      "de Saúde\r\n",
      "Senhor Presidente:\r\n",
      "Nos termos do art. 113, inciso I e § 1º, do Regimento Interno da\r\n",
      "Câmara  dos  Deputados,  requeiro  a  V.  Exª.  seja  encaminhada  ao  Poder\r\n",
      "Executivo,  na pessoa do Ministro  de Estado da Saúde,  a  Indicação anexa,\r\n",
      "sugerindo a revisão do protocolo de dispensação de insulinas análogas pelo\r\n",
      "Sistema Único de Saúde.\r\n",
      "Sala das Sessões, em 24 de setembro de 2020.\r\n",
      "Deputado DENIS BEZERRA\r\n",
      "PSB/CE\r\n",
      "*C\r\n",
      "D2\r\n",
      "01\r\n",
      "62\r\n",
      "79\r\n",
      "16\r\n",
      "00\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r D\r\n",
      "en\r\n",
      "is \r\n",
      "Be\r\n",
      "ze\r\n",
      "rr\r\n",
      "a \r\n",
      "(P\r\n",
      "SB\r\n",
      "/C\r\n",
      "E)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "09\r\n",
      "1,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "10\r\n",
      "54\r\n",
      "/2\r\n",
      "02\r\n",
      "0\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 2\r\n",
      "8/\r\n",
      "09\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "13\r\n",
      ":4\r\n",
      "0 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[0m\u001b[97m 1 \u001b[39m INDICAÇÃO Nº , DE 2020 ( Do Sr. DENIS BEZERRA )\n",
      "\n",
      "\u001b[97m 2 \u001b[39m Sugere ao Ministério da Saúde que se proceda à revisão dos protocolos para dispensação de análogos de insulina de ação rápida pelo Sistema Único de Saúde .\n",
      "\n",
      "\u001b[97m 3 \u001b[39m Excelentíssimo Senhor Ministro da Saúde , O principal fator determinante da qualidade de vida dos pacientes diabéticos é , obviamente , o adequado controle dos níveis glicêmicos . Nos diabéticos dependentes de insulina , esse controle é mais difícil , por depender de injeções e da dosagem precisa do medicamento . Nesse afã , é de extrema importância a existência de diferentes tipos ou preparações de insulina , com tempos de ação mais curtos ou mais prolongados . Esse arsenal terapêutico aumentou e melhorou sobremaneira com o desenvolvimento das chamadas insulinas análogas , moléculas modificadas com algumas sequências de aminoácidos diferentes da insulina natural . Há insulinas análogas de ação muito prolongada , que permitem reduzir o número de injeções diárias , e também de ação ultrarrápida , que permitem ao paciente descompensado retornar em pouco tempo aos níveis homeostáticos . Essas vantagens compensam , nos pacientes de difícil controle , o maior custo unitário das insulinas análogas , fato que foi reconhecido pela Comissão Nacional de Incorporação de Tecnologias – CONITEC , que recomendou a sua incorporação ao Protocolo Clínico e Diretrizes Terapêuticas do Diabete Melito Tipo 1 . Se , por um lado , o SUS rapidamente a disponibilizar esses novos recursos terapêuticos , a sua novidade ocasionou uma distorção que tem dificultado sua obtenção pelos pacientes . De acordo com a Relação Nacional de Medicamentos Essenciais – Rename de 2020 , as insulinas regular e NPH constam do componente básico da atenção farmacêutica ; as insulinas análogas , por sua vez , foram incluídas no componente especializado , \u001b[31m* C D2 01 62 79 16 00 0 * Do cu m en to e le tr ôn ic o as sin ad o po r D en is Be ze rr a ( P SB /C E ) , a tr av és d o po nt o SD R_ 56 09 1 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 10 54 /2 02 0 Ap re se nt aç ão : 2 8/ 09 /2 02 0 13 : 4 0 - M es a 2 \u001b[39mrequerendo um protocolo rigorosíssimo para sua dispensação , que inclui relatórios periódicos feitos por médico endocrinologista , enquadramento em critérios clínicos estritos e exames laboratoriais seriados . Infelizmente , a realidade da assistência pública à saúde fora dos grandes centros torna quase impossível satisfazer a tais exigências , resultando em um grande número de pacientes desassistidos . Mais além , chegou ao conhecimento deste gabinete , por meio de órgãos de imprensa , a possibilidade real do descarte de cerca de 1,4 milhão de doses de insulina análoga de ação rápida , dado seu prazo de vencimento no primeiro semestre de 2021 ( https : //blogs.correiobraziliense.com.br/vicente/ate-14-milhao-de-frascos-de- insulina-de-efeito-rapido-podem-ir-para-o-lixo/ ) . Vimos , portanto , sugerir a V. Exa . que se proceda à revisão dos protocolos de dispensação das insulinas análogas , de modo a simplificá- los , viabilizando sua disponibilização aos pacientes que delas necessitam e evitando a perda de medicamentos .\n",
      "\n",
      "\u001b[97m 4 \u001b[39m Sala das Sessões , em 24 de setembro de 2020 . Deputado DENIS BEZERRA PSB/CE \u001b[31m* C D2 01 62 79 16 00 0 * Do cu m en to e le tr ôn ic o as sin ad o po r D en is Be ze rr a ( P SB /C E ) , a tr av és d o po nt o SD R_ 56 09 1 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 10 54 /2 02 0 Ap re se nt aç ão : 2 8/ 09 /2 02 0 13 : 4 0 - M es a \u001b[39mREQUERIMENTO Nº , DE 2020 ( Do Sr. DENIS BEZERRA ) Requer o envio de Indicação ao Poder Executivo , relativa à revisão de procedimentos no âmbito do Sistema Único de Saúde Senhor Presidente : Nos termos do art . 113 , inciso I e § 1º , do Regimento Interno da Câmara dos Deputados , requeiro a V. Exª . seja encaminhada ao Poder Executivo , na pessoa do Ministro de Estado da Saúde , a Indicação anexa , sugerindo a revisão do protocolo de dispensação de insulinas análogas pelo Sistema Único de Saúde .\n",
      "\n",
      "\u001b[97m 5 \u001b[39m Sala das Sessões , em 24 de setembro de 2020 . Deputado DENIS BEZERRA PSB/CE \u001b[31m* C D2 01 62 79 16 00 0 * Do cu m en to e le tr ôn ic o as sin ad o po r D en is Be ze rr a ( P SB /C E ) , a tr av és d o po nt o SD R_ 56 09 1 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 10 54 /2 02 0 Ap re se nt aç ão : 2 8/ 09 /2 02 0 13 : 4 0 - M es a\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   3947: 5, 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it correct? [y/N]: N\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    id_ = None\n",
    "    \n",
    "    if id_ is not None:\n",
    "        print(tests.TEST_CASES[id_])\n",
    "        tests.print_results(df, id_, print_full_text=True)\n",
    "        # tests.update_test_case(id_, (14, 1))\n",
    "    \n",
    "    if rerun_tests:\n",
    "        try:\n",
    "            tests.run_tests(df[\"train\"][\"labels\"])\n",
    "            rerun_tests = False\n",
    "\n",
    "        except AssertionError as e:\n",
    "            raise AssertionError from e\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    document_idx = min(166, df[\"train\"].num_rows - 1)\n",
    "    while tests.test_case_exists(document_idx):\n",
    "        document_idx = random.randint(0, df[\"train\"].num_rows)\n",
    "\n",
    "    print(colorama.Fore.YELLOW + \"Chosen id:\" + colorama.Fore.RESET, document_idx, end=\"\\n\\n\")\n",
    "\n",
    "    expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "    print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "    inp = input()\n",
    "    if inp == \"y\":\n",
    "        tests.update_test_case(document_idx, expected_test_case_values)\n",
    "        print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T20:44:34.347789Z",
     "start_time": "2022-03-02T20:44:34.344071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 64 test cases at './test_cases/110001_120000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
