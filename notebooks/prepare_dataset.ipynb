{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:27:20.023882Z",
     "start_time": "2022-03-05T23:27:19.982250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "Loaded 64 test cases from './test_cases/110001_120000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "import typing as t\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "DEV_RUN = True\n",
    "\n",
    "\n",
    "random.seed(7899)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "DATASET_ROW_START = None\n",
    "DATASET_ROW_END = None\n",
    "if DEV_RUN:\n",
    "    TESTS_DIR = \"test_cases\"\n",
    "    DATASET_ROW_START = 110001\n",
    "    DATASET_ROW_END = 120000\n",
    "    TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "    tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T14:26:33.955081Z",
     "start_time": "2022-03-05T14:26:29.776330Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=DEV_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:44:33.833028Z",
     "start_time": "2022-03-05T22:44:33.709735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m ❌s__ 11_SPECIAL CÂMARA @DOS @DEPUTADOS  ❌e__ 11_SPECIAL REQUERIMENTO Nº , DE 2019 (Do Sr. Nicoletti) para uma única instituição. Na data de 28 de Março p.p., o nosso Presidente da República publicou em suas redes sociais que essa instituição já teria adquirido 100 ( cem ) novos leitos de UTIs. Segue o link : https : //www.instagram.com/p/B- ❌s__ 11_SPECIAL @ * C D2 06 77 66 09 40 0 *  @ Le xE di t RI C n. 33 3/ 20 20 Ap re se nt aç ão : 0 1/ 04 /2 02 0 15 :@5 9 @@ ❌e__ 10_SPECIAL S0gCbBxlQ/ ?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DEBUG_PATTERN = \"(?:\\s*[0-9]{1,3}(?:_[A-Z]{1,30})+\\s*)\"\n",
    "ALL_SPECIAL_MARKERS = f\"(?:{MARKER_INTENDED_CORRUPTION}|{MARKER_NOISE_START}|{MARKER_NOISE_END}|{MARKER_VALID})\"\n",
    "ALL_BUT_NEWSEG = f\"[^{MARKER_VALID}]\"\n",
    "COMMISSION_LIST = (r\"\"\"\n",
    "    (?:\n",
    "    AGRICULTURA(?:[,\\s]|DE)*PECU[AÁ]RIA(?:[,\\s]|DE)*ABASTECIMENTO[E\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA(?:[,\\s]|DE)*COMUNICA[CÇ][AÃ]O(?:[E\\s]|DA)*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*(?:DE\\s*CIDADANIA)?|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*(?:DO|AO)\\s*CONSUMIDOR|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO(?:[,\\s]|DE)*IND[UÚ]STRIA(?:[,\\s]|DE)*COM[EÉ]RCIO(?:[E\\s]|DE)*SERVI[CÇ]OS|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS(?:(?:[E\\s]|DAS)*MINORIAS)?|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS(?:[E\\s]|DE)*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA(?:[E\\s]|DE)*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL(?:[,\\s]|DE)*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*REGIONAL(?:[E\\s]|DA)*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    (?:MEIO\\s*)?AMBIENTE(?:[E\\s]|DE)*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS(?:[E\\s]|DA)*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES(?:(?:[E\\s]|DE)*\\s*DEFESA\\s*NACIONAL)?|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL(?:[E\\s]|DA)*FAM[IÍ]LIA|\n",
    "    TRABALHO(?:[,\\s]|DE)*ADMINISTRA[CÇ][AÃ]O(?:[E\\s]|DE)*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES|\n",
    "    INQU[EÉ]RITO|\n",
    "    REDA[CÇ][ÃA]O\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "COMMISSIONS = (\n",
    "    r\"COMISS(?:[AÃ]O|[OÕ]ES)[\\s:]*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:D[EOA]S?|[\\s;:,]|E|PARLAMENTAR(?:ES)?)\\s*)+\" +\n",
    "    COMMISSION_LIST +\n",
    "    r\"\\s*)+\"\n",
    ")\n",
    "\n",
    "class DetectRecurrentMetadata:\n",
    "    \n",
    "    RE_CAMARA_RAW = regex.compile(\n",
    "        \"C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\"\n",
    "    )\n",
    "    \n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_camara_recurrent_metadata(cls, subpattern, text, dir_: t.Literal[-1, 1]):\n",
    "        positions = [\n",
    "            match.end() if dir_ == 1 else match.start()\n",
    "            for match in cls.RE_CAMARA_RAW.finditer(text)\n",
    "        ]\n",
    "        \n",
    "        if len(positions) <= 1:\n",
    "            return text\n",
    "        \n",
    "        ref_pos = max(positions) if dir_ == 1 else min(positions)\n",
    "        i = 0\n",
    "        ind_last_space = 0\n",
    "        \n",
    "        while 0 <= i + ref_pos < len(text):\n",
    "            chrs = {text[j + i].lower() for j in positions}\n",
    "            \n",
    "            if len(chrs) != 1:\n",
    "                break\n",
    "            \n",
    "            if text[i + ref_pos] == \" \":\n",
    "                ind_last_space = i\n",
    "            \n",
    "            i += 1 * dir_\n",
    "\n",
    "        if i + ref_pos in {-1, len(text)}:\n",
    "            chrs = {text[j + i].lower() for j in positions if 0 <= i + j < len(text)}\n",
    "            \n",
    "            if len(chrs) == 1 and chrs.pop() == \" \":\n",
    "                ind_last_space = i\n",
    "\n",
    "        if dir_ == 1:\n",
    "            slice_ = text[positions[0]:positions[0] + ind_last_space]\n",
    "            \n",
    "        else:\n",
    "            slice_ = text[positions[0] + ind_last_space + 1:positions[0]]\n",
    "            \n",
    "        tokens = [\n",
    "            f\"(\\s*{regex.escape(tok)}\\s*)\"\n",
    "            for tok in regex.split(\n",
    "                r\"([^\" + UPPERCASE_LETTERS + r\"]{1,5})\",\n",
    "                slice_,\n",
    "                flags=regex.IGNORECASE)\n",
    "            if tok\n",
    "        ]\n",
    "        \n",
    "        if not tokens:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            \"\".join(map(lambda gn: (\n",
    "                f\"{MARKER_INTENDED_CORRUPTION}\\g<{gn}>{MARKER_INTENDED_CORRUPTION}\"\n",
    "            ), range(1, 1 + len(tokens))))\n",
    "        )\n",
    "        \n",
    "        text = regex.sub(\n",
    "            (f\"(?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)\" if dir_ == 1 else \"\") +\n",
    "            \"\".join(tokens) +\n",
    "            (f\"(?=\\s*C[AÂ]MARA\\s*DOS\\s*DEPUTADOS)\" if dir_ == -1 else \"\"),\n",
    "            mod_subpattern,\n",
    "            text,\n",
    "        )\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_camara_recurrent_metadata(subpattern, text, dir_=1)\n",
    "        text = cls._detect_camara_recurrent_metadata(subpattern, text, dir_=-1)\n",
    "        return text\n",
    "\n",
    "\n",
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(\n",
    "        r\"\\*\" +\n",
    "        f\"(?:\\s*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"([\\sA-Z0-9]+)\" +\n",
    "        r\"\\*\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BARCODE_2 = regex.compile(r\"(((?:[0-9A-F]{2}\\s*?){7})\\s*\\2)\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(\" + ALL_BUT_NEWSEG + r\"{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_CAMARA_REPEATED = regex.compile(\n",
    "        r\"(?:\" +\n",
    "        r\"(C[AÂ]MARA\\s*|CONGRES)(DOS\\s*|SO\\s*NAC)\" +\n",
    "        r\"(DEPUTADOS|IONAL)\" +\n",
    "        r\"([\\s0-9]+(?![\\s0-9]*[-–\\.\\)]))?\" +\n",
    "        r\"(?!\" + ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "        r\"(?:[dD][eE][cC][rR][eE][tT][aA]|[rR][eE][sS][oO][lL][vV][eE])\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,40}?\\s*:\\s*)\" +\n",
    "        r\")\",\n",
    "    )\n",
    "    RE_CAMARA_LOWERCASE = regex.compile(\n",
    "        f\"(?<=^|{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*[cC][âa]mara)(\\s*[dD]os\\s*)([dD]eputados)\" +\n",
    "        r\"(?!\" + ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "        r\"(?:[dD][eE][cC][rR][eE][tT][aA]|[rR][eE][sS][oO][lL][vV][eE])\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,40}?\\s*:\\s*)\"\n",
    "    )\n",
    "    RE_COMMISSIONS_REPEATED = regex.compile(\n",
    "        r\"((?<!\\(.{,5}\\s*)\" + COMMISSIONS + r\"(?!\\s*.{,5}\\)))\"\n",
    "    )\n",
    "    RE_SALA_DAS_SESSOES_CODE = regex.compile(\n",
    "        r\"(?<=Sala\\s*das\\s*sess[oõ]es\\s*\" + ALL_BUT_NEWSEG + r\"{,150}?)([0-9]{1,5}\\s*_\\s*(?:\" +\n",
    "        MARKER_NOISE_START +\n",
    "        r\")?\\s*[0-9]{1,5})\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    \n",
    "    CAMARA_PAGE_NUMBER_SUFFIX = (\n",
    "        f\"(?=\\s*(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\\s*C[AÂ]MARA\\s*DOS\\s*DEPUTADOS)\"\n",
    "    )\n",
    "    \n",
    "    RE_CAMARA_PAGE_NUMBER = regex.compile(r\"([0-9]+)\" + CAMARA_PAGE_NUMBER_SUFFIX)\n",
    "    \n",
    "    FN_PAGE_NUMBER = lambda page_num: (\n",
    "        r\"(P[aá\\s]?g(?:ina)?[\\.\\s:]*)?\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        f\"(\\s*0?{page_num}\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*(?:[\\\\/-]|de)\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]+\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\"\n",
    "    )\n",
    "    RE_PAGE_NUMBER_01 = regex.compile( #Pág: 1 de 3\n",
    "        f\"^\\s*{FN_PAGE_NUMBER(1)}|(P[aá]g(?:ina)?[\\.\\s:]*){FN_PAGE_NUMBER(1)}\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = map(lambda item: r\"\\s*\".join(cls.RE_BLANK_SPACES.sub(\"\", item)), pseudo_patterns)\n",
    "        pseudo_patterns = set(pseudo_patterns)\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION\n",
    "        )\n",
    "        \n",
    "        for barcode in sorted(pseudo_patterns):\n",
    "            text = regex.sub(f\"([\\*\\s]*{barcode}[\\*\\s]*)\", mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_camara_page_number(cls, subpattern, text):\n",
    "        numbers = sorted(map(int, cls.RE_CAMARA_PAGE_NUMBER.findall(text)))\n",
    "        \n",
    "        for i, p in enumerate(numbers, 1):\n",
    "            if i != p:\n",
    "                break\n",
    "            \n",
    "            text = regex.sub(f\"({i}){cls.CAMARA_PAGE_NUMBER_SUFFIX}\", subpattern, text)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara(cls, subpattern, text):        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\\4\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_REPEATED.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara_lowercase(cls, subpattern, text):\n",
    "        match = cls.RE_CAMARA_LOWERCASE.match(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_LOWERCASE.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_commissions(cls, subpattern, text):\n",
    "        freqs = collections.Counter(map(str.strip, cls.RE_COMMISSIONS_REPEATED.findall(text)))\n",
    "        \n",
    "        for commission_name, freq in freqs.items():\n",
    "            if freq <= 2:\n",
    "                continue\n",
    "            \n",
    "            mod_subpattern = f\" {MARKER_INTENDED_CORRUPTION}\".join(cls.RE_BLANK_SPACES.split(commission_name))\n",
    "            mod_subpattern = subpattern.replace(r\"\\1\", mod_subpattern)\n",
    "            \n",
    "            text = text.replace(commission_name, mod_subpattern)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_page_number(cls, subpattern, text):\n",
    "        match = cls.RE_PAGE_NUMBER_01.search(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        last_page = int(match.group(4) or match.group(9))\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(r\"\\1\", r\"\\1\\2\\3\\4\")\n",
    "        \n",
    "        for i in range(1, 1 + last_page):\n",
    "            text = regex.sub(cls.FN_PAGE_NUMBER(i), mod_subpattern, text, flags=regex.IGNORECASE)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_page_number(subpattern, text)\n",
    "        text = cls._detect_camara_page_number(subpattern, text)\n",
    "        text = cls._detect_repeated_camara_lowercase(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        text = cls.RE_SALA_DAS_SESSOES_CODE.sub(subpattern, text)\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        text = cls._detect_repeated_commissions(subpattern, text)\n",
    "        text = cls.RE_BARCODE_2.sub(subpattern, text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "class PostProcRecurrentNoise(DetectRecurrentNoise):\n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    \n",
    "UPPERCASE_LETTERS = r\"ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z\"\n",
    "UPPERCASE_LETTERS_OR_NUM = UPPERCASE_LETTERS + r\"0-9\"\n",
    "VALID_ROMAN_NUM = r\"(?:M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3}))\"\n",
    "NRO_SMALL = r\"[nN]\\s*[oO0º°\\.]{1,3}\"\n",
    "NRO = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?<=\\s)[dD][eE]\\s+)?\" +\n",
    "    r\"[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[oO0º°]\" +\n",
    "    r\"(?=[^\" + MARKER_VALID + UPPERCASE_LETTERS + UPPERCASE_LETTERS.lower() + r\"])|\" +\n",
    "    r\"(?<=\\s)\" + NRO_SMALL +\n",
    "    r\")\"\n",
    ")\n",
    "QUOTES = r\"”“”\\\"'‘\"\n",
    "QUOTES_CLASS = f\"[{QUOTES}]\"\n",
    "\n",
    "class AgreementList:\n",
    "    ITEMS = (\n",
    "        r\"(\\s*(?:\" +\n",
    "        r\"(?:[ÓO]rg[aã]o\\s*)?(?:Superior|[cC]oncedente|[cC]onve(?:nente|niada))|\" +\n",
    "        NRO + r\"\\s*(?:SIAFI|Original|Do\\s*conv[eê]nio)|\" +\n",
    "        r\"Valor\\s*(?:do\\s*conv[eê]nio)?|\" +\n",
    "        r\"(?:In[ií]cio|Fim)\\s*(?:d[ea]\\s*vig[eê]ncia)?|\" +\n",
    "        r\"Objeto|\" +\n",
    "        r\"Conv[eê]nio|\" +\n",
    "        r\"Processo|\" +\n",
    "        r\"Total\\s*de\\s*itens\\s*Licitados|\" +\n",
    "        r\"Fundamento\\s*legal|\"+\n",
    "        r\"Contratada|\" +\n",
    "        r\"Questionamentos|\" +\n",
    "        r\"Justificativa\"\n",
    "        r\")\\s*)\"\n",
    "    )\n",
    "    RE_ITEMS = regex.compile(ITEMS + r\"(\\s*:)\", regex.IGNORECASE)\n",
    "    REG_GET_LIST = regex.compile(\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + ITEMS + r\":\\s*[^:\" + MARKER_VALID + \"]{,150}?){2,10}\" +\n",
    "        ITEMS + r\":\\s*[^:\" + MARKER_VALID + r\"]{,150}\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern, text: str, *args, **kwargs):\n",
    "        re_match = cls.REG_GET_LIST.search(text)\n",
    "        if re_match is None:\n",
    "            return text\n",
    "        s_start, s_end = re_match.span()\n",
    "        text_slice = text[s_start:s_end]\n",
    "        subpattern = subpattern.replace(r\"\\1\", r\"\\1\" + f\" {MARKER_INTENDED_CORRUPTION} \" + r\"\\2\")\n",
    "        text_slice = cls.RE_ITEMS.sub(\n",
    "            subpattern,\n",
    "            text_slice,\n",
    "        )\n",
    "        text = f\"{text[:s_start]}{text_slice}{text[s_end:]}\"\n",
    "        return text\n",
    "\n",
    "\n",
    "STATES_ACRONYM = r\"\"\"\n",
    "(?:\n",
    "AC|\n",
    "AL|\n",
    "AP|\n",
    "AM|\n",
    "BA|\n",
    "CE|\n",
    "DF|\n",
    "ES|\n",
    "GO|\n",
    "MA|\n",
    "MT|\n",
    "MS|\n",
    "MG|\n",
    "PA|\n",
    "PB|\n",
    "PR|\n",
    "PE|\n",
    "PI|\n",
    "RJ|\n",
    "RN|\n",
    "RS|\n",
    "RO|\n",
    "RR|\n",
    "SC|\n",
    "SP|\n",
    "SE|\n",
    "TO\n",
    ")\n",
    "\"\"\".replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "DOC_ABBVR_LIST = (\n",
    "    \"COM\", \"DCR\", \"DEN\", \"DTQ\", \"DVS\", \"DVT\", \"EMC\", \"EMD\", \"EML\", \"LDO\", \"EMO\",\n",
    "    \"EMP\", \"EMR\", \"ERD\", \"ESB\", \"EXP\", \"INA\", \"INC\", \"MPV\", \"MSC\", \"PAR\", \"PDC\",\n",
    "    \"PEC\", \"PET\", \"PFC\", \"PLP\", \"PLV\", \"PRC\", \"PRF\", \"PRN\", \"PRO\", \"RCP\", \"REC\",\n",
    "    \"REL\", \"REM\", \"REP\", \"REQ\", \"RIC\", \"RPR\", \"SBE\", \"SBT\", \"SDL\", \"LDO\", \"SIT\",\n",
    "    \"TCU\", \"SOA\", \"STF\", \"SUG\", \"SUM\", \"CCJ\", \"TER\", \"TVR\", \"VTS\", \"PL\", \"PDL\",\n",
    ")\n",
    "DOC_ABBVR = r\"(?:\" + \"|\".join(DOC_ABBVR_LIST) + r\")\"\n",
    "DOC_ABBVR_WITH_SPACES = (\n",
    "    r\"(?:\" +\n",
    "    r\"|\".join(map(lambda item: r\"\\s*\".join([\"\", *item, \"\"]), DOC_ABBVR_LIST)) +\n",
    "    r\")\"\n",
    ")\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "RAW_NUMBER_PREFIXES = (\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*|\" + NRO_SMALL + r\"|\\$|p[aá]g\\s*\\.|cep\\s*\\.|ltda\\s*\\.\"\n",
    ")\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:(?:[-–º°0-9]+|(?<=igos?|\\s+)[A-Z]{1,2})|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+|\" + QUOTES_CLASS + r\")(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\soO0º°]*[-–:]\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\(?\\s+[0-9]{1,2}[\\s0oOº°]*(?:[-–\\)]|\\.(?![\\.0-9]))\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\s+[0-9]{1,2}\\s*(?:\\.[0-9]+){1,2}(?![\\.0-9]*,)\",\n",
    ")\n",
    "MONTHS = \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    ")).upper()\n",
    "DATE = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,º0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[0-9]{,2}[º°oO\\s]*(?:de|em)\\s*(?:\" + MONTHS + r\")\\s*(?:de|em)\\s*[0-9]{4}\"\n",
    ")\n",
    "DATE_OR_UNDERSCORES = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,\\.º0-9\\s]*){1,3}(?:[0-9]{4}|[\\._]+)|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*(?:[0-9]{,2}|[\\._]+)[º°oO\\s]*(?:de|em)\\s*(?:\" + MONTHS +\n",
    "    r\"|_+)\\s*(?:de|em)\\s*(?:[0-9]{4}|[\\._]+)\"\n",
    ")\n",
    "UPPERCASE_DATE_OR_UNDERSCORES = DATE_OR_UNDERSCORES.replace(\"em\", \"EM\").replace(\"de\", \"DE\")\n",
    "EOF = r\".{,450}$\"\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    EOF +\n",
    "    r\"|\" +\n",
    "    DATE_OR_UNDERSCORES + \n",
    "    r\")\"\n",
    ")\n",
    "RE_DOC_CODE_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"030|Daniel|[eE]ss|Jaa|ac[fgp]|afpa|cmrv|(da[-–])?conle|[Cc]rps|\" +\n",
    "    r\"dennn?er|dpsl?|drb|epo|faa|‘?[Gg]ab|gsl|jaa|jbs|kvp|lgl|mlcl?|\" +\n",
    "    r\"mm|pnf|rpb|tksa|[Vv][Pp][Ll][cf]?|wgl\" +\n",
    "    r\")\"\n",
    ")\n",
    "RE_DOC_CODE_CORE = r\"(?:pls|mpv|plc|pec|pds|plv|prn|plp|pdl|tema)\"\n",
    "RE_DOC_CODE_SUFFIX = (\n",
    "    r\"(?:(?:\" +\n",
    "    r\"c(?:ompleme?ntar)?|eme(?:nda)?s?|\" +\n",
    "    r\"rev(?:is)?|sub(?:st\\.?(?:itutivo)?)?|sust|tt?\" +\n",
    "    r\")\\s*?)*\"\n",
    ")\n",
    "RE_DOC_CODE_FULL = (\n",
    "    r\"(\" +\n",
    "    r\"(?<=\\s)\" +\n",
    "    RE_DOC_CODE_PREFIX +\n",
    "    \"/\" +\n",
    "    RE_DOC_CODE_CORE +\n",
    "    r\"(?:[-–0-9]+)\" +\n",
    "    f\"(?:{RE_DOC_CODE_SUFFIX}[-–\\s]*?)+\" +\n",
    "    r\")\"\n",
    ")\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"Sala\\s*d[ea]s?\\s*(?:sess|comiss|reuni)(?:[õo]es|[ãa]o)\" + EOF_OR_DATE,\n",
    "    r\"Senado\\s*Federal\\s*,\" + EOF_OR_DATE,\n",
    "    r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\" + EOF_OR_DATE,\n",
    "    r\"Bras[ií]lia\\s*,\\s*(?:\" + DATE_OR_UNDERSCORES + r\")\\s*\",\n",
    "    r\"•\",\n",
    "    r\"●\",\n",
    "    \"\\uF0B7\",\n",
    "    r\"As?\\s*mesas?\\s*da\\s*c[aâ]mara\\s*dos\\s*deputados[^:\" + MARKER_VALID + r\"]{,300}?:\",\n",
    "    r\"(?:Atenciosamente|Respeitosam?ente)\\s*,\",\n",
    ")\n",
    "# CEP 70.160.900\n",
    "CEP_NUMBERS = r\"(?<g_cep_fst>[0-9]{2}\\.?[0-9]{3})(?<g_cep_snd>[-–\\.\\s]*[0-9]{3})\"\n",
    "CEP = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<g_cep_lab>(?:CEP|Código\\s*[pP]ostal)[-–\\s\\.:]*)?\" + CEP_NUMBERS +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "BRASILIA = r\"(?<g_bra_name>Bras[ií]lia\" + ALL_BUT_NEWSEG + r\"{,5}?)(?<g_bra_df>DF|Distrito\\s*Federal)\"\n",
    "\n",
    "NOISE_PLACE_ITEMS = (\n",
    "    r\"(?:\" +\n",
    "    f\"sala\\s+[{UPPERCASE_LETTERS_OR_NUM}]\" + r\"{1,3}(?:[-–\\.]\" + f\"[{UPPERCASE_LETTERS_OR_NUM}]\" + r\")?|\" +\n",
    "    r\"pavimento\\s*(?:s(?:uperior)?|t[eé]rreo)?|\" +\n",
    "    f\"(?:Bloco|(?<=[^{UPPERCASE_LETTERS}])Ala)\\s+[A-Z](?=[^{UPPERCASE_LETTERS}])|\" +\n",
    "    r\"anexo\\s+(?:[0-9]+|\" + VALID_ROMAN_NUM + r\")\" +\n",
    "    r\")\"\n",
    ")\n",
    "NOISE_PLACE_SEP = (\n",
    "    r\"[^\" + MARKER_VALID + MARKER_NOISE_START[0] + MARKER_NOISE_END[0] + \"]{,40}\"\n",
    ")\n",
    "\n",
    "LARGER_BLOCKS_HIERARCHY = (\n",
    "    \"(?:PARTE\\s*(?:PRIMEIRA|SEGUNDA|TERCEIRA|QUARTA|QUINTA)\\s*(?:DO\\s*)?)?LIVRO\",\n",
    "    \"T[IÍ]TULO\",\n",
    "    \"CAP[IÍ]TULO\",\n",
    "    \"(?:Sub)?[sS]e[cç][aã]o\",\n",
    "    BASE_LEGAL_ITEMS[1] + r\"(?=\\s*[^\" + UPPERCASE_LETTERS_OR_NUM + r\"])\",\n",
    ")\n",
    "    \n",
    "SOURCE_URL = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:\" +\n",
    "    r\"(?:\" +\n",
    "    r\"Dispon[ií]vel|Ler|Leia|mais|Vide|Veja|Fontes?|Extra[ií]do|\" +\n",
    "    r\"Link|URL|Endere[cç]o|Eletr[oô]nico|Dados|Matéria|Material|\" +\n",
    "    r\"Pesquisa|Ver|Publicado|[ÌI]ntegra|Respostas?|Confira|Conferir\" +\n",
    "    r\")\" +\n",
    "    r\"(?:[,\\s]|em|d?[aeo]s?|n[ao]s?|[ao]s)*)+\\s*\" + ALL_BUT_NEWSEG + r\"{,60}?[\\s:]*)?\" +\n",
    "    r\"[\\<\\s]*\" +\n",
    "    r\"(?:https?://|www){1,2}\" +\n",
    "    r\"(?:[^\\s\" + MARKER_VALID +\n",
    "    r\"]+|\\s+\\&(?=[\\sa-z]*=)|\\s*[a-z]+=[^\\&\\s\" + MARKER_VALID + r\"]\" +\n",
    "    r\"{,100}\\&|(?<=\\&)\\s*[a-z]+=)*\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "    regex.compile( #0, Câmara dos Deputados , Gab . 862 , Anexo IV\n",
    "        r\"((?:C[aâ]mara\\s*dos\\s*Deputados\\s*\" + ALL_BUT_NEWSEG + r\"{,15}?\\s*)?\" +\n",
    "        r\"(?:\"\n",
    "        r\"Anexo\\s*\" + VALID_ROMAN_NUM + r\"\" + ALL_BUT_NEWSEG + r\"{,30}?\" +\n",
    "        r\"Gab(?:inete)?.{,10}?\" + NRO + r\"?[0-9]+\" +\n",
    "        r\"|\" +\n",
    "        r\"Gab(?:inete)?.{,10}?\" + NRO + r\"?[0-9]+.{,30}?\" + r\"Anexo\\s*\" + VALID_ROMAN_NUM +\n",
    "        r\")\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(f\"(?<!{NRO}[_X\\s\\.0-9]*)\" + r\"([0-9]{11,})\"), #1\n",
    "    regex.compile(r\"(_{9,}\\s*)+\"), #2\n",
    "    regex.compile( #3\n",
    "        r\"(\" +\n",
    "        r\"^(?:\\s*[^\\s\" +\n",
    "        \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM +\n",
    "        r\"]\\s*)+|\" +\n",
    "        r\"(?:\\s*[^\\s\\.\\)\\?\" +\n",
    "        \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM +\n",
    "        r\"]\\s*)+(?:\\.docx?\\s*)?$\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #4\n",
    "        r\"((?:(?:E[-–\\s]*mails?|Endere[cç]os?\\s*eletr[oô]nicos?)[\\s:]*)?\" +\n",
    "        r\"[-–a-zA-Z0-9\\._]{,40}\\s*@\\s*(?:[a-zA-Z]{1,15}\\.?){1,3})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #5-13-22-26\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, *EXTRA_LEGAL_ITEMS, *LARGER_BLOCKS_HIERARCHY[:-1])\n",
    "    ],\n",
    "    regex.compile( # 27\n",
    "        r\"((?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)CPI\\s*(?:da\\s*Petrobr[áa]s)?\\s*[-–]\\s*\" +\n",
    "        r\"(LEI\\s*ROUANET|Relat[oó]rio\\s*Final|EXPLORA[CÇ][AÃ]O\\s*SEXUAL\\s*DE\\s*CRIAN[CÇ]AS\\s*E\\s*ADOLESCENTES))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #28\n",
    "        r\"(Gabinete\\s*d[eoa]\\s*deputad[oa]\\s*[^0-9\" + MARKER_VALID + \"]{,50}?[-–\\\\/]\\s*\" +\n",
    "        STATES_ACRONYM +\n",
    "        \"(?=\\s|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #29\n",
    "        r\"(c[âa]mara\\s*dos\\s*deputados\\s*.{,10}?\\s*pra[çc]a\\s*dos\\s*tr[êe]s\\s*poderes)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #30\n",
    "        r\"(C:(\\\\[^\\.\" + MARKER_VALID + \"]+)*\\.[a-z]+)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #31\n",
    "        r\"(\" +\n",
    "        r\"[\\[\\(\\s]*\" +\n",
    "        r\"[0-9]+\" +\n",
    "        r\"[\\]\\)\\s]*\" +\n",
    "        r\"[\" + UPPERCASE_LETTERS + r\"]{,15}?\" +\n",
    "        SOURCE_URL +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #32\n",
    "        r\"(Infoleg[^a-z]{,6}Autenticador)\", regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #33\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + NOISE_PLACE_ITEMS + NOISE_PLACE_SEP + r\"){2,4}\" +\n",
    "        NOISE_PLACE_ITEMS +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #34\n",
    "        r\"(\" +\n",
    "        r\"(?:formatado|r[ée]cuo)\\s*:\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"fonte\\s*:\\s*(?:[\\s0-9]+pt|\\(padr[aã]o\\)\\s*arial)\" +\n",
    "        r\"(?:\\s*,\\s*(?:Negrito|It[aá]lico|cor\\s*da\\s*fonte\\s*:\\s*autom[aá]tica))*|\" +\n",
    "        r\"n[aã]o\\s*cabe[cç]alho\\s*diferente\\s*na\\s*primeira\\s*p[aá]gina|\" +\n",
    "        r\"justificado|\" +\n",
    "        r\"cor\\s*da\\s*fonte\\s*:\\s*autom[aá]tica|\"\n",
    "        r\"corpo\\s*padr[aã]o\\s*,\\s*[aàá]\\s*(?:esquerda|direita)|\" +\n",
    "        r\"espaçamento\\s*entre\\s*linhas\\s*:\\s*(?:duplo|simples)|\" +\n",
    "        r\"espa[cç]o\\s*depois\\s*de\\s*:\\s*[0-9]+cm|\" +\n",
    "        r\"(?:[,\\s]*\" +\n",
    "        r\"(?:Esquerda|Direita|Inferior|Largura|Altura|Superior|Primeira\\s*linha|Espa[cç]o\\s*depois\\s*de)\" +\n",
    "        r\"\\s*:\\s*\" +\n",
    "        r\"[\\.,0-9]+\\s*(?:['\\\"]|cm|pt)?[,\\s]*)+|\"\n",
    "        r\")\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"(\" + r\"\\s*\".join(\"LexEdit\") + r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC|\\.{3,})\\s*\\)\\s*|\" +\n",
    "    f\"[{QUOTES}]|\\uF03F)\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    r\"(?:(?:\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    r\"\" + ALL_BUT_NEWSEG + r\"{,900}?\" +\n",
    "    MARKER_NOISE_END + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    r\"))\"\n",
    ")\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in (\n",
    "        *BASE_LEGAL_ITEMS,\n",
    "        *EXTRA_LEGAL_ITEMS,\n",
    "        r\"D[eê][-–]se\\s*ao\\s*Projeto\\s*a\\s*seguinte\\s*reda[cç][aã]o\\s*:\",\n",
    "    )\n",
    ")\n",
    "ADDITIONAL_TITLES = (\n",
    "    r\"(?:\" +\n",
    "    r\"Ju[ií]z[ea]?s?|M[\\.\\s]*M[aª]?[\\s\\.]*|\" +\n",
    "    r\"Doutor[ea]?s?|D\\.?r[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Professor[ea]?s?|Prof[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Advogad[ao]s?|Adv[\\s\\.]*|\" +\n",
    "    r\"Capit[aã](?:o|es)?|Cap[\\s\\.]*|\" +\n",
    "    r\"Pastor[ea]?s?|Pr[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Sargent[ao]s?|Sarg[\\s\\.]*|\" +\n",
    "    r\"Reitor[ea]?s?\" +\n",
    "    r\")*\"\n",
    ")\n",
    "ABBVR_EXMO = r\"Ex\\.?m[aªoº]s?\\s*\\.?\"\n",
    "ABBVR_EX = r\"Ex\\.?[aªoº]?s?\\s*\\.\\s*[ºªᵉ]?\"\n",
    "ABBVR_SR = r\"S\\.?r\\.?[aªeᵉ]?s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\"\n",
    "ABBVR_MM = r\"M\\.?M\\.[aªoº]*\"\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)?[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)?\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"(?:MENSAGEM|\" + DOC_ABBVR + \")\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" +\n",
    "    r\"CPI|\" +\n",
    "    r\"Bancada|\" +\n",
    "    r\"PROVENIENTE\\s*DA\\s*(?:MEDIDA\\s*PROVIS[OÓ]RIA|MPV)|\" + \n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "#DOS/AS SRS/AS\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(\" + MARKER_VALID + r\"]{,100}\\(\\s*(?:D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}{MARKER_VALID}\\)]\" + r\"{1,200})?\\)\" +\n",
    "    r\"(?!\\s*[;:,])\"\n",
    ")\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\"\" + ALL_BUT_NEWSEG + r\"{,100}?D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}{MARKER_VALID}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._X0-9]+|\" +\n",
    "    f\"(?:{NRO}\" + r\"[_X\\s\\.0-9]*)?\\s*(?:\" + UPPERCASE_DATE_OR_UNDERSCORES + r\")|\" +\n",
    "    NRO + r\"[_X\\s\\.0-9]*\" + r\"(?:[^,\" + MARKER_VALID + r\"]{,30}?[,\\.]+\\s*(?:DE\\s*)+?[\\._X0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "# DATE\n",
    "fn_lambda_single = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" \n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "fn_lambda_quad = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \" + r\"\\4\" + f\" {symb} {deb} \"\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:\\s(?:Ao|[AÁÀ]))?s?\\s*\" +\n",
    "    r\"(?:\\s*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"Excelent[ií]ssim[oa]s?|\" + ABBVR_EXMO + r\"|\" +\n",
    "    r\"Merit[ií]ssim[oa]s?|\" + ABBVR_MM + r\"|\" +\n",
    "    r\"Magn[iíì]fic[ao]s?|\"\n",
    "    r\"A\\s*sua\\s*(?:magnific[eê]ncia|excel[eê]ncia)|\" +\n",
    "    r\"(?:Vossa|V\\s*\\.)\\*(?:excel[eê]ncias?|\" + ABBVR_EX + r\")|\" +\n",
    "    r\"Senhor[ae]?s?|\" + ABBVR_SR +\n",
    "    r\")\" +\n",
    "    r\"\\s*)+\" +\n",
    "    r\"[\\.\\s]*(?:Primeir[oa]s?|Vices?|[-–\\s])*\"\n",
    "    r\")\"\n",
    ")\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_CORE = (\n",
    "    r\"(?:\" +\n",
    "    r\"Pres(?:id(?:ent[ae])?)?s?|\" +\n",
    "    r\"Min(?:istr[oa])?s?|\" +\n",
    "    r\"Advogad[ao]s?\\s*Geral\\s*da\\s*Uni[aã]o|\" +\n",
    "    r\"Secret[aá]ri[oa]s?|\" +\n",
    "    r\"Reitor[ea]?s?\" +\n",
    "    r\")\"\n",
    ")\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_SUFFIX = (\n",
    "    r\"(?:[^,:;\\.\" + MARKER_VALID + r\"]{,75}?[,:;\\.])\"\n",
    ")\n",
    "REQUEST_PRESIDENT_OR_MINISTRY = (\n",
    "    \"(?:\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_PREFIX +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_CORE +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_SUFFIX +\n",
    "    \")\"\n",
    ")\n",
    "REQUEST_PRONOUN_COLON = (\n",
    "    \"(?:\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_PREFIX +\n",
    "    f\"{REQUEST_PRESIDENT_OR_MINISTRY_CORE}?\" +\n",
    "    r\"[^: \" + MARKER_VALID + \"r]{,75}?\\s*:\" +\n",
    "    \")\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<=(?<!\" + f\"{ABBVR_EXMO}|{ABBVR_EX}|{ABBVR_SR}|{ABBVR_MM}\" +\")\\s*\\.\" +\n",
    "    ALL_BUT_NEWSEG + r\"{,10}?|\\)\" + ALL_BUT_NEWSEG + r\"{,10}?)\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY + \"|\" +\n",
    "    r\"(?:(?<=\\.\\s*)(\\s+O\\s*)?Requeir(?:o|emos)|Solicit(?:o|amos))\" +\n",
    "    r\")\"\n",
    ")\n",
    "PRACA_DTP = r\"Pra[çc]a\\s*dos\\s*tr[eê]s\\s*poderes\"\n",
    "PRACA_DTP_NEIGHBORS = (\n",
    "    r\"(?|\" +\n",
    "    r\"(Gabinete\\s*)?(Bras[ií]lia)|(D)(F)|(C[aâ]mara\\s*Dos)(\\s*Deputados)|\" +\n",
    "    r\"((?:Pal[aá]cio\\s*do\\s*)?Congresso\\s*)(Nacional)|(Gabinete\\s*)(Parlamentar)|\" +\n",
    "    r\"(Comiss[aã]o\\s*de\\s*)(Fiscaliza[cç][aã]o\\s*Financeira[e\\s]*Controle)\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile( #0\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,15}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #1\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,15}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #2\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #3\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #4\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.\" +\n",
    "        MARKER_VALID + r\"]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    \n",
    "    (regex.compile( #5\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.\" +\n",
    "        MARKER_VALID + r\"]{,20}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1,\n",
    "    ),\n",
    "    \n",
    "    (regex.compile( #6\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O\" + ALL_BUT_NEWSEG + r\"{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG +\n",
    "        r\"{,1000}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara)\" +\n",
    "        r\"(\\s*dos\\s*deputados)([^\\.\" + MARKER_VALID + r\"]*?resolve\\s*:)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" +\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\3\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\"\n",
    "    ), 1),\n",
    "    \n",
    "    (regex.compile( #7\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O\" + ALL_BUT_NEWSEG + r\"{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG +\n",
    "        r\"{,1000}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara)\" +\n",
    "        r\"(\\s*dos\\s*deputados)([^\\.\" + MARKER_VALID +\n",
    "        \"]*?resolve\\s*:)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" +\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\3\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\"\n",
    "    ), 1),\n",
    "    \n",
    "    (regex.compile( #8\n",
    "        r\"(MEDIDA\\s*PROVIS[ÓO]RIA\" + ALL_BUT_NEWSEG + r\"{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1200}?)\" +\n",
    "        r\"([OA]\\s*President[ea]\\s*da\\s*rep[úu]blica[^:\" + MARKER_VALID +\n",
    "        r\"]+?com\\s*for[cç]a\\s*de\\s*lei\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, 1),\n",
    "    (regex.compile( #9\n",
    "        r\"\\s*\".join([\n",
    "            r\"(\",\n",
    "            r\"(?:\",\n",
    "            *r\"Documento\",\n",
    "            r\"|\",\n",
    "            *r\"Chancela\",\n",
    "            r\")\",\n",
    "            *r\"eletr\",\n",
    "            r\"[oô]\",\n",
    "            *r\"nic\",\n",
    "            r\"[ao]\",\n",
    "            r\".{,400}?\",\n",
    "            *r\"mesa\",\n",
    "            NRO,\n",
    "            r\"[\\s0-9]+\",\n",
    "            r\"(?:de|/|\\\\)\",\n",
    "            \"(?:\\s*[0-9]\\s*){4}\",\n",
    "            r\"\\.\",\n",
    "            r\")\",\n",
    "        ]),\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #10 #PL n .1 31 1/ 20 20 Ap re se nt aç ão : 3 1/ 03 /2 02 0 13 : 0 4\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + DOC_ABBVR_WITH_SPACES + \"\\s*\" + f\"(?:{NRO})*\" + r\"\\s*[\\d\\s]+/[\\s\\d]+)?+\\s*\" +\n",
    "        r\"\\s*\".join([\"\", *\"Apresenta\", \"[çc]\", \"[aã]\", *\"o:\", \"\"]) +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){4}\" + r\"\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*:\\s*\" +\n",
    "        r\")\" +\n",
    "        f\"({MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        f\"({MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        r\"(?:\" +\n",
    "        r\"([-–]*)\" +\n",
    "        r\"(\" + r\"\\s*\".join([\"\", *\"Mesa\", \"\"]) + r\")\" +\n",
    "        r\")?\" +\n",
    "        r\"([\\s0-9]+(?=[\\s0-9]*(?:[§\" + UPPERCASE_LETTERS + r\"]|$)))?\"\n",
    "        , regex.IGNORECASE | regex.MULTILINE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\5\" + MARKER_INTENDED_CORRUPTION + r\"\\6\" + MARKER_INTENDED_CORRUPTION + r\"\\7\\8\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (DetectRecurrentNoise, #11\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #12\n",
    "#         r\"([:;\" + QUOTES + r\"\\?]\\s*\" + f\"{PREFIX_EXTENSIONS}?)\" +\n",
    "#         r\"(\\s{,10}[-–])\" +\n",
    "#         f\"(?!\\s*{MARKER_NOISE_START})\"\n",
    "        r\"_________PLACEHOLDER_________\"\n",
    "    ),\n",
    "    lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    (regex.compile( #13\n",
    "        r\"((?<!\\s[sS]\\s*\\.\\s*[aA]\\s*|[lL][tT][dD][aA]\\s*)\\.)\" +\n",
    "        r\"(\\s{,10}[-–])(?=\\s*[\" + UPPERCASE_LETTERS + \"])\"),\n",
    "    lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    (regex.compile( #14\n",
    "        r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #15\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,\" + MARKER_VALID + r\"]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double, None),\n",
    "    \n",
    "    (regex.compile( #16\n",
    "        r\"(\" +\n",
    "        r\"(?:TVR|(?:Ato\\s*de\\s*)?Concess[aã]o(?:e|\\s)*Renova[cç][ãa]o(?:de|\\s)*Concess[aã]o(?:de|\\s)*Emissora(?:de|\\s)*Rádio(?:e|de|\\s)*Televisão)\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID}|{DEPT_EXTENSION}|{NRO}\\s*[_X\\s\\.,X0-9]*)+\" +\n",
    "        r\")\" +\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    \n",
    "    (regex.compile( #17\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*|\\s*DE\\s*CONVERS[AÃ]O\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)?\" +\n",
    "        f\"(?!{DEPT_EXTENSION})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #18\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*|\\s*DE\\s*CONVERS[AÃ]O\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)\" +\n",
    "        f\"(?:{UPPERCASE_DATE_OR_UNDERSCORES})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \"\n",
    "    ), 1),\n",
    "    \n",
    "    (regex.compile( #19\n",
    "        r\"(?<=[\" + UPPERCASE_LETTERS + \"]{3,}\\s+)([0-9]{1,2}\\s*\\.\\s+[0-9]+)\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    \n",
    "    (regex.compile( #20\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*|ou|,)\\s*)\" +\n",
    "        r\"(?:([^0-9a-z\\s\" + MARKER_VALID +\n",
    "        r\"]?)(\\s*(?:0xx)?[0-9]{2,}\\s*)([^0-9a-z\\s\" + MARKER_VALID + r\"]?))?\" +\n",
    "        r\"(\\s*[0-9]{4,}\\s*[-–\\.\\s]?)(\\s*[0-9]{4,})\" +\n",
    "        r\"((?:\\s*/\\s*[0-9]{4,}\\s*)*)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\5\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\6\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\7\" + MARKER_INTENDED_CORRUPTION + f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #21\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.\" + MARKER_VALID + r\"]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    \n",
    "    (regex.compile( #22\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.\" + MARKER_VALID + r\"]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})?\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    \n",
    "    (regex.compile( #23\n",
    "        r\"(OF[IÍ]CIO\\s*\" + NRO + r\"\" + ALL_BUT_NEWSEG + r\"{,110}?\\s*)\" +\n",
    "        r\"((?:Bras[ií]lia|Senado\\s*Federal)?[,\\s]*(?:\" + DATE_OR_UNDERSCORES + r\")[\\.\\s]*)\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,500}?\\s*)\" +\n",
    "        r\"(Assunto\\s*:\\s*\" + ALL_BUT_NEWSEG + r\"{,400}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED}|{REQUEST_PRONOUN_COLON})\", regex.IGNORECASE\n",
    "    ),\n",
    "    fn_lambda_quad, 1),\n",
    "    \n",
    "    (regex.compile( #24\n",
    "        r\"(Atenciosamente\\s*),\" +\n",
    "        r\"(\\s*\" + ALL_BUT_NEWSEG + r\"{,250}?\" +\n",
    "        RE_DOC_CODE_FULL +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\",\\2\" + f\" {symb} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #25\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,10}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        r\"([ÀÁA]\\s*sua\\s*excel[eê]ncia\" + ALL_BUT_NEWSEG + r\"{,100}?)\" +\n",
    "        r\"(?=(?:\" + REQUEST_PRESIDENT_OR_MINISTRY + \"[,\\s]*)?(?:Requeiro|Solicito))\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, 1),\n",
    "    \n",
    "    (regex.compile( #26\n",
    "        r\"(Autora?\\s*:\\s*\" + ALL_BUT_NEWSEG + r\"{,200}?)(\\s*Relatora?\\s*:)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    (regex.compile( #27\n",
    "        r\"(?<=(?:Relatora?|Autora?)\\s*:\" + ALL_BUT_NEWSEG + r\"{,200}?\\s+)(\" + VALID_ROMAN_NUM + r\"[-–\\s]+RELAT[OÓ]RIO\\s+)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    \n",
    "    (AgreementList, #28\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    \n",
    "    (regex.compile( #29\n",
    "        r\"(?=Reiterando\\s*os\\s*votos\\s*de\\s*apre[cç]o\\s*e\\s*considera[cç][aã]o)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #30\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*)\\s*)?\" +\n",
    "        r\"(?:([^0-9a-z\" + MARKER_VALID + r\"]?)(\\s*(?:0xx)?[0-9]{2,}\\s*)([^0-9a-z\" + MARKER_VALID + r\"]?))?\" +\n",
    "        r\"(\\s*[0-9]{4,}\\s*[-–\\.\\s]?)(\\s*[0-9]{4,})\" +\n",
    "        r\"((?:\\s*/\\s*[0-9]{4}\\s*)*)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\5\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\6\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\7\" + f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #31\n",
    "        r\"(\" +\n",
    "        r\"(?:DESPACHO\\s*:\\s*|\\(\\s*)?\" +\n",
    "        f\"\\s*[AÃÁÀ]S\\s*{COMMISSIONS}\\s*\" +\n",
    "        r\"\\(\\s*\" +\n",
    "        r\")\" +\n",
    "        r\"(ART(?:IGO)?[\\s\\.]+)\" +\n",
    "        r\"([0-9]+.{,60}?\\))\" +\n",
    "        r\"(.{,20}?\\))?\" +\n",
    "        r\"(?=.{,150}$)\", regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + r\"\\1\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\4\" + f\" {symb} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #32\n",
    "        PRACA_DTP_NEIGHBORS + r\"(?P<g_PRACA>.{,6}?\" +\n",
    "        f\"{PRACA_DTP})|(?P<g_PRACA>{PRACA_DTP}\" +\n",
    "        r\".{,6}?)\" + PRACA_DTP_NEIGHBORS,\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" +\n",
    "        r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\\3\\4 \" + MARKER_INTENDED_CORRUPTION + r\"\\5\" +\n",
    "        f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #33\n",
    "        r\"(^\\s*[0-9][\\s0-9]*|(?<!:[\\s0-9_]*)(?:[0-9]+_+)?\\s*[0-9][\\s0-9]*(?:\\.docx?\\s*)?$)\"\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #34\n",
    "        f\"({CEP}(?<g_cep_sep>[-–\\s]*){BRASILIA})\",\n",
    "        regex.IGNORECASE\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_fst>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_snd>\" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_sep>\" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_name>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_df>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #35\n",
    "        f\"{BRASILIA}(?<g_cep_sep>[-–\\s]*){CEP}\",\n",
    "        regex.IGNORECASE\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_name>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_df>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_sep>\" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_fst>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_snd>\" +\n",
    "        f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #36\n",
    "        r\"([:;\" + QUOTES + r\"\\?]\\s*\" + f\"{PREFIX_EXTENSIONS}?)\" +\n",
    "        r\"(\\s{,10}[-–])\" +\n",
    "        f\"(?!\\s*{MARKER_NOISE_START})\"\n",
    "    ),\n",
    "    lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    ####################\n",
    "    \n",
    "    (regex.compile( #37\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*)\" +\n",
    "        r\"(\" +\n",
    "        r\"(?:(?:web.?|home\\.?)?(?:Site|page)|S[ií]tio|Endere[cç]o)s?\\s*(?:eletr[oô]nicos?)?[\\s:]*\" +\n",
    "        r\"(?:https?://)?\" +\n",
    "        r\"www\\.([^\\s\\.\" + MARKER_VALID + r\"]+\\.){1,5}[^\\s\" + MARKER_VALID + r\"]+\" +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #38\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*|\" +\n",
    "        r\"\\(\\s*(?:NR|AC|\\.{3})\\s*\\)\\s*)\" +\n",
    "        r\"([0-9]+)(?=\\s*(?:Art|§|Par[aá]grafo|(?:Sub)?se[cç][aã]o))\", regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #39\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*)([^\\s\" + MARKER_VALID + UPPERCASE_LETTERS + r\"])((?:\\s|\\2)*)(\\s*)\" +\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\\4\" + f\" {symb_end} {deb} \", None),\n",
    ")\n",
    "\n",
    "RE_PRE_POST_BLOCKS = tuple(\n",
    "    regex.compile(\n",
    "        f\"{pattern}\" +\n",
    "        f\"(\\s*{MARKER_NOISE_START}{ALL_BUT_NEWSEG}*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\",\n",
    "        reg_flags,\n",
    "    )\n",
    "    for pattern, reg_flags in [\n",
    "        ( #0\n",
    "            r\"(ACORDO\\s*DE\\s*[-,\"\n",
    "            + UPPERCASE_LETTERS_OR_NUM\n",
    "            + r\"\\s]+)(?=(?:[OA]\\s+)?[\"\n",
    "            + UPPERCASE_LETTERS\n",
    "            + r\"][a-z])\",\n",
    "            0,\n",
    "        ),\n",
    "        (r\"(?<!\\(\" + ALL_BUT_NEWSEG + r\"{,50}?)(\" + COMMISSIONS + \")\", 0), #1\n",
    "        ( #2\n",
    "            r\"(O\\s*Congresso\\s*Nacional\\s*\" +\n",
    "            ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "            r\"\\s*decreta\\s*\" + ALL_BUT_NEWSEG + r\"{,40}?\\s*:)\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #3\n",
    "            r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*\" +\n",
    "            ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "            r\"\\s*decreta\\s*\" + ALL_BUT_NEWSEG +\n",
    "            r\"{,40}?\\s*:)\",\n",
    "            regex.IGNORECASE\n",
    "        ),\n",
    "        ( #4\n",
    "            r\"((?:SUBSTITUTIVO\\s*AO\\s*)?\" +\n",
    "            r\"Projeto\\s*de\\s*Lei\\s*\" +\n",
    "            r\"(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*|\\s*DE\\s*CONVERS[AÃ]O\\s*)*\\s*\" +\n",
    "            f\"(?:{DATE_AND_ID})?\" + r\"\\s*\"+ DEPT_EXTENSION + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #5\n",
    "            r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Decreto\\s*Legislativo\\s*\" +\n",
    "            DATE_AND_ID +\n",
    "            f\"(?:{DEPT_EXTENSION})?\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #5\n",
    "            r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Resolu[cç][aã]o\\s*\" +\n",
    "            f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #6\n",
    "            r\"(?<=^[^\\(]{,500}?)(Mensagem\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*)\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #7\n",
    "            r\"((?:SUBSTITUTIV[AO]\\s*[ÁÀA]\\s*)?\" +\n",
    "            r\"Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "            f\"(?:{DEPT_EXTENSION})\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        *[ #8, 9, 10\n",
    "            (\n",
    "                r\"(\" +\n",
    "                f\"{LARGER_BLOCKS_HIERARCHY[i]}\" + r\"\\s*\" + f\"(?:{VALID_ROMAN_NUM}|[0-9]+)\" +\n",
    "                r\"(?:[-–\\.\\s,\" + UPPERCASE_LETTERS_OR_NUM + r\"])+?\" +\n",
    "                r\"(?:\\s*\" +\n",
    "                MARKER_NOISE_START + r\"\" + ALL_BUT_NEWSEG + r\"{,800}?\" + MARKER_NOISE_END +\n",
    "                r\"\\s*\" + f\"{DEBUG_PATTERN}*\" +\n",
    "                r\"\\s*)?\" +\n",
    "                f\"(?={MARKER_VALID}|\" + r\"|\".join(LARGER_BLOCKS_HIERARCHY[i + 1:]) + r\")\" +\n",
    "                r\")\",\n",
    "                regex.IGNORECASE,\n",
    "            )\n",
    "            for i in range(len(LARGER_BLOCKS_HIERARCHY) - 1)\n",
    "        ],\n",
    "        ( #11, Esta lei entra em vigor cento e oitenta dias após a data de sua publicação\n",
    "            r\"(Art\" + ALL_BUT_NEWSEG + r\"{,10}?Est[áàãa]\\s*\" +\n",
    "            r\"(?:lei|EC|Emenda\\s*(?:Constitucional|[àaá\\s]*constitui[cç][aã]o)|resolu[cç][aã]o)\\s*\" +\n",
    "            r\"entr[ea]\\s*em\\s*vigor\\s*\" + ALL_BUT_NEWSEG +\n",
    "            r\"{,100}?\\s*(?:data\\s*de\\s*)sua\\s*publica[cç][aã]o\\s*(?:\\.|$))\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        (r\"(APRECIA[CÇ][AÃ]O\\s*:\" + ALL_BUT_NEWSEG + r\"{,100})$\", 0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "RE_POST_PROCESSING_BLOCKS = (\n",
    "    (PostProcRecurrentNoise, #0\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"),\n",
    "    \n",
    "    (regex.compile( #1\n",
    "        r\"(\" +\n",
    "#         f\"(?<![{UPPERCASE_LETTERS_OR_NUM}])\" +\n",
    "        f\"[^{UPPERCASE_LETTERS_OR_NUM}{MARKER_VALID}]\" +\n",
    "        r\"[0-9]\" +\n",
    "        r\"[\\]\\)\\s]+\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,120}?\" +\n",
    "        SOURCE_URL +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE | regex.REVERSE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        r\"(?<=\"\n",
    "        r\"(?:^\\s*(?!.{,20}C[ÂA]MARA).{,20}?\\s*|\" +\n",
    "        f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"\\s*\" +\n",
    "        r\")\"+\n",
    "        r\"(\" +\n",
    "        f\"(?:Gabinete\\s*d[oa]|^\\s*|(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*))\" +\n",
    "        r\"\\s*deputad[oa]\\s*(?:federal)?\\s*\" +\n",
    "        f\"{ALL_BUT_NEWSEG}\" + r\"{,200}?\" +\n",
    "        r\")\" +\n",
    "        f\"(?={MARKER_VALID}|{MARKER_NOISE_START})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"({MARKER_VALID}\\s*{DEBUG_PATTERN}*)(\\s*)\" +\n",
    "        f\"(\\s+[{UPPERCASE_LETTERS_OR_NUM}]\" + r\"{1,3}\\s+)\" +\n",
    "        f\"(?=\\s*{MARKER_VALID}|\\s*$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\3\\2\" + f\" {symb_end} {deb} \" + r\"\\1\"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG +\n",
    "        r\"{,10}?\\s*C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,10}?)\" +\n",
    "        f\"(?={MARKER_NOISE_START})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"(?<={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*{ALL_BUT_NEWSEG}\" +\n",
    "        r\"{60,}?\" +\n",
    "        f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"([^\" + \"\".join([MARKER_VALID, MARKER_NOISE_START[0], MARKER_NOISE_END[0]]) + r\"]{1,90})\"\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*{ALL_BUT_NEWSEG}\" +\n",
    "        r\"{60,}?\"\n",
    "        f\"{MARKER_NOISE_END})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    (regex.compile(\n",
    "        f\"({MARKER_VALID}\\s*{DEBUG_PATTERN}*)(\\s*)\" +\n",
    "        f\"(\\s+[{UPPERCASE_LETTERS_OR_NUM}]\" + r\"{1,3}\\s+)\" +\n",
    "        f\"({MARKER_NOISE_START}{ALL_BUT_NEWSEG}*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\"\n",
    "        f\"(?=\\s*{MARKER_VALID}|\\s*$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\3\\2\" + f\" {symb_end} {deb} \" + r\"\\4\\1\"\n",
    "    )),\n",
    ")\n",
    "\n",
    "RE_HIGH_PRIORITY_BLOCKS = (\n",
    "    (DetectRecurrentMetadata, #0\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    ")\n",
    "\n",
    "\n",
    "RE_POST_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={pattern})\", regex.IGNORECASE)\n",
    "    for pattern in []\n",
    ")\n",
    "COALESCE_NOISE = regex.compile(\n",
    "    f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*\"\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False, coalesce_noise: bool = True) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, (reg, fun, fun_post) in enumerate(RE_HIGH_PRIORITY_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_HIGH_PTY\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=False)\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(\n",
    "            f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \",\n",
    "            text,\n",
    "            concurrent=False,\n",
    "        )\n",
    "    \n",
    "    for i, (reg, fun, sub_count) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=False, count=sub_count or 0)\n",
    "\n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=False)\n",
    "        \n",
    "    for i, reg in enumerate(RE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=False)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(\n",
    "            f\" {MARKER_VALID} {debug_text} \" + r\"\\1\\2\" + f\" {MARKER_VALID} {debug_text} \",\n",
    "            text,\n",
    "            concurrent=True,\n",
    "        )\n",
    "        \n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    for i, (reg, fun) in enumerate(RE_POST_PROCESSING_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POST_PROC\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=False)\n",
    "        \n",
    "\n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def preprocess_instance(\n",
    "        item, ind, print_preprocessed: bool = False, debug: bool = False, coalesce_noise: bool = True):    \n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug, coalesce_noise=coalesce_noise)\n",
    "    preprocessed_text = preprocessed_text.replace(MARKER_INTENDED_CORRUPTION, \"@\" if debug else \"\")\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(colorama.Fore.WHITE, colorama.Style.DIM, preprocessed_text, colorama.Style.RESET_ALL, sep=\"\")\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            cur_token = tokens.pop(i)\n",
    "            cur_label = labels.pop(i)\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_START]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_END:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_NOISE_END:\n",
    "                # labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            labels[i] = SPECIAL_SYMBOLS[cur_token]\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels:\n",
    "        maybe_erase_pool = []\n",
    "        noise_on = False\n",
    "\n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                labels[i] = labels[i + 1] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                maybe_erase_pool.clear()\n",
    "                continue\n",
    "\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                while maybe_erase_pool:\n",
    "                    ind = maybe_erase_pool.pop()\n",
    "                    labels[ind] = 0\n",
    "\n",
    "            if labels[i] > 0:\n",
    "                maybe_erase_pool.append(i)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                if noise_on:\n",
    "                    labels[i] = 0\n",
    "                else:\n",
    "                    noise_on = True\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                if noise_on:\n",
    "                    noise_on = False\n",
    "                else:\n",
    "                    labels[i] = 0\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                noise_on = False\n",
    "            \n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                labels[i] = 0\n",
    "            \n",
    "        while tokens and tokens[0] in SPECIAL_SYMBOLS:\n",
    "            labels.pop(0)\n",
    "            tokens.pop(0)\n",
    "\n",
    "        while tokens and tokens[-1] in SPECIAL_SYMBOLS:\n",
    "            labels.pop()\n",
    "            tokens.pop()\n",
    "        \n",
    "        if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "            labels[0] = 0\n",
    "    \n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "if DEV_RUN:\n",
    "    auxaux = \"\"\"\n",
    "CÂMARA DOS DEPUTADOS \n",
    " \n",
    "REQUERIMENTO Nº               , DE 2019 \n",
    "(Do Sr. Nicoletti) \n",
    " \n",
    " para uma única instituição . Na data de 28 de Março p.p. , o nosso Presidente da República publicou em suas redes sociais que essa instituição já teria adquirido 100 ( cem ) novos leitos de UTIs . Segue o link : https : //www.instagram.com/p/B- * C D2 06 77 66 09 40 0 * Le xE di t RI C n . 33 3/ 20 20 Ap re se nt aç ão : 0 1/ 04 /2 02 0 15 :5 9 S0gCbBxlQ/ ? \n",
    "\n",
    "\"\"\".replace(\" , \", \", \").replace(\" . \", \". \")\n",
    "    res=preprocess_instance({\"text\": auxaux}, -1, True, debug=True, coalesce_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T22:47:32.114558Z",
     "start_time": "2022-03-05T22:44:38.120775Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-46b3e822caba5a99\n",
      "Reusing dataset csv (../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e2013b4f724e0c885ad01b37acf6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-8aa3bb54f5af798d.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-c193758333c74832.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-d427d4e1d50f0f25.arrow\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START if DEV_RUN else None,\n",
    "    nrows=(DATASET_ROW_END - DATASET_ROW_START + 1) if DEV_RUN else None,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A?\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[\" + UPPERCASE_LETTERS + r\"])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÂÃÀÁ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aãâàá]\\s*o\\s+(?=[\" + UPPERCASE_LETTERS + r\"])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=None if DEV_RUN else \"text\")\n",
    "\n",
    "rerun_tests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T17:24:45.616588Z",
     "start_time": "2022-03-03T17:24:45.613685Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:27:11.074692Z",
     "start_time": "2022-03-05T23:27:03.001171Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChosen id:\u001b[39m 2711\n",
      "\n",
      "\u001b[37m\u001b[2m \n",
      "REQUERIMENTO Nº          , DE 2019 \n",
      "(Do Sr. CAPITÃO ALBERTO NETO) \n",
      " \n",
      "Requer o envio de Indicação ao Poder \n",
      "Executivo, sugerindo que, no âmbito de sua \n",
      "competência supletiva, o Ministério da \n",
      "Educação desenvolva programa de apoio \n",
      "aos sistemas de ensino que estabelecem \n",
      "gestão compartilhada de escolas com as \n",
      "polícias militares. \n",
      " \n",
      "Senhor Presidente: \n",
      " \n",
      "Nos termos do art. 113, inciso I e § 1º, do Regimento Interno da \n",
      "Câmara dos Deputados, requeiro a V. Exª. seja encaminhada ao Poder \n",
      "Executivo a Indicação anexa, sugerindo que, no âmbito de sua competência \n",
      "supletiva, o Ministério da Educação desenvolva programa de apoio aos \n",
      "sistemas de ensino que estabelecem gestão compartilhada de escolas com as \n",
      "polícias militares. \n",
      " \n",
      "Sala das Sessões, em 24 de junho de 2019. \n",
      " \n",
      " \n",
      "CAPITÃO ALBERTO NETO \n",
      "Deputado Federal PRB/AM \n",
      " \n",
      "2 \n",
      "INDICAÇÃO Nº      , DE 2019 \n",
      "(Do Sr. CAPITÃO ALBERTO NETO) \n",
      "Sugere que, no âmbito de sua \n",
      "competência supletiva, o Ministério da \n",
      "Educação desenvolva programa de apoio \n",
      "aos sistemas de ensino que estabelecem \n",
      "gestão compartilhada de escolas com as \n",
      "polícias militares. \n",
      "Excelentíssimo Senhor Ministro de Estado da Educação: \n",
      "Em vários estados, entre os quais destacamos Amazonas, \n",
      "Goiás e o Distrito Federal, a gestão de escolas públicas estaduais, situadas em \n",
      "regiões de alta vulnerabilidade social e com elevados índices de violência no \n",
      "ambiente escolar, tem sido entregue, mediante parceria com a Secretaria de \n",
      "Educação Estadual, à Polícia Militar. \n",
      "Essas experiências têm apresentado indicadores \n",
      "absolutamente positivos, com nítidas melhorias na cultura de paz das escolas, \n",
      "diminuição do uso e do tráfico de drogas e melhoria da aprendizagem dos \n",
      "estudantes. Evidência marcante desse modelo de gestão escolar é a alta \n",
      "demanda, por parte dos pais e responsáveis, para matricular os alunos nessas \n",
      "instituições de ensino. \n",
      "Iniciativas em políticas públicas com bons resultados devem \n",
      "merecer a atenção para que as boas práticas educacionais sejam replicadas. \n",
      "Portanto, esta Indicação objetiva sugerir à equipe desse nobre Ministério da \n",
      "Educação que, entre os seus programas de assistência técnica e financeira aos \n",
      "entes federados subnacionais, haja vista a competência supletiva desse órgão \n",
      "em matéria educacional, desenvolva programa de apoio aos sistemas de \n",
      "ensino que estabelecem gestão compartilhada de escolas com as polícias \n",
      "militares, de modo a fomentar a articulação entre as redes de ensino e as \n",
      "corporações de polícia militar estadual, em benefício da qualidade da educação \n",
      " \n",
      "escolar, notadamente para os que frequentam instituições de ensino situadas \n",
      "em contextos de vulnerabilidade social. \n",
      "Nosso pleito está embasado nas premissas da Lei nº 9.394, de \n",
      "20 de dezembro de 1996 (LDB). Entre outras disposições, o art. 12 da referida \n",
      "legislação preceitua que os estabelecimentos de ensino terão a incumbência \n",
      "de estabelecer ações destinadas a promover a cultura de paz nas escolas \n",
      "(inciso X) e promover ambiente escolar seguro, adotando estratégias de \n",
      "prevenção e enfrentamento ao uso ou dependência de drogas (inciso XI). É \n",
      "salutar que o Ministério da Educação apoie os sistemas de ensino nessa \n",
      "empreitada, o que ratifica o pleito evidenciado nesta Indicação. \n",
      "Ante o exposto, Senhor Ministro, ao passo que o saudamos, \n",
      "estamos certos de que o mérito da sugestão ora apresentada haverá de \n",
      "receber atenção especial desse Ministério no sentido de promover a sua \n",
      "implementação, motivo que nos incita a pedir-lhe que nos encaminhe \n",
      "expedientes referentes às ações provenientes desta Indicação. \n",
      "Sala das Sessões, em 24 de Junho de 2019. \n",
      "CAPITÃO ALBERTO NETO \n",
      "Deputado Federal PRB/AM \n",
      " \n",
      "\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[0m\u001b[97m 1 \u001b[39m REQUERIMENTO Nº , DE 2019 ( Do Sr. CAPITÃO ALBERTO NETO )\n",
      "\n",
      "\u001b[97m 2 \u001b[39m Requer o envio de Indicação ao Poder Executivo , sugerindo que , no âmbito de sua competência supletiva , o Ministério da Educação desenvolva programa de apoio aos sistemas de ensino que estabelecem gestão compartilhada de escolas com as polícias militares .\n",
      "\n",
      "\u001b[97m 3 \u001b[39m Senhor Presidente : Nos termos do art . 113 , inciso I e § 1º , do Regimento Interno da Câmara dos Deputados , requeiro a V. Exª . seja encaminhada ao Poder Executivo a Indicação anexa , sugerindo que , no âmbito de sua competência supletiva , o Ministério da Educação desenvolva programa de apoio aos sistemas de ensino que estabelecem gestão compartilhada de escolas com as polícias militares .\n",
      "\n",
      "\u001b[97m 4 \u001b[39m Sala das Sessões , em 24 de junho de 2019 . CAPITÃO ALBERTO NETO Deputado Federal PRB/AM 2\n",
      "\n",
      "\u001b[97m 5 \u001b[39m INDICAÇÃO Nº , DE 2019 ( Do Sr. CAPITÃO ALBERTO NETO )\n",
      "\n",
      "\u001b[97m 6 \u001b[39m Sugere que , no âmbito de sua competência supletiva , o Ministério da Educação desenvolva programa de apoio aos sistemas de ensino que estabelecem gestão compartilhada de escolas com as polícias militares .\n",
      "\n",
      "\u001b[97m 7 \u001b[39m Excelentíssimo Senhor Ministro de Estado da Educação : Em vários estados , entre os quais destacamos Amazonas , Goiás e o Distrito Federal , a gestão de escolas públicas estaduais , situadas em regiões de alta vulnerabilidade social e com elevados índices de violência no ambiente escolar , tem sido entregue , mediante parceria com a Secretaria de Educação Estadual , à Polícia Militar . Essas experiências têm apresentado indicadores absolutamente positivos , com nítidas melhorias na cultura de paz das escolas , diminuição do uso e do tráfico de drogas e melhoria da aprendizagem dos estudantes . Evidência marcante desse modelo de gestão escolar é a alta demanda , por parte dos pais e responsáveis , para matricular os alunos nessas instituições de ensino . Iniciativas em políticas públicas com bons resultados devem merecer a atenção para que as boas práticas educacionais sejam replicadas . Portanto , esta Indicação objetiva sugerir à equipe desse nobre Ministério da Educação que , entre os seus programas de assistência técnica e financeira aos entes federados subnacionais , haja vista a competência supletiva desse órgão em matéria educacional , desenvolva programa de apoio aos sistemas de ensino que estabelecem gestão compartilhada de escolas com as polícias militares , de modo a fomentar a articulação entre as redes de ensino e as corporações de polícia militar estadual , em benefício da qualidade da educação escolar , notadamente para os que frequentam instituições de ensino situadas em contextos de vulnerabilidade social . Nosso pleito está embasado nas premissas da Lei nº 9.394 , de 20 de dezembro de 1996 ( LDB ) . Entre outras disposições , o art . 12 da referida legislação preceitua que os estabelecimentos de ensino terão a incumbência de estabelecer ações destinadas a promover a cultura de paz nas escolas ( inciso X ) e promover ambiente escolar seguro , adotando estratégias de prevenção e enfrentamento ao uso ou dependência de drogas ( inciso XI ) . É salutar que o Ministério da Educação apoie os sistemas de ensino nessa empreitada , o que ratifica o pleito evidenciado nesta Indicação . Ante o exposto , Senhor Ministro , ao passo que o saudamos , estamos certos de que o mérito da sugestão ora apresentada haverá de receber atenção especial desse Ministério no sentido de promover a sua implementação , motivo que nos incita a pedir-lhe que nos encaminhe expedientes referentes às ações provenientes desta Indicação .\n",
      "\n",
      "\u001b[97m 8 \u001b[39m Sala das Sessões , em 24 de Junho de 2019 . CAPITÃO ALBERTO NETO Deputado Federal PRB/AM\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   2711: 8, 0\n",
      "Is it correct? [y/N]: y\n",
      "Added to test cases.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    #\n",
    "    id_ = None\n",
    "    \n",
    "    if id_ is not None:\n",
    "        print(tests.TEST_CASES[id_])\n",
    "        tests.print_results(df, id_, print_full_text=True)\n",
    "#         tests.update_test_case(id_, (8, 1))\n",
    "        assert False\n",
    "    \n",
    "    if rerun_tests:\n",
    "        try:\n",
    "            tests.run_tests(df[\"train\"][\"labels\"])\n",
    "            rerun_tests = False\n",
    "\n",
    "        except AssertionError as e:\n",
    "            raise AssertionError from e\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    document_idx = min(9090, df[\"train\"].num_rows - 1)\n",
    "    while tests.test_case_exists(document_idx):\n",
    "        document_idx = random.randint(0, df[\"train\"].num_rows)\n",
    "\n",
    "    print(colorama.Fore.YELLOW + \"Chosen id:\" + colorama.Fore.RESET, document_idx, end=\"\\n\\n\")\n",
    "\n",
    "    expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "    print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "    inp = input()\n",
    "    if inp == \"y\":\n",
    "        tests.update_test_case(document_idx, expected_test_case_values)\n",
    "        print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T23:27:12.995769Z",
     "start_time": "2022-03-05T23:27:12.988831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 80 test cases at './test_cases/100001_110000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
