{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T22:36:38.363299Z",
     "start_time": "2022-02-28T22:36:38.358800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "No test cases found at './test_cases/100001_110000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "DEV_RUN = True\n",
    "\n",
    "\n",
    "random.seed(198)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "DATASET_ROW_START = None\n",
    "DATASET_ROW_END = None\n",
    "if DEV_RUN:\n",
    "    TESTS_DIR = \"test_cases\"\n",
    "    DATASET_ROW_START = 100001\n",
    "    DATASET_ROW_END = 110000\n",
    "    TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "    tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T18:39:46.210267Z",
     "start_time": "2022-02-28T18:39:41.122096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=DEV_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:24:22.040165Z",
     "start_time": "2022-03-01T03:24:21.584426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2mSenhor Presidente, Nos termos do art. 113, inciso I e parágrafo 1º, do Regimento Interno da Câmara dos Deputados, requeiro o envio de Indicação ao Poder Executivo, por meio do Ministro da Economia, Paulo Guedes, sugerindo a isenção do Imposto de Importação (II), incidente sobre a comercialização de dispositivos protéticos necessários à reabilitação de pessoas amputadas.  ❌s__ @@@ ❌s__ 8_SPECIAL *C D2 02 64 89 71 10 0* ❌s__ 7_SPECIAL   ❌e__ 8_SPECIAL @@Do cu m en to e le tr ôn ic o as sin ad o po r W ol ne y Q ue iro z (P DT /P E), a tr av és d o po nt o SD R_ 56 16 4, na fo rm a do a rt. 1 02, § 1 º, d o RI CD c /c o a rt. 2 º, d o At o da M es a n. 8 0 de 2 01 6. PL n .4 92 3/ 20 20 Ap re se nt aç ão : 1 4/ 10 /2 02 0 16 : ❌s__ 14_NOISE 5 ❌e__ 14_NOISE  7 @-@ M es a  ❌e__ 7_SPECIAL ✓ 9_PRE   ✓ 9_PRE Sala das Sessões, em ___ de  ❌s__ 2_NOISE ____________  ❌e__ 2_NOISE de 2020.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DEBUG_PATTERN = \"(?:\\s*[0-9]{1,3}_[A-Z]{1,30}\\s*)\"\n",
    "ALL_SPECIAL_MARKERS = f\"(?:{MARKER_INTENDED_CORRUPTION}|{MARKER_NOISE_START}|{MARKER_NOISE_END}|{MARKER_VALID})\"\n",
    "\n",
    "COMMISSION_LIST = (r\"\"\"\n",
    "    (?:\n",
    "    AGRICULTURA[,\\s]*PECU[AÁ]RIA[,\\s]*ABASTECIMENTO[E\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA[,\\s]*COMUNICA[CÇ][AÃ]O(?:[E\\s]|DA)*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*DE\\s*CIDADANIA|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*(?:DO|AO)\\s*CONSUMIDOR|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO[,\\s]*IND[UÚ]STRIA[,\\s]*COM[EÉ]RCIO(?:[E\\s]|DE)*SERVI[CÇ]OS|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS(?:[E\\s]|DAS)*MINORIAS|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS[E\\s]*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA[E\\s]*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL[,\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*REGIONAL(?:[E\\s]|DA)*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    (?:MEIO\\s*)?AMBIENTE[E\\s]*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS(?:[E\\s]|DA)*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES(?:[E\\s]|DE)*\\s*DEFESA\\s*NACIONAL|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL(?:[E\\s]|DA)*FAMÍLIA|\n",
    "    TRABALHO[,\\s]*ADMINISTRA[CÇ][AÃ]O[E\\s]*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES|\n",
    "    INQUÉRITO\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "COMMISSIONS = (\n",
    "    r\"COMISS[AÃ]O\\s*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:D[EOA]S?|[,;\\s]*E|[;,]\\s*E?|PARLAMENTAR)\\s*)+\" +\n",
    "    COMMISSION_LIST +\n",
    "    r\"\\s*)+\"\n",
    ")\n",
    "\n",
    "\n",
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(r\"\\*([\\sA-Z0-9]+)\\*\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(.{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_CAMARA_REPEATED = regex.compile(\n",
    "        r\"(?:(C[AÂ]MARA\\s*)(DOS\\s*)(DEPUTADOS[\\s0-9]*(?!\\s*[-–\\.\\)])))\",\n",
    "    )\n",
    "    RE_COMMISSIONS_REPEATED = regex.compile(\n",
    "        f\"({COMMISSIONS})\"\n",
    "    )\n",
    "    RE_SALA_DAS_SESSOES_CODE = regex.compile(\n",
    "        r\"(?<=Sala\\s*das\\s*sess[oõ]es\\s*.{,150}?)([0-9]{1,5}\\s*_\\s*(?:\" +\n",
    "        MARKER_NOISE_START +\n",
    "        r\")?\\s*[0-9]{1,5})\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = sorted(set(pseudo_patterns))\n",
    "        \n",
    "        for pseudo_pattern in pseudo_patterns:\n",
    "            pattern = list(cls.RE_BLANK_SPACES.sub(\"\", pseudo_pattern))\n",
    "            pattern.append(\"\")\n",
    "            pattern.insert(0, \"\")\n",
    "            pattern = (r\"(?:\\s*(?:\" + MARKER_NOISE_START + r\")?\\s*\" + DEBUG_PATTERN + r\"*\\s*)\").join(pattern)\n",
    "            pattern = (\n",
    "                r\"(?:(\\s*C[AÂ]MARA\\s*)(DOS\\s*)(DEPUTADOS\\s*)([0-9][\\s0-9]*)?)?\" +\n",
    "                r\"(\\*\" +\n",
    "                pattern +\n",
    "                r\"\\*\\s*\" +\n",
    "                r\"(?:\" + MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*)?\\s*\" +\n",
    "                f\"(?:{pattern})?\" +\n",
    "                r\")\" +\n",
    "                r\"(?:(\\s*C[AÂ]MARA\\s*)(DOS\\s*)(DEPUTADOS))?\"\n",
    "            )\n",
    "            \n",
    "            mod_subpattern = (\n",
    "                f\" {MARKER_NOISE_START} \" +\n",
    "                MARKER_INTENDED_CORRUPTION.join([r\"\\1\", r\"\\2\", r\"\\3\", r\"\\4\"]) +\n",
    "                subpattern.replace(r\"\\1\", r\"\\5\") +\n",
    "                MARKER_INTENDED_CORRUPTION.join([r\"\\6\", r\"\\7\", r\"\\8\"]) +\n",
    "                \"\"\n",
    "            )\n",
    "            \n",
    "            text = regex.sub(pattern, mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara(cls, subpattern, text):\n",
    "        occurrences = cls.RE_CAMARA_REPEATED.findall(text)\n",
    "        \n",
    "        if len(occurrences) <= 2:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_REPEATED.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_commissions(cls, subpattern, text):\n",
    "        freqs = collections.Counter(map(str.strip, cls.RE_COMMISSIONS_REPEATED.findall(text)))\n",
    "        \n",
    "        for commission_name, freq in freqs.items():\n",
    "            if freq <= 2:\n",
    "                continue\n",
    "            \n",
    "            mod_subpattern = f\" {MARKER_INTENDED_CORRUPTION}\".join(cls.RE_BLANK_SPACES.split(commission_name))\n",
    "            mod_subpattern = subpattern.replace(r\"\\1\", mod_subpattern)\n",
    "            \n",
    "            text = text.replace(commission_name, mod_subpattern)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        text = cls.RE_SALA_DAS_SESSOES_CODE.sub(subpattern, text)\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        text = cls._detect_repeated_commissions(subpattern, text)\n",
    "        return text\n",
    "\n",
    "\n",
    "VALID_ROMAN_NUM = r\"M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3})\"\n",
    "NRO_SMALL = r\"[nN]\\s*[oO0º°\\.]{1,3}\"\n",
    "NRO = r\"(?:[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[oO0º°]|\" + NRO_SMALL + r\"\\s*(?=[0-9]))\"\n",
    "QUOTES = r\"”“”\\\"'‘\"\n",
    "QUOTES_CLASS = f\"[{QUOTES}]\"\n",
    "UPPERCASE_LETTERS = r\"ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z\"\n",
    "UPPERCASE_LETTERS_OR_NUM = UPPERCASE_LETTERS + r\"0-9\"\n",
    "\n",
    "ANNEX = r\"(?:Anexo\\s*\" + f\"(?:{VALID_ROMAN_NUM})\" + r\")\"\n",
    "CABINET = r\"(?:Gab(?:inete)?[\\.\\s]*[0-9]{1,5})\"\n",
    "NOISE_ANNEX_CABINET = (\n",
    "    r\"C[âa]mara\\s*dos\\s*Deputados\\s*.{,20}?\\s*\" +\n",
    "    r\"(\" +\n",
    "    ANNEX + r\"\\s*.{,20}?\\s*\" + CABINET +\n",
    "    r\"|\" +\n",
    "    CABINET + r\"\\s*.{,20}?\\s*\" + ANNEX +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "\n",
    "class AgreementList:\n",
    "    ITEMS = (\n",
    "        r\"(\\s*(?:\" +\n",
    "        r\"(?:[ÓO]rg[aã]o\\s*)?(?:Superior|[cC]oncedente|[cC]onve(?:nente|niada))|\" +\n",
    "        NRO + r\"\\s*(?:SIAFI|Original|Do\\s*conv[eê]nio)|\" +\n",
    "        r\"Valor\\s*(?:do\\s*conv[eê]nio)?|\" +\n",
    "        r\"(?:In[ií]cio|Fim)\\s*(?:d[ea]\\s*vig[eê]ncia)?|\" +\n",
    "        r\"Objeto|\" +\n",
    "        r\"Conv[eê]nio|\" +\n",
    "        r\"Processo|\" +\n",
    "        r\"Total\\s*de\\s*itens\\s*Licitados|\" +\n",
    "        r\"Fundamento\\s*legal|\"+\n",
    "        r\"Contratada|\" +\n",
    "        r\"Questionamentos|\" +\n",
    "        r\"Justificativa\"\n",
    "        r\")\\s*)\"\n",
    "    )\n",
    "    RE_ITEMS = regex.compile(ITEMS + r\"(\\s*:)\", regex.IGNORECASE)\n",
    "    REG_GET_LIST = regex.compile(\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + ITEMS + r\":\\s*[^:]{,150}?){2,10}\" +\n",
    "        ITEMS + r\":\\s*[^:]{,150}\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    @classmethod\n",
    "    def sub(cls, subpattern, text: str, *args, **kwargs):\n",
    "        re_match = cls.REG_GET_LIST.search(text)\n",
    "        if re_match is None:\n",
    "            return text\n",
    "        s_start, s_end = re_match.span()\n",
    "        text_slice = text[s_start:s_end]\n",
    "        subpattern = subpattern.replace(r\"\\1\", r\"\\1\" + f\" {MARKER_INTENDED_CORRUPTION} \" + r\"\\2\")\n",
    "        text_slice = cls.RE_ITEMS.sub(\n",
    "            subpattern,\n",
    "            text_slice,\n",
    "        )\n",
    "        text = f\"{text[:s_start]}{text_slice}{text[s_end:]}\"\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DOC_ABBVR = r\"(?:\" + \"|\".join((\n",
    "    \"COM\", \"DCR\", \"DEN\", \"DTQ\", \"DVS\", \"DVT\", \"EMC\", \"EMD\", \"EML\", \"LDO\", \"EMO\",\n",
    "    \"EMP\", \"EMR\", \"ERD\", \"ESB\", \"EXP\", \"INA\", \"INC\", \"MPV\", \"MSC\", \"PAR\", \"PDC\",\n",
    "    \"PEC\", \"PET\", \"PFC\", \"PLP\", \"PLV\", \"PRC\", \"PRF\", \"PRN\", \"PRO\", \"RCP\", \"REC\",\n",
    "    \"REL\", \"REM\", \"REP\", \"REQ\", \"RIC\", \"RPR\", \"SBE\", \"SBT\", \"SDL\", \"LDO\", \"SIT\",\n",
    "    \"TCU\", \"SOA\", \"STF\", \"SUG\", \"SUM\", \"CCJ\", \"TER\", \"TVR\", \"VTS\", \"PL\",\n",
    ")) + r\")\"\n",
    "\n",
    "\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "RAW_NUMBER_PREFIXES = (\n",
    "    r\"Art(?:igo)?s?\\s?\\.?\\s?|\" + NRO_SMALL + r\"|\\$|p[aá]g\\s*\\.\"\n",
    ")\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:(?:[-–º°0-9]+|[A-Z]{1,2})|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+|\" + QUOTES_CLASS + r\")(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\so0º°]*:\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\(?\\s+[0-9]{1,2}[\\s0oOº°]*(?:[-–\\)]|\\.(?![0-9]))\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\s+[0-9]{1,2}\\s*(?:\\.[0-9]+){1,2}(?![\\.0-9]*,)\",\n",
    ")\n",
    "\n",
    "MONTHS = \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    ")).upper()\n",
    "\n",
    "DATE = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*[0-9]{,2}\\s*(?:de|em)\\s*(?:\" + MONTHS + r\")\\s*(?:de|em)\\s*[0-9]{4}\"\n",
    ")\n",
    "\n",
    "DATE_OR_UNDERSCORES = (\n",
    "    r\"[,\\s]*(?:(?:de|em)[,\\.0-9\\s]*){1,3}(?:[0-9]{4}|[\\._]+)|\" +\n",
    "    r\"[,\\s]*(?:de|em)?\\s*(?:[0-9]{,2}|[\\._]+)\\s*(?:de|em)\\s*(?:\" + MONTHS +\n",
    "    r\"|_+)\\s*(?:de|em)\\s*(?:[0-9]{4}|[\\._]+)\"\n",
    ")\n",
    "\n",
    "UPPERCASE_DATE_OR_UNDERSCORES = DATE_OR_UNDERSCORES.replace(\"em\", \"EM\").replace(\"de\", \"DE\")\n",
    "\n",
    "EOF = r\".{,300}$\"\n",
    "\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    EOF +\n",
    "    r\"|\" +\n",
    "    DATE_OR_UNDERSCORES + \n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"030|Daniel|[eE]ss|Jaa|ac[fgp]|afpa|cmrv|(da[-–])?conle|[Cc]rps|\" +\n",
    "    r\"dennn?er|dpsl?|drb|epo|faa|‘?[Gg]ab|gsl|jaa|jbs|kvp|lgl|mlcl?|\" +\n",
    "    r\"mm|pnf|rpb|tksa|[Vv][Pp][Ll][cf]?|wgl\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_CORE = r\"(?:pls|mpv|plc|pec|pds|plv|prn|plp|pdl|tema)\"\n",
    "\n",
    "RE_DOC_CODE_SUFFIX = (\n",
    "    r\"(?:(?:\"\n",
    "    r\"c(?:ompleme?ntar)?|eme(?:nda)?s?|\" +\n",
    "    r\"rev(?:is)?|sub(?:st\\.?(?:itutivo)?)?|sust|tt?\" +\n",
    "    r\")\\s*?)*\"\n",
    ")\n",
    "\n",
    "RE_DOC_CODE_FULL = (\n",
    "    r\"(\" +\n",
    "    r\"(?<=\\s)\" +\n",
    "    RE_DOC_CODE_PREFIX +\n",
    "    \"/\" +\n",
    "    RE_DOC_CODE_CORE +\n",
    "    \"(?:[-–0-9]+)\" +\n",
    "    RE_DOC_CODE_SUFFIX +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"Sala\\s*d[ea]s?\\s*(?:sess|comiss|reuni)(?:[õo]es|[ãa]o)\" + EOF_OR_DATE,\n",
    "    r\"Senado\\s*Federal\\s*,\" + EOF_OR_DATE,\n",
    "    r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\" + EOF_OR_DATE,\n",
    "    r\"Bras[ií]lia\\s*,\\s*(?:\" + DATE_OR_UNDERSCORES + \")\\s*\",\n",
    "    r\"•\",\n",
    "    \"\\uF0B7\",\n",
    "    r\"As?\\s*mesas?\\s*da\\s*c[aâ]mara\\s*dos\\s*deputados[^:]{,300}?:\",\n",
    "    r\"Atenciosamente\\s*,\",\n",
    ")\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "#     regex.compile( #0\n",
    "#         r\"(\" +\n",
    "#         r\"(?:\" +\n",
    "#         r\"\\*[^\\*]{12,}\\*\" +\n",
    "#         r\"\\s*\".join([\"\", *\"Documentoeletr\", \"[oô]\", *\"nico\", \"\"]) +\n",
    "#         r\"\\s*.{,400}?\\s*\" +\n",
    "#         r\")?\" +\n",
    "#         r\"(?:(?:PL|PDL|PEC)\\s*n[\\.o\\sº]*[\\d\\s]+/[\\s\\d]+)?+\\s*\" +\n",
    "#         r\"A\\s*p\\s*r\\s*e\\s*s\\s*e\\s*n\\s*t\\s*a\\s*[cç]\\s*[aã]\\s*o\\s*:\" +\n",
    "#         r\"(?:\\s*\\d\\s*){2}/(?:\\s*\\d\\s*){2}/(?:\\s*\\d\\s*){6}:(?:\\s*\\d){2,}\" +\n",
    "#         r\"(?:[-–\\s]*\" + r\"\\s*\".join([\"\", *\"Mesa\", \"\"]) + r\")?\"\n",
    "#         r\")\",\n",
    "#         regex.IGNORECASE | regex.MULTILINE,\n",
    "#     ),\n",
    "    regex.compile(f\"({NOISE_ANNEX_CABINET})\", regex.IGNORECASE), #1\n",
    "    regex.compile(f\"(?<!{NRO}[_\\s\\.0-9]*)\" + r\"([0-9]{11,})\"), #2\n",
    "    regex.compile(r\"(_{9,}\\s*)+\"), #3\n",
    "    regex.compile(r\"(^[\\s0-9]+|(?:[0-9]+_+)?[\\s0-9]+$)\"), #4\n",
    "    regex.compile( #5\n",
    "        r\"(^(?:\\s*[^\\s\" + \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM + r\"]\\s*)+|\" +\n",
    "        r\"(?:\\s*[^\\s\\.\\)\\?\" + \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM + r\"]\\s*)+$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(\n",
    "        r\"((?:(?:E[-–\\s]*mails?|Endere[cç]os?\\s*eletr[oô]nicos?)[\\s:]*)?\" +\n",
    "        r\"[-–a-zA-Z0-9\\._]{,40}\\s*@\\s*(?:[a-zA-Z]{1,15}\\.?){1,3})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(r\"(IN\\s*C\\s*\" + NRO + r\"\\s*[\\s0-9]{3,8}/\\s*[\\s0-9]{4,8})\", regex.IGNORECASE),\n",
    "    *[\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, r\"cap[ií]tulo\", r\"t[íi]tulo\")\n",
    "    ],\n",
    "    regex.compile(\n",
    "        r\"((?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)CPI\\s*(?:da\\s*Petrobr[áa]s)?\\s*[-–]\\s*\" +\n",
    "        r\"(LEI\\s*ROUANET|Relat[oó]rio\\s*Final|EXPLORA[CÇ][AÃ]O\\s*SEXUAL\\s*DE\\s*CRIAN[CÇ]AS\\s*E\\s*ADOLESCENTES))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    ")\n",
    "\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC|\\.{3,})\\s*\\)\\s*|\" +\n",
    "    f\"[{QUOTES}])\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    f\"(?:[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN +\n",
    "    r\"*.{,300}?\" +\n",
    "    MARKER_NOISE_END + r\"\\s*\" + DEBUG_PATTERN +\n",
    "    f\"*[\\s{MARKER_INTENDED_CORRUPTION}]*)\"\n",
    ")\n",
    "\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in (\n",
    "        *BASE_LEGAL_ITEMS,\n",
    "        *EXTRA_LEGAL_ITEMS,\n",
    "        r\"D[eê][-–]se\\s*ao\\s*Projeto\\s*a\\s*seguinte\\s*reda[cç][aã]o\\s*:\",\n",
    "    )\n",
    ")\n",
    "\n",
    "ADDITIONAL_TITLES = (\n",
    "    r\"(?:\" \n",
    "    r\"Ju[ií]z[ea]?s?|M[\\.\\s]*M[aª]?[\\s\\.]*|\" +\n",
    "    r\"Doutor[ea]?s?|D\\.?r[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Professor[ea]?s?|Prof[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Advogad[ao]s?|Adv[\\s\\.]*\" +\n",
    "    r\")*\"\n",
    ")\n",
    "\n",
    "ABBVR_EXMO = r\"Ex\\.?m[aªoº]s?\\s*\\.?\"\n",
    "ABBVR_EX = r\"Ex\\.?[aªoº]?s?\\s*\\.\\s*[ºªᵉ]?\"\n",
    "ABBVR_SR = r\"S\\.?r\\.?[aªeᵉ]?s?\"\n",
    "\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)?[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)?\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"(?:MENSAGEM|\" + DOC_ABBVR + \")\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" +\n",
    "    r\"CPI|\" +\n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(]{,100}\\(\\s*(?:D[oa]s?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}\\)]\" + r\"{1,100})?\\)\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\".{,100}?D[oa]s?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._0-9]+|\" +\n",
    "    f\"(?:{NRO}\" + r\"[_\\s\\.0-9]*)?\\s*(?:\" + UPPERCASE_DATE_OR_UNDERSCORES + r\")|\" +\n",
    "    NRO + r\"[_\\s\\.0-9]*\" +\n",
    "    r\"(?:[^,]{,30}?[,\\.]+\\s*(?:DE\\s*)+?[\\._0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "# DATE\n",
    "\n",
    "fn_lambda_single = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" \n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "fn_lambda_quad = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \" + r\"\\4\" + f\" {symb} {deb} \"\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY = (\n",
    "    r\"(?:Excelent[ií]ssim[oa]s?|\" + ABBVR_EXMO + r\"|(?:Vossa|V\\s*\\.)\\*(?:excel[eê]ncias?|\" + ABBVR_EX + r\"))?\" +\n",
    "    r\"\\s*(?:Senhor[ae]?s?|\" + ABBVR_SR + r\")[\\.\\s]*\" +\n",
    "    r\"\\s*(?:Primeir[oa]s?|Vices?|[-–\\s])*\" +\n",
    "    r\"(?:Pres(?:id(?:ent[ae])?)?s?|Min(?:istr[oa])?s?|Advogad[ao]s?\\s*Geral\\s*da\\s*Uni[aã]o|Secret[aá]ri[oa]s?)\" +\n",
    "    r\"[^,:;\\.]{,75}?[,:;\\.]\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<=(?<!\" + f\"{ABBVR_EXMO}|{ABBVR_EX}|{ABBVR_SR}\" + \")\\s*\\..{,10}?|\\).{,10}?)\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY + \"|\" +\n",
    "    r\"(?:(?<=\\.\\s*)Requeiro|Solicito)\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile( #0\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,15}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #1\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #2\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O).{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        DEPT_EXTENSION_A +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #3\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #4\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #5\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara\\s*dos\\s*deputados[^\\.]*?resolve\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #6\n",
    "        r\"(MEDIDA\\s*PROVIS[ÓO]RIA.{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,1200}?)([OA]\\s*President[ea]\\s*da\\s*rep[úu]blica[^:]+?com\\s*for[cç]a\\s*de\\s*lei\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #7\n",
    "        r\"(\" +\n",
    "        r\"\\s*\".join([\"\", *\"Documentoeletr\", r\"[oô]\", *\"nico\", \"\"]) +\n",
    "        r\"\\s*.{,400}?\" +\n",
    "        r\")?\" +\n",
    "        r\"(\\s*\" +\n",
    "        r\"(?:\" + DOC_ABBVR + \"\\s*\" + f\"(?:{NRO})*\" + r\"\\s*[\\d\\s]+/[\\s\\d]+)?+\\s*\" +\n",
    "        r\"\\s*\".join([\"\", *\"Apresenta\", \"[çc]\", \"[aã]\", *\"o:\", \"\"]) +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){4}\" + r\"\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*:\\s*\" +\n",
    "        r\"\\s*(?:\" +\n",
    "        f\"\\s*(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\\s*\" +\n",
    "        r\"[0-9]\" +\n",
    "        f\"\\s*(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\\s*\" +\n",
    "        r\"\\s*){2}\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"([-–]*)(\" + r\"\\s*\".join([\"\", *\"Mesa\", \"\"]) + r\")?\", regex.IGNORECASE | regex.MULTILINE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\" + MARKER_INTENDED_CORRUPTION + r\"\\4\" + f\" {symb_end} {deb} \", None),\n",
    "    (DetectRecurrentNoise, #8\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #9\n",
    "        r\"([:;\" + QUOTES + r\"\\?])(\\s{,10}[-–])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #10\n",
    "        r\"((?<!S\\s*\\.\\s*A\\s*)\\.)(\\s{,10}[-–])(?=\\s*[\" + UPPERCASE_LETTERS + \"])\"),\n",
    "     lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #11\n",
    "        r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"),\n",
    "     lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #12\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double, None),\n",
    "    (regex.compile( #13\n",
    "        r\"((?:TVR|(?:Ato\\s*de\\s*)?Concess[aã]o(?:e|\\s)*Renova[cç][ãa]o(?:de|\\s)*Concess[aã]o(?:de|\\s)*Emissora(?:de|\\s)*Rádio(?:e|de|\\s)*Televisão)\\s*\" + DATE_AND_ID + DEPT_EXTENSION + \")\"\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, None),\n",
    "    (regex.compile( #14\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR)?|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)?\" +\n",
    "        f\"(?!{DEPT_EXTENSION})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #15\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{NRO}[_\\s\\.0-9]*)\" +\n",
    "        f\"(?:{UPPERCASE_DATE_OR_UNDERSCORES})\"\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \", None\n",
    "    ),\n",
    "    (regex.compile( #16\n",
    "        r\"(?<=[\" + UPPERCASE_LETTERS + \"]{3,}\\s+)([0-9]{1,2}\\s*\\.\\s+[0-9]+)\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None\n",
    "    ),\n",
    "    (regex.compile( #17\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*|ou|,)\\s*)\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2,}\\s*)(\\)))?(\\s*[0-9]{4,}\\s*[-–\\.\\s]?\\s*[0-9]{4,}(?:\\s*/\\s*[0-9]{4})?)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #18\n",
    "        r\"(?<=\\s|^)(Bras[ií]lia[-–/\\s]*DF.{,10}?)?(CEP[\\.\\s:]*[0-9]{2}[\\s\\.]*[0-9]{3}\\s*[-–]\\s*[0-9]{3})(.{,10}?Bras[ií]lia[-–/\\s]*DF)?\"),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\" + f\" {symb_end} {deb} \",\n",
    "    None,\n",
    "    ),\n",
    "    (regex.compile( #19\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "     fn_lambda_double, None),\n",
    "    (regex.compile( #20\n",
    "        r\"(OF[IÍ]CIO\\s*\" + NRO + r\".{,110}?\\s*)\" +\n",
    "        r\"((?:Bras[ií]lia|Senado\\s*Federal)?[,\\s]*(?:\" + DATE_OR_UNDERSCORES + r\")[\\.\\s]*)\" +\n",
    "        r\"(.{,300}?\\s*)\" +\n",
    "        r\"(Assunto\\s*:\\s*.{,300}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE\n",
    "    ),\n",
    "    fn_lambda_quad, None),\n",
    "    (regex.compile( #21\n",
    "        r\"(Atenciosamente\\s*),\" +\n",
    "        r\"(\\s*.{,250}?\" +\n",
    "        RE_DOC_CODE_FULL +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\",\\2\" + f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #22\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ]ES|[AÃ]O).{,10}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"(.{,600}?)\" +\n",
    "        r\"([ÀÁA]\\s*sua\\s*excel[eê]ncia.{,100}?)\" +\n",
    "        r\"(?=(?:\" + REQUEST_PRESIDENT_OR_MINISTRY + \"[,\\s]*)?(?:Requeiro|Solicito))\", regex.IGNORECASE),\n",
    "     fn_lambda_triple, None),\n",
    "    (regex.compile( # 23\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*)([^\\s\" + UPPERCASE_LETTERS + r\"])((?:\\s|\\2)*)(\\s*)\" +\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)\",\n",
    "        regex.IGNORECASE),\n",
    "     lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\\4\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #24\n",
    "        r\"(Autora?\\s*:\\s*.{,200}?)(\\s*Relatora?\\s*:)\", regex.IGNORECASE),\n",
    "     lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    (regex.compile( #25\n",
    "        r\"(?<=(?:Relatora?|Autora?)\\s*:.{,200}?\\s+)(\" + VALID_ROMAN_NUM + r\"[-–\\s]+RELAT[OÓ]RIO\\s+)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (AgreementList, #26\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    (regex.compile(r\"(?=Reiterando\\s*os\\s*votos\\s*de\\s*apre[cç]o\\s*e\\s*considera[cç][aã]o)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    (regex.compile( #27\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*)\\s*)?\" +\n",
    "        r\"(?:(\\()(\\s*[0-9]{2,}\\s*)(\\)))(\\s*[0-9]{4,}\\s*[-–\\.\\s]?\\s*[0-9]{4,}(?:\\s*/\\s*[0-9]{4})?)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\" + f\" {symb_end} {deb} \", None),\n",
    ")\n",
    "\n",
    "LARGER_BLOCKS_HIERARCHY = (\n",
    "    \"LIVRO\",\n",
    "    \"T[IÍ]TULO\",\n",
    "    \"CAP[IÍ]TULO\",\n",
    "    \"(?:Sub)?[sS]e[cç][aã]o\",\n",
    "    BASE_LEGAL_ITEMS[1] + r\"(?=\\s*[^\" + UPPERCASE_LETTERS_OR_NUM + r\"])\",\n",
    ")\n",
    "\n",
    "RE_PRE_POST_BLOCKS = (\n",
    "    regex.compile( #0\n",
    "        r\"(ACORDO\\s*DE\\s*[-,\"\n",
    "        + UPPERCASE_LETTERS_OR_NUM\n",
    "        + r\"\\s]+)(?=(?:[OA]\\s+)?[\"\n",
    "        + UPPERCASE_LETTERS\n",
    "        + r\"][a-z])\"\n",
    "    ),\n",
    "    regex.compile(r\"(?<!\\(.{,50}?)(\" + COMMISSIONS + \")\"), #1\n",
    "    regex.compile(r\"(O\\s*Congresso\\s*Nacional\\s*decreta\\s*.{,40}?\\s*:)\", regex.IGNORECASE), #2\n",
    "    regex.compile(r\"(C[ÂA]MARA\\s*DOS\\s*DEPUTADOS|CONGRESSO\\s*NACIONAL)(?!\\s*[dD][eE][cC][rR][eE][tT][aA])\"), #3\n",
    "    regex.compile(r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*decreta\\s*.{,40}?\\s*:)\", regex.IGNORECASE), #4\n",
    "    regex.compile( #5\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Lei\\s*(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*)*\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" + r\"\\s*\"+ DEPT_EXTENSION + r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #6\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*(?:Decreto\\s*Legislativo|Resolu[cç][aã]o)\\s*\" +\n",
    "        f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #7\n",
    "        r\"(?<=^[^\\(]{,500}?)(Mensagem\\s*\" + DATE_AND_ID + \"\\s*[0-9][0-9\\s]*)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #8\n",
    "        r\"((?:SUBSTITUTIV[AO]\\s*[ÁÀA]\\s*)?\" +\n",
    "        r\"Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #9, 10, 11\n",
    "        regex.compile(\n",
    "            f\"({LARGER_BLOCKS_HIERARCHY[i]}\" + r\"\\s*\" + f\"(?:{VALID_ROMAN_NUM})\" +\n",
    "            r\"(?:[-–\\.\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]|\" + \n",
    "            f\"{MARKER_NOISE_END}|{MARKER_NOISE_START}\" +\n",
    "            r\")+?\" +\n",
    "            f\"(?={MARKER_VALID}|\" + r\"|\".join(LARGER_BLOCKS_HIERARCHY[i + 1:]) + r\"))\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for i in range(len(LARGER_BLOCKS_HIERARCHY) - 1)\n",
    "    ],\n",
    "    regex.compile( #12\n",
    "        r\"(Art.{,10}?Esta\\s*\" +\n",
    "        r\"(?:lei|EC|Emenda\\s*(?:Constitucional|[àaá\\s]*constitui[cç][aã]o))\\s*\" +\n",
    "        r\"entr[ea]\\s*em\\s*vigor\\s*na\\s*(?:data\\s*de\\s*)sua\\s*publica[cç][aã]o\\s*.{,50}?(?:\\.|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "RE_POST_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={pattern})\", regex.IGNORECASE)\n",
    "    for pattern in []\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \", text, concurrent=True)\n",
    "    \n",
    "    for i, (reg, fun, fun_post) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=True)\n",
    "        \n",
    "        if fun_post is not None:\n",
    "            text = fun_post(text)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \" + r\"\\1\" + f\" {MARKER_VALID} {debug_text} \", text, concurrent=True)\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_instance(item, ind, print_preprocessed: bool = False, debug: bool = False):    \n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug)\n",
    "    preprocessed_text = preprocessed_text.replace(MARKER_INTENDED_CORRUPTION, \"@\" if debug else \"\")\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(colorama.Fore.WHITE, colorama.Style.DIM, preprocessed_text, colorama.Style.RESET_ALL, sep=\"\")\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            cur_token = tokens.pop(i)\n",
    "            cur_label = labels.pop(i)\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_START]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_END:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = 0\n",
    "            else:\n",
    "                labels[i] = SPECIAL_SYMBOLS[cur_token]\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels:\n",
    "        maybe_erase_pool = []\n",
    "        noise_on = False\n",
    "\n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                labels[i] = labels[i + 1] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                maybe_erase_pool.clear()\n",
    "                continue\n",
    "\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                while maybe_erase_pool:\n",
    "                    ind = maybe_erase_pool.pop()\n",
    "                    labels[ind] = 0\n",
    "\n",
    "            if labels[i] > 0:\n",
    "                maybe_erase_pool.append(i)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                if noise_on:\n",
    "                    labels[i] = 0\n",
    "                else:\n",
    "                    noise_on = True\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                if noise_on:\n",
    "                    noise_on = False\n",
    "                else:\n",
    "                    labels[i] = 0\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                noise_on = False\n",
    "            \n",
    "        while tokens and tokens[0] in SPECIAL_SYMBOLS:\n",
    "            labels.pop(0)\n",
    "            tokens.pop(0)\n",
    "\n",
    "        while tokens and tokens[-1] in SPECIAL_SYMBOLS:\n",
    "            labels.pop()\n",
    "            tokens.pop()\n",
    "        \n",
    "        if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "            labels[0] = 0\n",
    "            \n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "if DEV_RUN:\n",
    "    auxaux = \"\"\"\n",
    "Senhor Presidente,  \n",
    " Nos termos do art. 113, inciso I e parágrafo 1º, do Regimento Interno da Câmara \n",
    "dos Deputados, requeiro o envio de Indicação ao Poder Executivo, por meio do Ministro \n",
    "da Economia, Paulo Guedes, sugerindo a isenção do Imposto de Importação (II), \n",
    "incidente sobre a comercialização de dispositivos protéticos necessários à reabilitação \n",
    "de pessoas amputadas.  *C D2 02 64 89 71 10 0* Do cu m en to e le tr ôn ic o as sin ad o po r W ol ne y Q ue iro z (P DT /P E) , a tr av és d o po nt o SD R_ 56 16 4, na fo rm a do a rt . 1 02 , § 1 º, d o RI CD c /c o a rt . 2 º, d o At o da M es a n. 8 0 de 2 01 6. PL n .4 92 3/ 20 20 Ap re se nt aç ão : 1 4/ 10 /2 02 0 16 :5 7 - M es a\n",
    " \n",
    "Sala das Sessões, em ___ de ____________ de 2020. \n",
    "\"\"\".replace(\" , \", \", \").replace(\" . \", \". \")\n",
    "\n",
    "_=preprocess_instance({\"text\": auxaux}, -1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:20:47.272536Z",
     "start_time": "2022-03-01T03:19:23.036697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-46b3e822caba5a99\n",
      "Reusing dataset csv (../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b2ea521101452c95a83f93ccb20a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-8aa3bb54f5af798d.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-40495513c975b77e.arrow\n",
      "Loading cached processed dataset at ../cache/datasets/csv/default-46b3e822caba5a99/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-9599182709e5e523.arrow\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START if DEV_RUN else None,\n",
    "    nrows=(DATASET_ROW_END - DATASET_ROW_START + 1) if DEV_RUN else None,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[\" + UPPERCASE_LETTERS + r\"])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÂÃÀÁ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aãâàá]\\s*o\\s+(?=[\" + UPPERCASE_LETTERS + r\"])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=None if DEV_RUN else \"text\")\n",
    "\n",
    "rerun_tests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:20:47.277474Z",
     "start_time": "2022-03-01T03:20:47.274567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 10000}\n"
     ]
    }
   ],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:26:25.892555Z",
     "start_time": "2022-03-01T03:25:20.967135Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChosen id:\u001b[39m 4145\n",
      "\n",
      "\u001b[37m\u001b[2m \n",
      "PROJETO DE LEI Nº          , DE 2019 \n",
      "(Da Sra. ANGELA AMIN) \n",
      "Altera o art. 473 da Consolidação das \n",
      "Leis do Trabalho (CLT), para permitir que o \n",
      "empregado deixe de comparecer ao serviço, \n",
      "sem prejuízo da remuneração, quando \n",
      "estiver participando do programa oferecido \n",
      "pela Justiça da Infância e da Juventude aos \n",
      "postulantes à adoção. \n",
      "O Congresso Nacional decreta: \n",
      "Art. 1º O art. 473 da Consolidação das Leis do Trabalho (CLT), \n",
      "aprovada pelo Decreto-lei nº 5.452, de 1º de maio de 1943, passa a vigorar \n",
      "com a seguinte alteração: \n",
      "“Art. 473........................................................................................ \n",
      "...................................................................................................... \n",
      "XIII – pelo tempo que se fizer necessário, quando estiver \n",
      "participando, na condição de postulante à adoção, do programa \n",
      "oferecido pela Justiça da Infância e da Juventude nos termos \n",
      "do § 1º do art. 197-C da Lei nº 8.069, de 13 de julho de 1990.” \n",
      "(NR) \n",
      "Art. 2º Esta lei entra em vigor na data de sua publicação.\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[0m\u001b[97m 1 \u001b[39m PROJETO DE LEI Nº , DE 2019 ( Da Sra. ANGELA AMIN )\n",
      "\n",
      "\u001b[97m 2 \u001b[39m Altera o art . 473 da Consolidação das Leis do Trabalho ( CLT ) , para permitir que o empregado deixe de comparecer ao serviço , sem prejuízo da remuneração , quando estiver participando do programa oferecido pela Justiça da Infância e da Juventude aos postulantes à adoção .\n",
      "\n",
      "\u001b[97m 3 \u001b[39m O Congresso Nacional decreta :\n",
      "\n",
      "\u001b[97m 4 \u001b[39m Art . 1º O art . 473 da Consolidação das Leis do Trabalho ( CLT ) , aprovada pelo Decreto-lei nº 5.452 , de 1º de maio de 1943 , passa a vigorar com a seguinte alteração : “\n",
      "\n",
      "\u001b[97m 5 \u001b[39m Art . 473 ........................................................................................ ......................................................................................................\n",
      "\n",
      "\u001b[97m 6 \u001b[39m XIII – pelo tempo que se fizer necessário , quando estiver participando , na condição de postulante à adoção , do programa oferecido pela Justiça da Infância e da Juventude nos termos do § 1º do art . 197-C da Lei nº 8.069 , de 13 de julho de 1990. ” ( NR )\n",
      "\n",
      "\u001b[97m 7 \u001b[39m Art . 2º Esta lei entra em vigor na data de sua publicação .\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   4145: 7, 0\n",
      "Is it correct? [y/N]: y\n",
      "Added to test cases.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    id_ = None\n",
    "    \n",
    "    if id_ is not None:\n",
    "        print(tests.TEST_CASES[id_])\n",
    "        tests.print_results(df, id_, print_full_text=True)\n",
    "#         tests.update_test_case(id_, (10, 0))\n",
    "    \n",
    "    if rerun_tests:\n",
    "        try:\n",
    "            tests.run_tests(df[\"train\"][\"labels\"])\n",
    "            rerun_tests = False\n",
    "\n",
    "        except AssertionError as e:\n",
    "            raise AssertionError from e\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    document_idx = min(9999, df[\"train\"].num_rows - 1)\n",
    "    while tests.test_case_exists(document_idx):\n",
    "        document_idx = random.randint(0, df[\"train\"].num_rows)\n",
    "\n",
    "    print(colorama.Fore.YELLOW + \"Chosen id:\" + colorama.Fore.RESET, document_idx, end=\"\\n\\n\")\n",
    "\n",
    "    expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "    print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "    inp = input()\n",
    "    if inp == \"y\":\n",
    "        tests.update_test_case(document_idx, expected_test_case_values)\n",
    "        print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:26:30.474222Z",
     "start_time": "2022-03-01T03:26:30.470600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 17 test cases at './test_cases/100001_110000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
