{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f75bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:07.749973Z",
     "start_time": "2022-04-06T23:02:06.223444Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import pickle\n",
    "import collections\n",
    "import timeit\n",
    "\n",
    "import optimum\n",
    "import optimum.onnxruntime\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import segmentador\n",
    "import eval_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DEV_RUN = False\n",
    "\n",
    "QUANTIZED_MODELS_DIR = \"quantized_models\"\n",
    "pathlib.Path(QUANTIZED_MODELS_DIR).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09721be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:08.367924Z",
     "start_time": "2022-04-06T23:02:07.751366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask']),\n",
       " (509827, 509827, 509827, 509827))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_df = datasets.Dataset.from_file(\n",
    "    \"../data/refined_datasets/df_tokenized_split_0_120000_6000/\"\n",
    "    \"combined_test_48_parts_1036_instances/dataset.arrow\"\n",
    ")\n",
    "\n",
    "concat_curated_df = collections.defaultdict(list)\n",
    "\n",
    "for key in curated_df.features.keys():\n",
    "    for val in curated_df[key]:\n",
    "        concat_curated_df[key] += val\n",
    "        if DEV_RUN and len(concat_curated_df[key]) >= 100000:\n",
    "            break\n",
    "        \n",
    "concat_curated_df.keys(), tuple(len(val) for key, val in concat_curated_df.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e8e9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T17:10:42.928492Z",
     "start_time": "2022-04-05T17:10:42.922482Z"
    }
   },
   "source": [
    "## Creating LSTM Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3580ae67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:08.493737Z",
     "start_time": "2022-04-06T23:02:08.370553Z"
    }
   },
   "outputs": [],
   "source": [
    "segmenter_lstm = segmentador.LSTMSegmenter(\n",
    "    uri_model=\"../pretrained_segmenter_model/512_6000_1_lstm/checkpoints/epoch=3-step=3591.ckpt\",\n",
    "    uri_tokenizer=\"../tokenizers/6000_subwords\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edeb9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:08.600742Z",
     "start_time": "2022-04-06T23:02:08.494980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_LSTMSegmenterTorchModule(\n",
      "  (embeddings): Embedding(6000, 768, padding_idx=0)\n",
      "  (lstm): DynamicQuantizedLSTM(768, 512, batch_first=True, bidirectional=True)\n",
      "  (lin_out): DynamicQuantizedLinear(in_features=1024, out_features=4, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_lstm = segmenter_lstm.model\n",
    "# model_lstm.qconfig = torch.quantization.float_qparams_weight_only_qconfig\n",
    "\n",
    "quantized_model_lstm = torch.quantization.quantize_dynamic(\n",
    "    model_lstm,\n",
    "    {nn.LSTM, nn.Linear},\n",
    "    dtype=torch.qint8,\n",
    ")\n",
    "\n",
    "print(quantized_model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20b4839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:08.679993Z",
     "start_time": "2022-04-06T23:02:08.602249Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model_lstm.state_dict(), os.path.join(QUANTIZED_MODELS_DIR, \"512_6000_1_lstm.pt\"))\n",
    "torch.save(\n",
    "    quantized_model_lstm.state_dict(),\n",
    "    os.path.join(QUANTIZED_MODELS_DIR, \"q_512_6000_1_lstm.pt\"),\n",
    "    pickle_protocol=pickle.HIGHEST_PROTOCOL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07b1322c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:42:59.917258Z",
     "start_time": "2022-04-06T23:42:59.812322Z"
    }
   },
   "outputs": [],
   "source": [
    "segmenter_lstm_quantized = segmentador.LSTMSegmenter(\n",
    "    uri_model=\"quantized_models/q_512_6000_1_lstm.pt\",\n",
    "    uri_tokenizer=\"../tokenizers/6000_subwords\",\n",
    "    device=\"cpu\",\n",
    "    quantize_weights=True,\n",
    "    lstm_hidden_layer_size=512,\n",
    "    lstm_num_layers=1,\n",
    "    inference_pooling_operation=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924b9fe",
   "metadata": {},
   "source": [
    "## Creating BERT Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb1f141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:08.825389Z",
     "start_time": "2022-04-06T23:02:08.803299Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model_path = os.path.join(QUANTIZED_MODELS_DIR, \"4_6000_layer_model.onnx\")\n",
    "\n",
    "onnx_quantized_model_output_path_dynamic = os.path.join(\n",
    "    QUANTIZED_MODELS_DIR,\n",
    "    \"q_dynamic_4_6000_layer_model.onnx\",\n",
    ")\n",
    "onnx_optimized_model_output_path = os.path.join(\n",
    "    QUANTIZED_MODELS_DIR,\n",
    "    \"4_6000_layer_model_optimized.onnx\",\n",
    ")\n",
    "\n",
    "onnx_config_quant_path = os.path.join(\n",
    "    QUANTIZED_MODELS_DIR,\n",
    "    \"q_4_6000_layer_model_config.pickle\",\n",
    ")\n",
    "onnx_config_opt_path = os.path.join(\n",
    "    QUANTIZED_MODELS_DIR,\n",
    "    \"4_6000_layer_model_optimization_config.pickle\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1234f421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:09.087898Z",
     "start_time": "2022-04-06T23:02:08.827180Z"
    }
   },
   "outputs": [],
   "source": [
    "segmenter_bert = segmentador.BERTSegmenter(\n",
    "    uri_model=\"../pretrained_segmenter_model/4_6000_layer_model/\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d569562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:14.861008Z",
     "start_time": "2022-04-06T23:02:09.089055Z"
    }
   },
   "outputs": [],
   "source": [
    "# The type of quantization to apply\n",
    "qconfig = optimum.onnxruntime.configuration.AutoQuantizationConfig.avx2(\n",
    "    is_static=False,\n",
    "    per_channel=True,\n",
    ")\n",
    "\n",
    "quantizer = optimum.onnxruntime.ORTQuantizer(\n",
    "    model=segmenter_bert.model,\n",
    "    tokenizer=segmenter_bert.tokenizer,\n",
    ")\n",
    "\n",
    "quantizer.export(\n",
    "    onnx_model_path=onnx_model_path,\n",
    "    onnx_quantized_model_output_path=onnx_quantized_model_output_path_dynamic,\n",
    "    quantization_config=qconfig,\n",
    ")\n",
    "\n",
    "with open(onnx_config_quant_path, \"wb\") as f_out:\n",
    "    pickle.dump(quantizer._onnx_config, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646ec0b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:14.884512Z",
     "start_time": "2022-04-06T23:02:14.862334Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "segmenter_bert_quantized = segmentador.QONNXBERTSegmenter(\n",
    "    uri_model=onnx_quantized_model_output_path_dynamic,\n",
    "    uri_tokenizer=\"../tokenizers/6000_subwords/\",\n",
    "    uri_onnx_config=onnx_config_quant_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35f5997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:16.211054Z",
     "start_time": "2022-04-06T23:02:14.885943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 20:02:15.054151616 [W:onnxruntime:, inference_session.cc:1546 Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n",
      "WARNING:fusion_skiplayernorm:symbolic shape infer failed. it's safe to ignore this message if there is no issue with optimized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed in shape inference <class 'AssertionError'>\n",
      "failed in shape inference <class 'AssertionError'>\n"
     ]
    }
   ],
   "source": [
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "from optimum.onnxruntime import ORTOptimizer\n",
    "\n",
    "# optimization_config=99 enables all available graph optimisations\n",
    "optimization_config = OptimizationConfig(optimization_level=99)\n",
    "\n",
    "optimizer = ORTOptimizer(\n",
    "    model=segmenter_bert.model,\n",
    "    tokenizer=segmenter_bert.tokenizer,\n",
    ")\n",
    "\n",
    "optimizer.export(\n",
    "    onnx_model_path=onnx_model_path,\n",
    "    onnx_optimized_model_output_path=onnx_optimized_model_output_path,\n",
    "    optimization_config=optimization_config,\n",
    ")\n",
    "\n",
    "with open(onnx_config_opt_path, \"wb\") as f_out:\n",
    "    pickle.dump(optimizer._onnx_config, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3eabec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:02:16.234534Z",
     "start_time": "2022-04-06T23:02:16.212634Z"
    }
   },
   "outputs": [],
   "source": [
    "segmenter_bert_optimized = segmentador.QONNXBERTSegmenter(\n",
    "    uri_model=onnx_optimized_model_output_path,\n",
    "    uri_tokenizer=\"../tokenizers/6000_subwords/\",\n",
    "    uri_onnx_config=onnx_config_opt_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd65245",
   "metadata": {},
   "source": [
    "## Validating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d600dc73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:44:08.121250Z",
     "start_time": "2022-04-06T23:44:08.098889Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model,\n",
    "    moving_window_size: int = 1024,\n",
    "    window_shift_size: float = 0.5,\n",
    "    inference_poobatch_size: int = 64\n",
    ") -> dict[str, float]:\n",
    "    t_start = timeit.time.perf_counter()\n",
    "    \n",
    "    logits = model(\n",
    "        concat_curated_df,\n",
    "        batch_size=batch_size,\n",
    "        return_logits=True,\n",
    "        show_progress_bar=True,\n",
    "        window_shift_size=window_shift_size,\n",
    "        moving_window_size=moving_window_size,\n",
    "        \n",
    "    ).logits\n",
    "    \n",
    "    t_delta = timeit.time.perf_counter() - t_start\n",
    "    \n",
    "    metrics = eval_model.compute_metrics(\n",
    "        ([logits], [concat_curated_df[\"labels\"]]),\n",
    "    )\n",
    "    metrics[\"approx_inference_time\"] = t_delta\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eacc4f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:17:20.080570Z",
     "start_time": "2022-04-06T23:02:46.172022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8ec051c91543828f88936917dfd140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04646f28ab4b405490258d2db6a36458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b10dd7c6c94d7e9c4b38d08d74c5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb048e3b9ac49d5953c83ed831c716a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383d6679c1d64ff4866ccf953aac9489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_bert = validate(segmenter_bert)\n",
    "metrics_bert_quantized = validate(segmenter_bert_quantized)\n",
    "metrics_bert_optimized = validate(segmenter_bert_optimized)\n",
    "metrics_lstm = validate(segmenter_lstm)\n",
    "metrics_lstm_quantized = validate(segmenter_lstm_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27b5cc8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T23:37:06.448900Z",
     "start_time": "2022-04-06T23:37:06.427241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_cls_precision_0': 0.9978579384799646,\n",
       " 'per_cls_precision_1': 0.921013412815711,\n",
       " 'per_cls_precision_2': 0.8635135135018444,\n",
       " 'per_cls_precision_3': 0.527027026991417,\n",
       " 'per_cls_recall_0': 0.997516059957145,\n",
       " 'per_cls_recall_1': 0.9413556740279171,\n",
       " 'per_cls_recall_2': 0.7671068427278859,\n",
       " 'per_cls_recall_3': 0.56521739126339,\n",
       " 'macro_precision': 0.8273529729472343,\n",
       " 'macro_recall': 0.8177989919940845,\n",
       " 'macro_f1': 0.822548235792856,\n",
       " 'overall_accuracy': 0.9953858362096711,\n",
       " 'approx_inference_time': 323.5718637810023}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
