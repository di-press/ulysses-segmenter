{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f59ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:50:10.487696Z",
     "start_time": "2022-03-06T13:50:07.176143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker symbol (valid): ✓\n",
      "Marker symbol (noise): ❌s__ ❌e__\n",
      "Loaded 70 test cases from './test_cases/110001_120000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "import typing as t\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import nltk\n",
    "import tokenizers\n",
    "import regex\n",
    "import colorama\n",
    "\n",
    "import segmentador\n",
    "import tests\n",
    "from config import *\n",
    "\n",
    "\n",
    "DEV_RUN = True\n",
    "\n",
    "\n",
    "random.seed(7899)\n",
    "print(\"Marker symbol (valid):\", MARKER_VALID)\n",
    "print(\"Marker symbol (noise):\", MARKER_NOISE_START, MARKER_NOISE_END)\n",
    "\n",
    "DATASET_ROW_START = None\n",
    "DATASET_ROW_END = None\n",
    "if DEV_RUN:\n",
    "    TESTS_DIR = \"test_cases\"\n",
    "    DATASET_ROW_START = 110001\n",
    "    DATASET_ROW_END = 120000\n",
    "    TEST_CASE_URI = os.path.join(\".\", TESTS_DIR, f\"{DATASET_ROW_START}_{DATASET_ROW_END}_registered_test_cases.csv\")\n",
    "\n",
    "    tests.load_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5461fd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:50:17.997731Z",
     "start_time": "2022-03-06T13:50:12.145267Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seg_model = segmentador.Segmenter(local_files_only=DEV_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d8643074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:55:20.264399Z",
     "start_time": "2022-03-06T15:55:20.125491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2mSenhor Presidente, Nos termos do art. 113, inciso I e §1º, do Regimento Interno da Câmara dos Deputados, requeiro a Vossa Excelência que seja encaminhada ao Poder Executivo a INDICAÇÃO anexa, sugerindo criação do selo ou certificação “ Estabelecimento Clean & Safe ” para empreendimentos turísticos e empresas do setor do turismo. ✓ 1_HIGH_PTY  Sala das Sessões, em 28 de abril de 2020. Deputado PEDRO LUCAS FERNANDES LÍDER DO PTB. kdsfçs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DEBUG_PATTERN = \"(?:\\s*[0-9]{1,3}(?:_[A-Z]{1,30})+\\s*)\"\n",
    "ALL_SPECIAL_MARKERS = f\"(?:{MARKER_INTENDED_CORRUPTION}|{MARKER_NOISE_START}|{MARKER_NOISE_END}|{MARKER_VALID})\"\n",
    "ALL_BUT_NEWSEG = f\"[^{MARKER_VALID}]\"\n",
    "COMMISSION_LIST = (r\"\"\"\n",
    "    (?:\n",
    "    AGRICULTURA(?:[,\\s]|DE)*PECU[AÁ]RIA(?:[,\\s]|DE)*ABASTECIMENTO[E\\s]*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*RURAL|\n",
    "    CI[EÊ]NCIA[E\\s]*TECNOLOGIA(?:[,\\s]|DE)*COMUNICA[CÇ][AÃ]O(?:[E\\s]|DA)*INFORM[AÁ]TICA|\n",
    "    CONSTITUI[CÇ][AÃ]O[E\\s]*JUSTI[CÇ]A[E\\s]*(?:DE\\s*CIDADANIA)?|\n",
    "    CULTURA|\n",
    "    DEFESA\\s*(?:DO|AO)\\s*CONSUMIDOR|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*ECON[OÔ]MICO(?:[,\\s]|DE)*IND[UÚ]STRIA(?:[,\\s]|DE)*COM[EÉ]RCIO(?:[E\\s]|DE)*SERVI[CÇ]OS|\n",
    "    (?:DES\\s*\\.|DESENVOLVIMENTO)\\s*URBANO|\n",
    "    DIREITOS\\s*DA\\s*MULHER|\n",
    "    DIREITOS\\s*DA\\s*PESSOA\\s*IDOSA|\n",
    "    DIREITOS\\s*DAS\\s*PESSOAS\\s*COM\\s*DEFICI[EÊ]NCIA|\n",
    "    DIREITOS\\s*HUMANOS(?:(?:[E\\s]|DAS)*MINORIAS)?|\n",
    "    EDUCA[CÇ][AÃ]O|\n",
    "    ESPORTE|\n",
    "    FINAN[CÇ]AS(?:[E\\s]|DE)*TRIBUTA[CÇ][AÃ]O|\n",
    "    FISCALIZA[CÇ][AÃ]O\\s*FINANCEIRA(?:[E\\s]|DE)*CONTROLE|\n",
    "    INTEGRA[CÇ][AÃ]O\\s*NACIONAL(?:[,\\s]|DE)*(?:DES\\s*\\.|DESENVOLVIMENTO)\\s*REGIONAL(?:[E\\s]|DA)*AMAZ[OÔ]NIA|\n",
    "    LEGISLA[CÇ][AÃ]O\\s*PARTICIPATIVA|\n",
    "    (?:MEIO\\s*)?AMBIENTE(?:[E\\s]|DE)*DESENVOLVIMENTO\\s*SUSTENT[AÁ]VEL|\n",
    "    MINAS(?:[E\\s]|DA)*ENERGIA|\n",
    "    RELA[CÇ][OÕ]ES\\s*EXTERIORES(?:(?:[E\\s]|DE)*\\s*DEFESA\\s*NACIONAL)?|\n",
    "    SEGURAN[CÇ]A\\s*P[UÚ]BLICA[E\\s]*COMBATE\\s*AO\\s*CRIME\\s*ORGANIZADO|\n",
    "    SEGURIDADE\\s*SOCIAL(?:[E\\s]|DA)*FAM[IÍ]LIA|\n",
    "    TRABALHO(?:[,\\s]|DE)*ADMINISTRA[CÇ][AÃ]O(?:[E\\s]|DE)*SERVI[CÇ]O\\s*P[UÚ]BLICO|\n",
    "    TURISMO|\n",
    "    VIA[CÇ][AÃ]O[E\\s]*TRANSPORTES|\n",
    "    INQU[EÉ]RITO|\n",
    "    REDA[CÇ][ÃA]O\n",
    "    )\n",
    "    \"\"\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    ")\n",
    "\n",
    "COMMISSIONS = (\n",
    "    r\"COMISS(?:[AÃ]O|[OÕ]ES)[\\s:]*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:D[EOA]S?|[\\s;:,]|E|PARLAMENTAR(?:ES)?)\\s*)+\" +\n",
    "    COMMISSION_LIST +\n",
    "    r\"\\s*)+\"\n",
    ")\n",
    "\n",
    "class DetectRecurrentMetadata:\n",
    "    \n",
    "    RE_CAMARA_RAW = regex.compile(\n",
    "        \"C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\"\n",
    "    )\n",
    "    \n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_camara_recurrent_metadata(cls, subpattern, text, dir_: t.Literal[-1, 1]):\n",
    "        positions = [\n",
    "            match.end() if dir_ == 1 else match.start()\n",
    "            for match in cls.RE_CAMARA_RAW.finditer(text)\n",
    "        ]\n",
    "        \n",
    "        if len(positions) <= 1:\n",
    "            return text\n",
    "        \n",
    "        ref_pos = max(positions) if dir_ == 1 else min(positions)\n",
    "        i = 0\n",
    "        ind_last_space = 0\n",
    "        \n",
    "        while 0 <= i + ref_pos < len(text):\n",
    "            chrs = {text[j + i].lower() for j in positions}\n",
    "            \n",
    "            if len(chrs) != 1:\n",
    "                break\n",
    "            \n",
    "            if text[i + ref_pos] == \" \":\n",
    "                ind_last_space = i\n",
    "            \n",
    "            i += 1 * dir_\n",
    "\n",
    "        if i + ref_pos in {-1, len(text)}:\n",
    "            chrs = {text[j + i].lower() for j in positions if 0 <= i + j < len(text)}\n",
    "            \n",
    "            if len(chrs) == 1 and chrs.pop() == \" \":\n",
    "                ind_last_space = i\n",
    "\n",
    "        if dir_ == 1:\n",
    "            slice_ = text[positions[0]:positions[0] + ind_last_space]\n",
    "            \n",
    "        else:\n",
    "            slice_ = text[positions[0] + ind_last_space + 1:positions[0]]\n",
    "            \n",
    "        tokens = [\n",
    "            f\"(\\s*{regex.escape(tok)}\\s*)\"\n",
    "            for tok in regex.split(\n",
    "                r\"([^\" + UPPERCASE_LETTERS + r\"]{1,5})\",\n",
    "                slice_,\n",
    "                flags=regex.IGNORECASE)\n",
    "            if tok\n",
    "        ]\n",
    "        \n",
    "        if not tokens:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            \"\".join(map(lambda gn: (\n",
    "                f\"{MARKER_INTENDED_CORRUPTION}\\g<{gn}>{MARKER_INTENDED_CORRUPTION}\"\n",
    "            ), range(1, 1 + len(tokens))))\n",
    "        )\n",
    "        \n",
    "        text = regex.sub(\n",
    "            (f\"(?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)\" if dir_ == 1 else \"\") +\n",
    "            \"\".join(tokens) +\n",
    "            (f\"(?=\\s*C[AÂ]MARA\\s*DOS\\s*DEPUTADOS)\" if dir_ == -1 else \"\"),\n",
    "            mod_subpattern,\n",
    "            text,\n",
    "        )\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_camara_recurrent_metadata(subpattern, text, dir_=1)\n",
    "        text = cls._detect_camara_recurrent_metadata(subpattern, text, dir_=-1)\n",
    "        return text\n",
    "\n",
    "\n",
    "class DetectRecurrentNoise:\n",
    "    RE_BARCODE = regex.compile(\n",
    "        r\"\\*\" +\n",
    "        f\"(?:\\s*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"([\\sA-Z0-9]+)\" +\n",
    "        r\"\\*\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BARCODE_2 = regex.compile(r\"(((?:[0-9A-F]{2}\\s*?){7})\\s*\\2)\")\n",
    "    RE_PREAMBLE = regex.compile(\n",
    "        r\"^\\s*(\" + ALL_BUT_NEWSEG + r\"{,60}?)[\\s0-9]*\" +\n",
    "        r\"(?=C[aâ]mara\\s*dos\\s*deputados\\s*(Proj|Req))\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_CAMARA_REPEATED = regex.compile(\n",
    "        r\"(?:\" +\n",
    "        r\"(C[AÂ]MARA\\s*|(?:PAL[AÁ]CIO\\s*DO\\s*)?CONGRES)(DOS\\s*|SO\\s*NAC)\" +\n",
    "        r\"(DEPUTADOS|IONAL)\" +\n",
    "        r\"([\\s0-9]+(?![\\s0-9]*[-–\\.\\)]))?\" +\n",
    "        r\"(?!\" + ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "        r\"(?:[dD][eE][cC][rR][eE][tT][aA]|[rR][eE][sS][oO][lL][vV][eE])\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,40}?\\s*:\\s*)\" +\n",
    "        r\")\",\n",
    "    )\n",
    "    RE_CAMARA_LOWERCASE = regex.compile(\n",
    "        f\"(?<=^|{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*[cC][âa]mara)(\\s*[dD]os\\s*)([dD]eputados)\" +\n",
    "        r\"(?!\" + ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "        r\"(?:[dD][eE][cC][rR][eE][tT][aA]|[rR][eE][sS][oO][lL][vV][eE])\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,40}?\\s*:\\s*)\"\n",
    "    )\n",
    "    RE_COMMISSIONS_REPEATED = regex.compile(\n",
    "        r\"((?<!\\(.{,5}\\s*)\" + COMMISSIONS + r\"(?!\\s*.{,5}\\)))\"\n",
    "    )\n",
    "    RE_SALA_DAS_SESSOES_CODE = regex.compile(\n",
    "        r\"(?<=Sala\\s*das\\s*sess[oõ\\u0303ô]+es\\s*\" + ALL_BUT_NEWSEG + r\"{,150}?)([0-9]{1,5}\\s*_\\s*(?:\" +\n",
    "        MARKER_NOISE_START +\n",
    "        r\")?\\s*[0-9]{1,5})\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    \n",
    "    CAMARA_PAGE_NUMBER_SUFFIX = (\n",
    "        f\"(?=\\s*(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\\s*C[AÂ]MARA\\s*DOS\\s*DEPUTADOS)\"\n",
    "    )\n",
    "    \n",
    "    RE_CAMARA_PAGE_NUMBER = regex.compile(r\"([0-9]+)\" + CAMARA_PAGE_NUMBER_SUFFIX)\n",
    "    \n",
    "    FN_PAGE_NUMBER = lambda page_num: (\n",
    "        r\"(P[aá\\s]?g(?:ina)?[\\.\\s:]*)?\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        f\"(\\s*0?{page_num}\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*(?:[\\\\/-]|de)\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]+\\s*)\" +\n",
    "        f\"(?:{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\"\n",
    "    )\n",
    "    RE_PAGE_NUMBER_01 = regex.compile( #Pág: 1 de 3\n",
    "        f\"^\\s*{FN_PAGE_NUMBER(1)}|(P[aá]g(?:ina)?[\\.\\s:]*){FN_PAGE_NUMBER(1)}\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    RE_BLANK_SPACES = regex.compile(r\"\\s+\")\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_barcode(cls, subpattern, text):\n",
    "        pseudo_patterns = cls.RE_BARCODE.findall(text)\n",
    "        \n",
    "        if not pseudo_patterns:\n",
    "            return text\n",
    "        \n",
    "        pseudo_patterns = map(lambda item: r\"\\s*\".join(cls.RE_BLANK_SPACES.sub(\"\", item)), pseudo_patterns)\n",
    "        pseudo_patterns = set(pseudo_patterns)\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            MARKER_INTENDED_CORRUPTION + r\"\\1\" + MARKER_INTENDED_CORRUPTION\n",
    "        )\n",
    "        \n",
    "        for barcode in sorted(pseudo_patterns):\n",
    "            text = regex.sub(f\"([\\*\\s]*{barcode}[\\*\\s]*)\", mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_preamble_noise(cls, subpattern, text):\n",
    "        preamble = cls.RE_PREAMBLE.match(text)\n",
    "    \n",
    "        if not preamble or not preamble.group(1).strip():\n",
    "            return text\n",
    "        \n",
    "        preamble_content = r\"\\s*\".join(preamble.group(1).split(\" \"))\n",
    "        preamble_content = regex.escape(preamble_content)\n",
    "        text = regex.sub(r\"(\\s*\" + preamble_content + r\"[\\s\\d]*)\", subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_camara_page_number(cls, subpattern, text):\n",
    "        numbers = sorted(map(int, cls.RE_CAMARA_PAGE_NUMBER.findall(text)))\n",
    "        \n",
    "        for i, p in enumerate(numbers, 1):\n",
    "            if i != p:\n",
    "                break\n",
    "            \n",
    "            text = regex.sub(f\"({i}){cls.CAMARA_PAGE_NUMBER_SUFFIX}\", subpattern, text)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara(cls, subpattern, text):        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\\4\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_REPEATED.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_camara_lowercase(cls, subpattern, text):\n",
    "        match = cls.RE_CAMARA_LOWERCASE.match(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(\n",
    "            r\"\\1\",\n",
    "            r\"\\1\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\2\" +\n",
    "            MARKER_INTENDED_CORRUPTION +\n",
    "            r\"\\3\"\n",
    "        )\n",
    "        \n",
    "        text = cls.RE_CAMARA_LOWERCASE.sub(mod_subpattern, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_repeated_commissions(cls, subpattern, text):\n",
    "        freqs = collections.Counter(map(str.strip, cls.RE_COMMISSIONS_REPEATED.findall(text)))\n",
    "        \n",
    "        for commission_name, freq in freqs.items():\n",
    "            if freq <= 2:\n",
    "                continue\n",
    "            \n",
    "            mod_subpattern = f\" {MARKER_INTENDED_CORRUPTION}\".join(cls.RE_BLANK_SPACES.split(commission_name))\n",
    "            mod_subpattern = subpattern.replace(r\"\\1\", mod_subpattern)\n",
    "            \n",
    "            text = text.replace(commission_name, mod_subpattern)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def _detect_page_number(cls, subpattern, text):\n",
    "        match = cls.RE_PAGE_NUMBER_01.search(text)\n",
    "        \n",
    "        if match is None:\n",
    "            return text\n",
    "        \n",
    "        last_page = int(match.group(4) or match.group(9))\n",
    "        \n",
    "        mod_subpattern = subpattern.replace(r\"\\1\", r\"\\1\\2\\3\\4\")\n",
    "        \n",
    "        for i in range(1, 1 + last_page):\n",
    "            text = regex.sub(cls.FN_PAGE_NUMBER(i), mod_subpattern, text, flags=regex.IGNORECASE)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_barcode(subpattern, text)\n",
    "        text = cls._detect_page_number(subpattern, text)\n",
    "        text = cls._detect_camara_page_number(subpattern, text)\n",
    "        text = cls._detect_repeated_camara_lowercase(subpattern, text)\n",
    "        text = cls._detect_preamble_noise(subpattern, text)\n",
    "        text = cls.RE_SALA_DAS_SESSOES_CODE.sub(subpattern, text)\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        text = cls._detect_repeated_commissions(subpattern, text)\n",
    "        text = cls.RE_BARCODE_2.sub(subpattern, text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "class PostProcRecurrentNoise(DetectRecurrentNoise):\n",
    "    @classmethod\n",
    "    def sub(cls, subpattern: str, text: str, *args, **kwargs):\n",
    "        text = cls._detect_repeated_camara(subpattern, text)\n",
    "        return text\n",
    "    \n",
    "    \n",
    "UPPERCASE_LETTERS = \"ÀÁÂÃÇÉÊẼÓÕÔÜÚÍA-Z\\u0303\\u0300\\u0301\\u0302\\u0303\\u0304\\u0305\\u0340\\u0341\\u0342\\u0343\"\n",
    "UPPERCASE_LETTERS_OR_NUM = UPPERCASE_LETTERS + r\"0-9\"\n",
    "VALID_ROMAN_NUM = r\"(?:M{0,3}(?:C[MD]|D?C{0,3})(?:X[CL]|L?X{0,3})(?:I?X|I?V|V?I{1,3}))\"\n",
    "NRO_SMALL = r\"[nN]\\s*[oO0º°\\.]{1,3}\"\n",
    "NRO = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?<=\\s)[dD][eE]\\s+)?\" +\n",
    "    r\"[nN](?:[uú]me)?(?:ro)?[\\.\\s]*[oO0º°]\" +\n",
    "    r\"(?=[^\" + MARKER_VALID + UPPERCASE_LETTERS + UPPERCASE_LETTERS.lower() + r\"])|\" +\n",
    "    r\"(?<=\\s)\" + NRO_SMALL +\n",
    "    r\")\"\n",
    ")\n",
    "QUOTES = r\"”“”\\\"'‘\"\n",
    "QUOTES_CLASS = f\"[{QUOTES}]\"\n",
    "\n",
    "class AgreementList:\n",
    "    ITEMS = (\n",
    "        r\"(\\s*(?:\" +\n",
    "        r\"(?:[ÓO]rg[aã]o\\s*)?(?:Superior|[cC]oncedente|[cC]onve(?:nente|niada))|\" +\n",
    "        NRO + r\"\\s*(?:SIAFI|Original|Do\\s*conv[eê]nio)|\" +\n",
    "        r\"Valor\\s*(?:do\\s*conv[eê]nio)?|\" +\n",
    "        r\"(?:In[ií]cio|Fim)\\s*(?:d[ea]\\s*vig[eê]ncia)?|\" +\n",
    "        r\"Objeto|\" +\n",
    "        r\"Conv[eê]nio|\" +\n",
    "        r\"Processo|\" +\n",
    "        r\"Total\\s*de\\s*itens\\s*Licitados|\" +\n",
    "        r\"Fundamento\\s*legal|\"+\n",
    "        r\"Contratada|\" +\n",
    "        r\"Questionamentos|\" +\n",
    "        r\"Justificativa\"\n",
    "        r\")\\s*)\"\n",
    "    )\n",
    "    RE_ITEMS = regex.compile(ITEMS + r\"(\\s*:)\", regex.IGNORECASE)\n",
    "    REG_GET_LIST = regex.compile(\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + ITEMS + r\":\\s*[^:\" + MARKER_VALID + \"]{,150}?){2,10}\" +\n",
    "        ITEMS + r\":\\s*[^:\" + MARKER_VALID + r\"]{,150}\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    )\n",
    "    \n",
    "    @classmethod\n",
    "    def sub(cls, subpattern, text: str, *args, **kwargs):\n",
    "        re_match = cls.REG_GET_LIST.search(text)\n",
    "        if re_match is None:\n",
    "            return text\n",
    "        s_start, s_end = re_match.span()\n",
    "        text_slice = text[s_start:s_end]\n",
    "        subpattern = subpattern.replace(r\"\\1\", r\"\\1\" + f\" {MARKER_INTENDED_CORRUPTION} \" + r\"\\2\")\n",
    "        text_slice = cls.RE_ITEMS.sub(\n",
    "            subpattern,\n",
    "            text_slice,\n",
    "        )\n",
    "        text = f\"{text[:s_start]}{text_slice}{text[s_end:]}\"\n",
    "        return text\n",
    "\n",
    "\n",
    "STATES_ACRONYM = r\"\"\"\n",
    "(?:\n",
    "AC|\n",
    "AL|\n",
    "AP|\n",
    "AM|\n",
    "BA|\n",
    "CE|\n",
    "DF|\n",
    "ES|\n",
    "GO|\n",
    "MA|\n",
    "MT|\n",
    "MS|\n",
    "MG|\n",
    "PA|\n",
    "PB|\n",
    "PR|\n",
    "PE|\n",
    "PI|\n",
    "RJ|\n",
    "RN|\n",
    "RS|\n",
    "RO|\n",
    "RR|\n",
    "SC|\n",
    "SP|\n",
    "SE|\n",
    "TO\n",
    ")\n",
    "\"\"\".replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "DOC_ABBVR_LIST = (\n",
    "    \"COM\", \"DCR\", \"DEN\", \"DTQ\", \"DVS\", \"DVT\", \"EMC\", \"EMD\", \"EML\", \"LDO\", \"EMO\",\n",
    "    \"EMP\", \"EMR\", \"ERD\", \"ESB\", \"EXP\", \"INA\", \"INC\", \"MPV\", \"MSC\", \"PAR\", \"PDC\",\n",
    "    \"PEC\", \"PET\", \"PFC\", \"PLP\", \"PLV\", \"PRC\", \"PRF\", \"PRN\", \"PRO\", \"RCP\", \"REC\",\n",
    "    \"REL\", \"REM\", \"REP\", \"REQ\", \"RIC\", \"RPR\", \"SBE\", \"SBT\", \"SDL\", \"LDO\", \"SIT\",\n",
    "    \"TCU\", \"SOA\", \"STF\", \"SUG\", \"SUM\", \"CCJ\", \"TER\", \"TVR\", \"VTS\", \"PL\", \"PDL\",\n",
    ")\n",
    "DOC_ABBVR = r\"(?:\" + \"|\".join(DOC_ABBVR_LIST) + r\")\"\n",
    "DOC_ABBVR_WITH_SPACES = (\n",
    "    r\"(?:\" +\n",
    "    r\"|\".join(map(lambda item: r\"\\s*\".join([\"\", *item, \"\"]), DOC_ABBVR_LIST)) +\n",
    "    r\")\"\n",
    ")\n",
    "MINISTRIES = \"|\".join((\n",
    "    \"MAPA\",\n",
    "    \"MC\",\n",
    "    \"MCTI\",\n",
    "    \"MCom\",\n",
    "    \"MinC\",\n",
    "    \"MD\",\n",
    "    \"MDR\",\n",
    "    \"ME\",\n",
    "    \"MEC\",\n",
    "    \"MI\",\n",
    "    \"MJSP\",\n",
    "    \"MMA\",\n",
    "    \"MME\",\n",
    "    \"MMFDH\",\n",
    "    \"MRE\",\n",
    "    \"MS\",\n",
    "    \"MTP\",\n",
    "    \"MTur\",\n",
    "    \"CGU\",\n",
    "    \"SeGov\",\n",
    "    \"SGPR\",\n",
    "    \"CC\",\n",
    "    \"GSI\",\n",
    "    \"AGU\",\n",
    "    \"MAER\",\n",
    "    \"MESA\",\n",
    "    \"MINTER\",\n",
    "    \"MInfra\",\n",
    "    \"MPA\",\n",
    "    \"MPS\",\n",
    "    \"SMPE\",\n",
    "    \"SAE\",\n",
    "    \"PR\",\n",
    "    \"SEPPIR\",\n",
    "    \"SNPM\",\n",
    "    \"SRI\",\n",
    "    \"SNPTA\",\n",
    "    \"SAC\",\n",
    "))\n",
    "\n",
    "RAW_NUMBER_PREFIXES = (\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*|\" + NRO_SMALL + r\"|\\$|p[aá]g\\s*\\.|cep\\s*\\.|ltda\\s*\\.\"\n",
    ")\n",
    "\n",
    "BASE_LEGAL_ITEMS = (\n",
    "    r\"§\\s*[0-9]+\",\n",
    "    r\"Art(?:igo)?s?\\s*\\.?\\s*(?:(?:[-–º°0-9]+|(?<=igos?|\\s+)[A-Z]{1,2})|\\.{3}|[uú]nico)\",\n",
    "    r\"(?:\\(\\s*|\\s+|\" + QUOTES_CLASS + r\")(?:[A-Za-z]|[0-9]{1,2})\\s*\\)\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[úu]nico\",\n",
    "    r\"(?:par[áa]grafo|§)\\s*[0-9]{1,2}[\\soO0º°]*[-–:]\",\n",
    "    r\"(?:sub)?se[çc][ãa]o\",\n",
    "    r\"\\(?\" + f\"{VALID_ROMAN_NUM}\" + r\"\\s*(?:[-–\\)\\.])\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\(?\\s+[0-9]{1,2}[\\s0oOº°]*(?:[-–\\)]|\\.(?![\\.0-9]))\",\n",
    "    r\"(?<!\" + RAW_NUMBER_PREFIXES + r\")\\s+[0-9]{1,2}\\s*(?:\\.[0-9]+){1,2}(?![\\.0-9]*,)\",\n",
    ")\n",
    "MONTHS = (\n",
    "    \"(?:\" + \"|\".join((\n",
    "    r\"[jJ]an(?:eiro)?\",\n",
    "    r\"[fF]ev(?:ereiro)\",\n",
    "    r\"[mM]ar(?:[cç]o)\",\n",
    "    r\"[aA]br(?:il)?\",\n",
    "    r\"[mM]ai(?:o)?\",\n",
    "    r\"[jJ]un(?:ho)?\",\n",
    "    r\"[jJ]ul(?:ho)?\",\n",
    "    r\"[aA]go(?:sto)?\",\n",
    "    r\"[sS]et(?:embro)?\",\n",
    "    r\"[oO]ut(?:ubro)?\",\n",
    "    r\"[nN]ov(?:embro)?\",\n",
    "    r\"[dD]ez(?:embro)?\",\n",
    ")).upper() +\")\"\n",
    ")\n",
    "\n",
    "DATE = (\n",
    "    r\"(?:\" +\n",
    "    r\"\\s*(?:em|de)?\\s*\"\n",
    "    r\"(?:\" +\n",
    "    r\"[,\\s]*[0-9]{1,2}[-–/\\.;][0-9]{1,2}[-–/\\.;][0-9]{2,4}|\" +\n",
    "    r\"[,\\s]*(?:(?:de|em|/)[,\\.º/0-9\\s]*){1,3}[0-9]{4}|\" +\n",
    "    r\"[,\\s]*(?:de|em|/)?\\s*[0-9]{,2}[º°oO\\s]*(?:de|em|/)\\s*(?:\" + MONTHS +\n",
    "    r\")\\s*(?:de|em|/)\\s*[0-9]{4}\" +\n",
    "    r\")\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "# em 28 de abril de 2020\n",
    "DATE_OR_UNDERSCORES = (\n",
    "    r\"(?:\" +\n",
    "    r\"\\s*(?:em|de)?\\s*\"\n",
    "    r\"(?:\" +\n",
    "    r\"[,\\s]*[_0-9]{1,2}[-–/\\.;][_0-9]{1,2}[-–/\\.;][_0-9]{2,4}|\" +\n",
    "    r\"[,\\s]*(?:(?:de|em|/)[,\\.º_/0-9\\s]*){1,3}(?:[0-9]{4}|[\\._]+)|\" +\n",
    "    r\"[,\\s]*(?:de|em|/)?\\s*(?:[0-9]{,2}|[\\._]+)[º°oO\\s]*(?:de|em|/)\\s*(?:\" + MONTHS +\n",
    "    r\"|_+)\\s*(?:de|em|/)\\s*(?:[0-9]{4}|[\\._]+)\" +\n",
    "    r\")\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "UPPERCASE_DATE_OR_UNDERSCORES = DATE_OR_UNDERSCORES.replace(\"em\", \"EM\").replace(\"de\", \"DE\")\n",
    "EOF = r\".{,450}$\"\n",
    "EOF_OR_DATE = (\n",
    "    r\"(?:\" +\n",
    "    EOF +\n",
    "    r\"|\" +\n",
    "    DATE_OR_UNDERSCORES + \n",
    "    r\")\"\n",
    ")\n",
    "RE_DOC_CODE_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"030|Daniel|[eE]ss|Jaa|ac[fgp]|afpa|cmrv|(da[-–])?conle|[Cc]rps|\" +\n",
    "    r\"dennn?er|dpsl?|drb|epo|faa|‘?[Gg]ab|gsl|jaa|jbs|kvp|lgl|mlcl?|\" +\n",
    "    r\"mm|pnf|rpb|tksa|[Vv][Pp][Ll][cf]?|wgl\" +\n",
    "    r\")\"\n",
    ")\n",
    "RE_DOC_CODE_CORE = r\"(?:pls|mpv|plc|pec|pds|plv|prn|plp|pdl|tema)\"\n",
    "RE_DOC_CODE_SUFFIX = (\n",
    "    r\"(?:(?:\" +\n",
    "    r\"c(?:ompleme?ntar)?|eme(?:nda)?s?|\" +\n",
    "    r\"rev(?:is)?|sub(?:st\\.?(?:itutivo)?)?|sust|tt?\" +\n",
    "    r\")\\s*?)*\"\n",
    ")\n",
    "RE_DOC_CODE_FULL = (\n",
    "    r\"(\" +\n",
    "    r\"(?<=\\s)\" +\n",
    "    RE_DOC_CODE_PREFIX +\n",
    "    \"/\" +\n",
    "    RE_DOC_CODE_CORE +\n",
    "    r\"(?:[-–0-9]+)\" +\n",
    "    f\"(?:{RE_DOC_CODE_SUFFIX}[-–\\s]*?)+\" +\n",
    "    r\")\"\n",
    ")\n",
    "EXTRA_LEGAL_ITEMS = (\n",
    "    r\"•\",\n",
    "    r\"●\",\n",
    "    \"\\uF0B7\",\n",
    ")\n",
    "\n",
    "# CEP 70.160.900\n",
    "CEP_NUMBERS = r\"(?<g_cep_fst>[0-9]{2}\\.?[0-9]{3})(?<g_cep_snd>[-–\\.\\s]*[0-9]{2,3})\"\n",
    "CEP = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<g_cep_lab>(?:CEP|C[oó]digo\\s*[pP]ostal)[-–\\s\\.:]*)?\" + CEP_NUMBERS +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "BRASILIA = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<g_bra_name>Bras[ií]lia\" + ALL_BUT_NEWSEG + r\"{,5}?)?\" +\n",
    "    r\"(?<g_bra_df>(?<=[^\" + UPPERCASE_LETTERS + MARKER_VALID + r\"])DF|Distrito\\s*Federal)\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "NOISE_PLACE_ITEMS = (\n",
    "    r\"(?:\" +\n",
    "    f\"(?:sala|gabinete)\\s+({NRO}\\s*)?[{UPPERCASE_LETTERS_OR_NUM}]\" + r\"{1,3}(?:[-–\\.]\" +\n",
    "    f\"[{UPPERCASE_LETTERS_OR_NUM}]\" + r\")?|\" +\n",
    "    r\"pavimento\\s*(?:s(?:uperior)?|t[eé]rreo)?|\" +\n",
    "    f\"(?:Bloco|(?<=[^{UPPERCASE_LETTERS}])Ala)\\s+[A-Z](?=[^{UPPERCASE_LETTERS}])|\" +\n",
    "    f\"anexo\\s+(?:(\\s*{NRO}\\s*)?[0-9]+|\" + VALID_ROMAN_NUM + r\")\" +\n",
    "    r\")\"\n",
    ")\n",
    "NOISE_PLACE_SEP = (\n",
    "    r\"[^\" + MARKER_VALID + MARKER_NOISE_START[0] + MARKER_NOISE_END[0] + \"]{,40}\"\n",
    ")\n",
    "\n",
    "LARGER_BLOCKS_HIERARCHY = (\n",
    "    \"(?:PARTE\\s*(?:PRIMEIRA|SEGUNDA|TERCEIRA|QUARTA|QUINTA)\\s*(?:DO\\s*)?)?LIVRO\",\n",
    "    \"T[IÍ]TULO\",\n",
    "    \"CAP[IÍ]TULO\",\n",
    "    \"(?:Sub)?[sS]e[cç][aã]o\",\n",
    "    BASE_LEGAL_ITEMS[1] + r\"(?=\\s*[^\" + UPPERCASE_LETTERS_OR_NUM + r\"])\",\n",
    ")\n",
    "    \n",
    "SOURCE_URL = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:(?:\" +\n",
    "    r\"(?:\" +\n",
    "    r\"Dispon[ií]vel|Ler|Leia|mais|Vide|Veja|Fontes?|Extra[ií]do|\" +\n",
    "    r\"Link|URL|Endere[cç]o|Eletr[oô]nico|Dados|Matéria|Material|\" +\n",
    "    r\"Pesquisa|Ver|Publicado|[ÌI]ntegra|Respostas?|Confira|Conferir\" +\n",
    "    r\")\" +\n",
    "    r\"(?:[,\\s]|em|d?[aeo]s?|n[ao]s?|[ao]s)*)+\\s*\" + ALL_BUT_NEWSEG + r\"{,60}?[\\s:]*)?\" +\n",
    "    r\"[\\<\\s]*\" +\n",
    "    r\"(?:https?://|www){1,2}\" +\n",
    "    r\"(?:[^\\s\" + MARKER_VALID +\n",
    "    r\"]+|\\s+\\&(?=[\\sa-z]*=)|\\s*[a-z]+=[^\\&\\s\" + MARKER_VALID + r\"]\" +\n",
    "    r\"{,100}\\&|(?<=\\&)\\s*[a-z]+=)*\" +\n",
    "    r\"(?:[,\\.\\s]*acess(?:ado|o)\\s*em[\\s:]*\" + DATE_OR_UNDERSCORES + r\")?\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_NOISE_BLOCKS = (\n",
    "    regex.compile( #0, Câmara dos Deputados , Gab . 862 , Anexo IV\n",
    "        r\"((?:C[aâ]mara\\s*dos\\s*Deputados\\s*\" + ALL_BUT_NEWSEG + r\"{,15}?\\s*)?\" +\n",
    "        r\"(?:\"\n",
    "        r\"Anexo\\s*\" + VALID_ROMAN_NUM + r\"\" + ALL_BUT_NEWSEG + r\"{,30}?\" +\n",
    "        r\"Gab(?:inete)?.{,10}?\" + NRO + r\"?[0-9]+\" +\n",
    "        r\"|\" +\n",
    "        r\"Gab(?:inete)?.{,10}?\" + NRO + r\"?[0-9]+.{,30}?\" + r\"Anexo\\s*\" + VALID_ROMAN_NUM +\n",
    "        r\")\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile(f\"(?<!{NRO}[_X\\s\\.0-9]*)\" + r\"([0-9]{11,})\"), #1\n",
    "    regex.compile(r\"(_{20,}\\s*)+\"), #2\n",
    "    regex.compile( #3\n",
    "        r\"(\" +\n",
    "        r\"^(?:\\s*[^\\s\" +\n",
    "        \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM +\n",
    "        r\"]\\s*)+|\" +\n",
    "        r\"(?:\\s*[^\\s\\.\\)\\?\" +\n",
    "        \"\".join(m[0] for m in ALL_SPECIAL_MARKERS) + UPPERCASE_LETTERS_OR_NUM +\n",
    "        r\"]\\s*)+(?:\\.docx?\\s*)?$\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #4\n",
    "        r\"((?:(?:E[-–\\s]*mails?|Endere[cç]os?\\s*eletr[oô]nicos?)[\\s:]*)?\" +\n",
    "        r\"[-–a-zA-Z0-9\\._]{,40}\\s*@\\s*(?:[a-zA-Z]{1,15}\\.?){1,3})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    *[ #5-13-16-20\n",
    "        regex.compile(\n",
    "            r\"(?<=[:\\?;\\.\" + QUOTES + r\"]\\s*(?:e|ou)?\\s*)([0-9]+)(?=\\s*\" + legal_item + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        )\n",
    "        for legal_item in (*BASE_LEGAL_ITEMS, *EXTRA_LEGAL_ITEMS, *LARGER_BLOCKS_HIERARCHY[:-1])\n",
    "    ],\n",
    "    regex.compile( # 21\n",
    "        r\"((?<=C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*)CPI\\s*(?:da\\s*Petrobr[áa]s)?\\s*[-–]\\s*\" +\n",
    "        r\"(LEI\\s*ROUANET|Relat[oó]rio\\s*Final|EXPLORA[CÇ][AÃ]O\\s*SEXUAL\\s*DE\\s*CRIAN[CÇ]AS\\s*E\\s*ADOLESCENTES))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #22\n",
    "        r\"(Gabinete\\s*d[eoa]\\s*deputad[oa]\\s*[^0-9\" + MARKER_VALID + \"]{,50}?[-–\\\\/]\\s*\" +\n",
    "        STATES_ACRONYM +\n",
    "        \"(?=\\s|$))\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #23\n",
    "        r\"(c[âa]mara\\s*dos\\s*deputados\\s*.{,10}?\\s*pra[çc]a\\s*dos\\s*tr[êe]s\\s*poderes)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #24\n",
    "        r\"(C:(\\\\[^\\.\" + MARKER_VALID + \"]+)*\\.[a-z]+)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #25\n",
    "        r\"(\" +\n",
    "        r\"[\\[\\(\\s]*\" +\n",
    "        r\"[0-9]+\" +\n",
    "        r\"[\\]\\)\\s]*\" +\n",
    "        r\"[\" + UPPERCASE_LETTERS + r\"]{,15}?\" +\n",
    "        SOURCE_URL +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #26\n",
    "        r\"(Infoleg[^a-z]{,6}Autenticador)\", regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #27\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + NOISE_PLACE_ITEMS + NOISE_PLACE_SEP + r\"){2,4}\" +\n",
    "        NOISE_PLACE_ITEMS +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #28\n",
    "        r\"(\" +\n",
    "        r\"(?:formatado|r[ée]cuo)\\s*:\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"fonte\\s*:\\s*(?:[\\s0-9]+pt|\\(padr[aã]o\\)\\s*arial)\" +\n",
    "        r\"(?:\\s*,\\s*(?:Negrito|It[aá]lico|cor\\s*da\\s*fonte\\s*:\\s*autom[aá]tica))*|\" +\n",
    "        r\"n[aã]o\\s*cabe[cç]alho\\s*diferente\\s*na\\s*primeira\\s*p[aá]gina|\" +\n",
    "        r\"justificado|\" +\n",
    "        r\"cor\\s*da\\s*fonte\\s*:\\s*autom[aá]tica|\"\n",
    "        r\"corpo\\s*padr[aã]o\\s*,\\s*[aàá]\\s*(?:esquerda|direita)|\" +\n",
    "        r\"espaçamento\\s*entre\\s*linhas\\s*:\\s*(?:duplo|simples)|\" +\n",
    "        r\"espa[cç]o\\s*depois\\s*de\\s*:\\s*[0-9]+(?:cm|pt|['\\\"])|\" +\n",
    "        r\"(?:[,\\s]*\" +\n",
    "        r\"(?:Esquerda|Direita|Inferior|Largura|Altura|Superior|Primeira\\s*linha|Espa[cç]o\\s*depois\\s*de)\" +\n",
    "        r\"\\s*:\\s*\" +\n",
    "        r\"[\\.,0-9]+\\s*(?:['\\\"]|cm|pt)?[,\\s]*)+|\"\n",
    "        r\")\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    regex.compile( #29\n",
    "        r\"(\" + r\"\\s*\".join(\"LexEdit\") + r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    ")\n",
    "STANDARD_PREFIXES = (\n",
    "    r\"(?:^|;(?:\\s*e|\\s*ou)?|[\\.:\\?]|\\(\\s*(?:NR|AC|JW|\\.{3,})\\s*\\)\\s*|\" +\n",
    "    f\"[{QUOTES}]|\\uF03F)\"\n",
    ")\n",
    "PREFIX_EXTENSIONS = (\n",
    "    r\"(?:(?:\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    MARKER_NOISE_START + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    r\"\" + ALL_BUT_NEWSEG + r\"{,900}?\" +\n",
    "    MARKER_NOISE_END + r\"\\s*\" + DEBUG_PATTERN + r\"*\" +\n",
    "    f\"[\\s{MARKER_INTENDED_CORRUPTION}]*\" +\n",
    "    r\"))\"\n",
    ")\n",
    "RE_PRE_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE)\n",
    "    for pattern in [\n",
    "        *BASE_LEGAL_ITEMS,\n",
    "        *EXTRA_LEGAL_ITEMS,\n",
    "        r\"D[eê][-–]se\\s*ao\\s*Projeto\\s*a\\s*seguinte\\s*reda[cç][aã]o\\s*:\",\n",
    "    ]\n",
    ")\n",
    "ADDITIONAL_TITLES = (\n",
    "    r\"(?:\" +\n",
    "    r\"Ju[ií]z[ea]?s?|M[\\.\\s]*M[aª]?[\\s\\.]*|\" +\n",
    "    r\"Doutor[ea]?s?|D\\.?r[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Professor[ea]?s?|Prof[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Advogad[ao]s?|Adv[\\s\\.]*|\" +\n",
    "    r\"Capit[aã](?:o|es)?|Cap[\\s\\.]*|\" +\n",
    "    r\"Pastor[ea]?s?|Pr[aª]?s?[\\s\\.]*|\" +\n",
    "    r\"Sargent[ao]s?|Sarg[\\s\\.]*|\" +\n",
    "    r\"Reitor[ea]?s?\" +\n",
    "    r\")*\"\n",
    ")\n",
    "ABBVR_EXMO = r\"Ex\\.?m[aªoº]s?\\s*\\.?\"\n",
    "ABBVR_EX = r\"Ex\\.?[aªoº]?s?\\s*\\.\\s*[ºªᵉ]?\"\n",
    "ABBVR_SR = r\"S\\.?r\\.?[aªeᵉ]?s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\"\n",
    "ABBVR_MM = r\"M\\.?M\\.[aªoº]*\"\n",
    "DEPT_EXTENSION_CORE = (\n",
    "    r\"(?:(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)?[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"(?:\" + ABBVR_SR + r\"|Senhor[ea]?s?)[\\s\\.]*(?:Deputad[oa]s?|Dep\\s*\\.)?\\s*\" + ADDITIONAL_TITLES + \"|\" +\n",
    "    r\"mesa\\s*(?:diretora)?|\" +\n",
    "    r\"(?:MENSAGEM|\" + DOC_ABBVR + \")\\s*\" + NRO + r\"|\" +\n",
    "    r\"poder\\s*(?:executivo|legislativo|judici[aá]rio)|\" +\n",
    "    r\"CPI|\" +\n",
    "    r\"Bancada|\" +\n",
    "    r\"PROVENIENTE\\s*DA\\s*(?:MEDIDA\\s*PROVIS[OÓ]RIA|MPV)|\" + \n",
    "    COMMISSIONS +\n",
    "    r\")\\s*\"\n",
    ")\n",
    "#DOS/AS SRS/AS\n",
    "DEPT_EXTENSION_A = (\n",
    "    r\"[^\\(\" + MARKER_VALID + r\"]{,100}\\(\\s*(?:D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}{MARKER_VALID}\\)]\" + r\"{1,200})?\\)\" +\n",
    "    r\"(?!\\s*[;:,])\"\n",
    ")\n",
    "DEPT_EXTENSION_B = (\n",
    "    r\"\" + ALL_BUT_NEWSEG + r\"{,100}?D[oa]s?(?:\\s*[/\\(]\\s*[oa]s?\\s*\\)?)?\\s*\" +\n",
    "    DEPT_EXTENSION_CORE +\n",
    "    f\"(?:[^{QUOTES}{MARKER_VALID}]\" + r\"{1,100}\" + f\"?(?=[{QUOTES}]))?\"\n",
    ")\n",
    "DEPT_EXTENSION = f\"(?:{DEPT_EXTENSION_A}|{DEPT_EXTENSION_B})\"\n",
    "DATE_AND_ID = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:DE\\s*)+?[\\._X0-9]+|\" +\n",
    "    f\"(?:{NRO}\" + r\"[_X\\s\\.0-9]*)?\\s*(?:\" + UPPERCASE_DATE_OR_UNDERSCORES + r\")|\" +\n",
    "    NRO + r\"[_X\\s\\.0-9]*\" + r\"(?:[^,\" + MARKER_VALID + r\"]{,30}?[,\\.]+\\s*(?:DE\\s*)+?[\\._X0-9]+)?\" +\n",
    "    r\")\"\n",
    ")\n",
    "# DATE\n",
    "fn_lambda_single = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" \n",
    "fn_lambda_double = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \"\n",
    "fn_lambda_triple = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \"\n",
    "fn_lambda_quad = lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" + f\" {symb} {deb} \" + r\"\\3\" + f\" {symb} {deb} \" + r\"\\4\" + f\" {symb} {deb} \"\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_PREFIX = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?:\\s(?:Ao|[AÁÀ]))?s?\\s*\" +\n",
    "    r\"(?:\\s*\" +\n",
    "    r\"(?:\" +\n",
    "    r\"Excelent[ií]ssim[oa]s?|\" + ABBVR_EXMO + r\"|\" +\n",
    "    r\"Merit[ií]ssim[oa]s?|\" + ABBVR_MM + r\"|\" +\n",
    "    r\"Magn[iíì]fic[ao]s?|\"\n",
    "    r\"A\\s*sua\\s*(?:magnific[eê]ncia|excel[eê]ncia)|\" +\n",
    "    r\"(?:Vossa|V\\s*\\.)\\s*(?:excel[eê]ncias?|\" + ABBVR_EX + r\")|\" +\n",
    "    r\"Senhor[ae]?s?|\" + ABBVR_SR +\n",
    "    r\")\" +\n",
    "    r\"\\s*)+\" +\n",
    "    r\"[\\.\\s]*(?:Primeir[oa]s?|Vices?|[-–\\s])*\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_CORE = (\n",
    "    r\"(?:\" +\n",
    "    r\"Pres(?:id(?:ent[ae])?)?s?|\" +\n",
    "    r\"Min(?:istr[oa])?s?|\" +\n",
    "    r\"Advogad[ao]s?\\s*Geral\\s*da\\s*Uni[aã]o|\" +\n",
    "    r\"Secret[aá]ri[oa]s?|\" +\n",
    "    r\"Reitor[ea]?s?\" +\n",
    "    r\")\"\n",
    ")\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_SUFFIX = (\n",
    "    r\"(?:[^,:;\\.\" + MARKER_VALID + r\"]{,75}?[,:;\\.])\"\n",
    ")\n",
    "REQUEST_PRESIDENT_OR_MINISTRY = (\n",
    "    \"(?:\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_PREFIX +\n",
    "    f\"{REQUEST_PRESIDENT_OR_MINISTRY_CORE}?\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_SUFFIX +\n",
    "    \")\"\n",
    ")\n",
    "REQUEST_PRONOUN_COLON = (\n",
    "    \"(?:\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY_PREFIX +\n",
    "    f\"{REQUEST_PRESIDENT_OR_MINISTRY_CORE}?\" +\n",
    "    r\"[^:\" + MARKER_VALID + \"r]{,75}?\\s*:\" +\n",
    "    \")\"\n",
    ")\n",
    "\n",
    "REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED = (\n",
    "    r\"(?:\" +\n",
    "    r\"(?<=(?<!\" + f\"{ABBVR_EXMO}|{ABBVR_EX}|{ABBVR_SR}|{ABBVR_MM}\" +\")\\s*\\.\" +\n",
    "    ALL_BUT_NEWSEG + r\"{,10}?|\\)\" + ALL_BUT_NEWSEG + r\"{,10}?)\" +\n",
    "    REQUEST_PRESIDENT_OR_MINISTRY + \"|\" +\n",
    "    r\"(?:(?<=\\.\\s*)(\\s+O\\s*)?Requeir(?:o|emos)|Solicit(?:o|amos))\" +\n",
    "    r\")\"\n",
    ")\n",
    "PRACA_DTP = r\"Pra[çc]a\\s*dos\\s*tr[eê]s\\s*poderes\"\n",
    "PRACA_DTP_NEIGHBORS = (\n",
    "    r\"(?|\" +\n",
    "    r\"(Gabinete\\s*)?(Bras[ií]lia)|(D)(F)|(C[aâ]mara\\s*Dos)(\\s*Deputados)|\" +\n",
    "    r\"((?:Pal[aá]cio\\s*do\\s*)?Congresso\\s*)(Nacional)|(Gabinete\\s*)(Parlamentar)|\" +\n",
    "    r\"(Comiss[aã]o\\s*de\\s*)(Fiscaliza[cç][aã]o\\s*Financeira[e\\s]*Controle)\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_SPECIAL = (\n",
    "    (regex.compile( #0\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ\\u0303]ES|[AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,15}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #1\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ\\u0303]ES|[AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,15}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #2\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID}|{DEPT_EXTENSION})\" + r\"{1,2}\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #3\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,25}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    (regex.compile( #4\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.\" +\n",
    "        MARKER_VALID + r\"]{,20}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    \n",
    "    (regex.compile( #5\n",
    "        r\"((?:(?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*)?INDICA[CÇ][AÃ]O[^\\.\" +\n",
    "        MARKER_VALID + r\"]{,20}?\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1,\n",
    "    ),\n",
    "    \n",
    "    (regex.compile( #6\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O\" + ALL_BUT_NEWSEG + r\"{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG +\n",
    "        r\"{,1000}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara)\" +\n",
    "        r\"(\\s*dos\\s*deputados)([^\\.\" + MARKER_VALID + r\"]*?resolve\\s*:)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" +\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\3\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\"\n",
    "    ), 1),\n",
    "    \n",
    "    (regex.compile( #7\n",
    "        r\"((?:(?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE\\s*)?RESOLU[CÇ][AÃ]O\" + ALL_BUT_NEWSEG + r\"{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG +\n",
    "        r\"{,1000}?)((?:A\\s*mesa\\s*d)?A\\s*C[âa]mara)\" +\n",
    "        r\"(\\s*dos\\s*deputados)([^\\.\" + MARKER_VALID +\n",
    "        \"]*?resolve\\s*:)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\" +\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\3\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\4\" + MARKER_INTENDED_CORRUPTION + r\"\\5\"\n",
    "    ), 1),\n",
    "    \n",
    "    (regex.compile( #8\n",
    "        r\"(MEDIDA\\s*PROVIS[ÓO]RIA\" + ALL_BUT_NEWSEG + r\"{,50}?\" + \n",
    "        DATE_AND_ID +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1200}?)\" +\n",
    "        r\"([OA]\\s*President[ea]\\s*da\\s*rep[úu]blica[^:\" + MARKER_VALID +\n",
    "        r\"]+?com\\s*for[cç]a\\s*de\\s*lei\\s*:)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, 1),\n",
    "    (regex.compile( #9\n",
    "        r\"\\s*\".join([\n",
    "            r\"(\",\n",
    "            r\"(?:\",\n",
    "            *r\"Documento\",\n",
    "            r\"|\",\n",
    "            *r\"Chancela\",\n",
    "            r\")\",\n",
    "            *r\"eletr\",\n",
    "            r\"[oô]\",\n",
    "            *r\"nic\",\n",
    "            r\"[ao]\",\n",
    "            r\".{,400}?\",\n",
    "            *r\"mesa\",\n",
    "            NRO,\n",
    "            r\"[\\s0-9]+\",\n",
    "            r\"(?:de|/|\\\\)\",\n",
    "            \"(?:\\s*[0-9]\\s*){4}\",\n",
    "            r\"\\.\",\n",
    "            r\")\",\n",
    "        ]),\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    (regex.compile( #10 #PL n .1 31 1/ 20 20 Ap re se nt aç ão : 3 1/ 03 /2 02 0 13 : 0 4\n",
    "        r\"(\" +\n",
    "        r\"(?:\" + DOC_ABBVR_WITH_SPACES + \"\\s*\" + f\"(?:{NRO})*\" + r\"\\s*[\\d\\s]+/[\\s\\d]+)?+\\s*\" +\n",
    "        r\"\\s*\".join([\"\", *\"Apresenta\", \"[çc]\", \"[aã]\", *\"o:\", \"\"]) +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*/\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){4}\" + r\"\\s*\" +\n",
    "        r\"\\s*(?:[0-9]\\s*){2}\" + r\"\\s*:\\s*\" +\n",
    "        r\")\" +\n",
    "        f\"({MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        f\"({MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\" +\n",
    "        r\"(\\s*[0-9]\\s*)\" +\n",
    "        r\"(?:\" +\n",
    "        r\"([-–]*)\" +\n",
    "        r\"(\" + r\"\\s*\".join([\"\", *\"Mesa\", \"\"]) + r\")\" +\n",
    "        r\")?\" +\n",
    "        r\"([\\s0-9]+(?=[\\s0-9]*(?:[§\" + UPPERCASE_LETTERS + r\"]|$)))?\"\n",
    "        , regex.IGNORECASE | regex.MULTILINE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\3\\5\" + MARKER_INTENDED_CORRUPTION + r\"\\6\" + MARKER_INTENDED_CORRUPTION + r\"\\7\\8\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (DetectRecurrentNoise, #11\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #12\n",
    "#         r\"([:;\" + QUOTES + r\"\\?]\\s*\" + f\"{PREFIX_EXTENSIONS}?)\" +\n",
    "#         r\"(\\s{,10}[-–])\" +\n",
    "#         f\"(?!\\s*{MARKER_NOISE_START})\"\n",
    "        r\"_________PLACEHOLDER_________\"\n",
    "    ),\n",
    "    lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    (regex.compile( #13\n",
    "        r\"((?<!\\s[sS]\\s*\\.\\s*[aA]\\s*|[lL][tT][dD][aA]\\s*)\\.)\" +\n",
    "        r\"(\\s{,10}[-–])(?=\\s*[\" + UPPERCASE_LETTERS + \"])\"),\n",
    "    lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    (regex.compile( #14\n",
    "        r\"(?<=,\\s*(?:e|ou)\\s*)\" + f\"(?={BASE_LEGAL_ITEMS[2]})\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #15\n",
    "        r\"(EMI\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*\" + f\"(?:(?:{MINISTRIES})/?)+\" + r\")\"\n",
    "        r\"(\\s*[^,\" + MARKER_VALID + r\"]{,50}?,\\s*(?:\" + DATE + r\")[\\.\\s]*)?\"\n",
    "    ),\n",
    "    fn_lambda_double, None),\n",
    "    \n",
    "    (regex.compile( #16\n",
    "        r\"(\" +\n",
    "        r\"(?:TVR|(?:Ato\\s*de\\s*)?Concess[aã]o(?:e|\\s)*Renova[cç][ãa]o(?:de|\\s)*Concess[aã]o(?:de|\\s)*Emissora(?:de|\\s)*Rádio(?:e|de|\\s)*Televisão)\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID}|{DEPT_EXTENSION}|{NRO}\\s*[_X\\s\\.,X0-9]*)+\" +\n",
    "        r\")\" +\n",
    "        r\"\\s*((?:mensagem|msc[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4})\" +\n",
    "        r\"\\s*((?:aviso|av[\\s\\.]*)\\s*\" + NRO + \"[_\\.0-9\\s]+/\\s*[0-9]{4}\" +\n",
    "        r\"(?:\\s*[-–]\\s*C\\s*\\.\\s*Civil)?)\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, 1),\n",
    "    \n",
    "    (regex.compile( #17\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*|\\s*DE\\s*CONVERS[AÃ]O\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID})?\" +\n",
    "        f\"(?!{DEPT_EXTENSION})\" +\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \"\n",
    "    ), 2),\n",
    "    \n",
    "    (regex.compile( #18\n",
    "        r\"((?:SUBSTITUTIVO\\s*AO\\s*)?PROJETO\\s*DE)(\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        r\"LEI(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*|\\s*DE\\s*CONVERS[AÃ]O\\s*)*|\" +\n",
    "        r\"DECRETO\\s*LEGISLATIVO|\" +\n",
    "        r\"RESOLU[ÇC][AÃ]O|\" +\n",
    "        r\"EMENDA\\s*CONSTITUICIONAL|\" +\n",
    "        r\"EMENDA\\s*[AÁÀ]\\s*CONSTITUI[CÇ][AÃ]O|\" +\n",
    "        r\"MEDIDA\\s*PROVIS[OÓ]RIA\"\n",
    "        r\")\\s*\" +\n",
    "        f\"(?:{DATE_AND_ID})\" +\n",
    "        r\"\\s*[\\s\" + UPPERCASE_LETTERS_OR_NUM + r\"]{,150}?\" +\n",
    "        r\"(?=(?:[OA]\\s+)?[\\.\" + UPPERCASE_LETTERS + \"][a-z])\" +\n",
    "        r\")\"),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\2\" + f\" {symb} {deb} \"\n",
    "    ), 2),\n",
    "    \n",
    "    (regex.compile( #19\n",
    "        r\"(?<=[\" + UPPERCASE_LETTERS + \"]{3,}\\s+)([0-9]{1,2}\\s*\\.\\s+[0-9]+)\"),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    \n",
    "    (regex.compile( #20\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*|ou|,)\\s*)\" +\n",
    "        r\"(?:([^0-9a-z\\s\" + MARKER_VALID +\n",
    "        r\"]?)(\\s*(?:0xx)?[0-9]{2,}\\s*)([^0-9a-z\\s\" + MARKER_VALID + r\"]?))?\" +\n",
    "        r\"(\\s*[0-9]{4,}\\s*[-–\\.\\s]?)(\\s*[0-9]{4,})\" +\n",
    "        r\"((?:\\s*/\\s*[0-9]{4,}\\s*)*)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\5\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\6\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\7\" + MARKER_INTENDED_CORRUPTION + f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #21\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.\" + MARKER_VALID + r\"]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{60,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    \n",
    "    (regex.compile( #22\n",
    "        r\"(PROPOSTA\\s*DE\\s*FISCALIZA[CÇ][AÃ]O\\s*E\\s*CONTROLE[^\\.\" + MARKER_VALID + r\"]{,20}?\" +\n",
    "        f\"\\s*(?:{DATE_AND_ID})?\\s*\" +\n",
    "        f\"\\s*(?:{DEPT_EXTENSION})?\\s*\" +\n",
    "        r\")\\s*\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        f\"(?={REQUEST_PRONOUN_COLON})\", regex.IGNORECASE),\n",
    "    fn_lambda_double, 1),\n",
    "    \n",
    "    (regex.compile( #23\n",
    "        r\"(OF[IÍ]CIO\\s*\" + NRO + r\"\" + ALL_BUT_NEWSEG + r\"{,110}?\\s*)\" +\n",
    "        r\"((?:Bras[ií]lia|Senado\\s*Federal)?[,\\s]*(?:\" + DATE_OR_UNDERSCORES + r\")[\\.\\s]*)\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,500}?\\s*)\" +\n",
    "        r\"(Assunto\\s*:\\s*\" + ALL_BUT_NEWSEG + r\"{,400}?)\" +\n",
    "        f\"(?={REQUEST_PRESIDENT_OR_MINISTRY_AFFIXED}|{REQUEST_PRONOUN_COLON})\", regex.IGNORECASE\n",
    "    ),\n",
    "    fn_lambda_quad, 1),\n",
    "    \n",
    "    (regex.compile( #24\n",
    "        r\"(Atenciosamente\\s*),\" +\n",
    "        r\"(\\s*\" + ALL_BUT_NEWSEG + r\"{,250}?\" +\n",
    "        RE_DOC_CODE_FULL +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + MARKER_INTENDED_CORRUPTION + r\"\\1\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\",\\2\" + f\" {symb} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #25\n",
    "        r\"((?:REQUERIMENTO|SOLICITA[CÇ][AÃ]O)\\s*DE\\s*INFORMA[CÇ](?:[OÕ\\u0303]ES|[AÃ]O)\" + ALL_BUT_NEWSEG + r\"{,10}?\" +\n",
    "        DATE_AND_ID +\n",
    "        f\"(?:{DEPT_EXTENSION})?\" +\n",
    "        r\"\\s*)\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG + r\"{,1000}?)\" +\n",
    "        r\"([ÀÁA]\\s*sua\\s*excel[eê]ncia\" + ALL_BUT_NEWSEG + r\"{,100}?)\" +\n",
    "        r\"(?=(?:\" + REQUEST_PRESIDENT_OR_MINISTRY + \"[,\\s]*)?(?:Requeiro|Solicito))\", regex.IGNORECASE),\n",
    "    fn_lambda_triple, 1),\n",
    "    \n",
    "    (regex.compile( #26\n",
    "        r\"(Autora?\\s*:\\s*\" + ALL_BUT_NEWSEG + r\"{,200}?)(\\s*Relatora?\\s*:)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    (regex.compile( #27\n",
    "        r\"(?<=(?:Relatora?|Autora?)\\s*:\" + ALL_BUT_NEWSEG + r\"{,200}?\\s+)(\" + VALID_ROMAN_NUM + r\"[-–\\s]+RELAT[OÓ]RIO\\s+)\", regex.IGNORECASE),\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    \n",
    "    (AgreementList, #28\n",
    "    lambda symb, deb: f\" {symb} {deb} \" + r\"\\1\", None),\n",
    "    \n",
    "    (regex.compile( #29\n",
    "        r\"(?=Reiterando\\s*os\\s*votos\\s*de\\s*apre[cç]o\\s*e\\s*considera[cç][aã]o)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: f\" {symb} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #30\n",
    "        r\"(?<=\\s|^)(\\s*(?:(?:Tel(?:efone)?s?|Fones?|Fax(?:es)?)[\\.\\s:]*)\\s*)?\" +\n",
    "        r\"(?:([^0-9a-z\" + MARKER_VALID + r\"]?)(\\s*(?:0xx)?[0-9]{2,}\\s*)([^0-9a-z\" + MARKER_VALID + r\"]?))?\" +\n",
    "        r\"(\\s*[0-9]{4,}\\s*[-–\\.\\s]?)(\\s*[0-9]{4,})\" +\n",
    "        r\"((?:\\s*/\\s*[0-9]{4}\\s*)*)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\\2\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\3\\4\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\5\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\6\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\7\" + f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #31\n",
    "        r\"(\" +\n",
    "        r\"(?:DESPACHO\\s*:\\s*|\\(\\s*)?\" +\n",
    "        f\"\\s*[AÃÁÀ]S\\s*{COMMISSIONS}\\s*\" +\n",
    "        r\"\\(\\s*\" +\n",
    "        r\")\" +\n",
    "        r\"(ART(?:IGO)?[\\s\\.]+)\" +\n",
    "        r\"([0-9]+.{,60}?\\))\" +\n",
    "        r\"(.{,20}?\\))?\" +\n",
    "        r\"(?=.{,150}$)\", regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb, deb: (\n",
    "        f\" {symb} {deb} \" + r\"\\1\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\2\" + MARKER_INTENDED_CORRUPTION + r\"\\3\" +\n",
    "        MARKER_INTENDED_CORRUPTION + r\"\\4\" + f\" {symb} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #32\n",
    "        PRACA_DTP_NEIGHBORS + r\"(?P<g_PRACA>.{,6}?\" +\n",
    "        f\"{PRACA_DTP})|(?P<g_PRACA>{PRACA_DTP}\" +\n",
    "        r\".{,6}?)\" + PRACA_DTP_NEIGHBORS,\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" +\n",
    "        r\"\\1\" + MARKER_INTENDED_CORRUPTION + r\"\\2\\3\\4 \" + MARKER_INTENDED_CORRUPTION + r\"\\5\" +\n",
    "        f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #33\n",
    "        r\"(^\\s*[0-9][\\s0-9]*|(?<!:[\\s0-9_]*)(?:[0-9]+_+)?\\s*[0-9][\\s0-9]*(?:\\.docx?\\s*)?$)\"\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #34\n",
    "        f\"({CEP}(?<g_cep_sep>[-–\\s]*){BRASILIA})\",\n",
    "        regex.IGNORECASE\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_fst>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_snd>\" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_sep>\" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_name>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_df>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #35\n",
    "        f\"{BRASILIA}(?<g_cep_sep>[-–\\s]*){CEP}\",\n",
    "        regex.IGNORECASE\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_name>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_bra_df>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_sep>\" +\n",
    "        MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_fst>\" + MARKER_INTENDED_CORRUPTION +\n",
    "        r\"\\g<g_cep_snd>\" +\n",
    "        f\" {symb_end} {deb} \"\n",
    "    ), None),\n",
    "    \n",
    "    (regex.compile( #36\n",
    "        r\"([:;\" + QUOTES + r\"\\?]\\s*\" + f\"{PREFIX_EXTENSIONS}?)\" +\n",
    "        r\"(\\s{,10}[-–])\" +\n",
    "        f\"(?!\\s*{MARKER_NOISE_START})\"\n",
    "    ),\n",
    "    lambda symb, deb: r\"\\1\" + f\" {symb} {deb} \" + r\"\\2\", None),\n",
    "    \n",
    "    ####################\n",
    "    \n",
    "    (regex.compile( #37\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*)\" +\n",
    "        r\"(\" +\n",
    "        r\"(?:(?:web.?|home\\.?)?(?:Site|page)|S[ií]tio|Endere[cç]o)s?\\s*(?:eletr[oô]nicos?)?[\\s:]*\" +\n",
    "        r\"(?:https?://)?\" +\n",
    "        r\"www\\.([^\\s\\.\" + MARKER_VALID + r\"]+\\.){1,5}[^\\s\" + MARKER_VALID + r\"]+\" +\n",
    "        r\"(?:[,\\s\\.]*acess(?:ado|o)\\s*em[\\s:]*\" + DATE_OR_UNDERSCORES + r\")?\" +\n",
    "        r\")\", regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #38\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*|\" +\n",
    "        r\"\\(\\s*(?:NR|AC|JW|\\.{3})\\s*\\)\\s*)\" +\n",
    "        r\"([0-9]+)(?=\\s*(?:Art|§|Par[aá]grafo|(?:Sub)?se[cç][aã]o))\", regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \", None),\n",
    "    \n",
    "    (regex.compile( #39\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\\s*)([^\\s\" + MARKER_VALID + UPPERCASE_LETTERS + r\"])((?:\\s|\\2)*)(\\s*)\" +\n",
    "        f\"(?={MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*)\",\n",
    "        regex.IGNORECASE),\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\\2\\3\\4\" + f\" {symb_end} {deb} \", None),\n",
    ")\n",
    "\n",
    "RE_PRE_POST_BLOCKS = tuple(\n",
    "    regex.compile(\n",
    "        f\"{pattern}\" +\n",
    "        f\"(\\s*{MARKER_NOISE_START}{ALL_BUT_NEWSEG}*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)?\",\n",
    "        reg_flags,\n",
    "    )\n",
    "    for pattern, reg_flags in [\n",
    "        ( #0\n",
    "            r\"(ACORDO\\s*DE\\s*[-,\"\n",
    "            + UPPERCASE_LETTERS_OR_NUM\n",
    "            + r\"\\s]+)(?=(?:[OA]\\s+)?[\"\n",
    "            + UPPERCASE_LETTERS\n",
    "            + r\"][a-z])\",\n",
    "            0,\n",
    "        ),\n",
    "        (r\"(?<!\\(\" + ALL_BUT_NEWSEG + r\"{,50}?)(\" + COMMISSIONS + \")\", 0), #1\n",
    "        ( #2\n",
    "            r\"(O\\s*Congresso\\s*Nacional\\s*\" +\n",
    "            ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "            r\"\\s*decreta\\s*\" + ALL_BUT_NEWSEG + r\"{,40}?\\s*:)\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #3\n",
    "            r\"(A\\s*C[aâ]mara\\s*dos\\s+deputados\\s*\" +\n",
    "            ALL_BUT_NEWSEG + r\"{,250}?\\s*\" +\n",
    "            r\"\\s*decreta\\s*\" + ALL_BUT_NEWSEG +\n",
    "            r\"{,40}?\\s*:)\",\n",
    "            regex.IGNORECASE\n",
    "        ),\n",
    "        ( #4\n",
    "            r\"((?:SUBSTITUTIVO\\s*AO\\s*)?\" +\n",
    "            r\"Projeto\\s*de\\s*Lei\\s*\" +\n",
    "            r\"(?:\\s*COMPLEMENTAR\\s*|\\s*DA\\s*C[AÂ]MARA\\s*|\\s*DE\\s*CONVERS[AÃ]O\\s*)*\\s*\" +\n",
    "            f\"(?:{DATE_AND_ID})?\" + r\"\\s*\"+ DEPT_EXTENSION + r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #5\n",
    "            r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Decreto\\s*Legislativo\\s*\" +\n",
    "            DATE_AND_ID +\n",
    "            f\"(?:{DEPT_EXTENSION})?\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #5\n",
    "            r\"((?:SUBSTITUTIVO\\s*AO\\s*)?Projeto\\s*de\\s*Resolu[cç][aã]o\\s*\" +\n",
    "            f\"(?:{DEPT_EXTENSION}|{DATE_AND_ID})\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #6\n",
    "            r\"(?<=^[^\\(]{,500}?)(Mensagem\\s*\" + DATE_AND_ID + r\"\\s*[0-9][0-9\\s]*)\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        ( #7\n",
    "            r\"((?:SUBSTITUTIV[AO]\\s*[ÁÀA]\\s*)?\" +\n",
    "            r\"Proposta\\s*de\\s*emenda\\s*(?:cons?titucional|[aàá]\\s*constitui[çc][ãa]o).*?\" +\n",
    "            f\"(?:{DEPT_EXTENSION})\" +\n",
    "            r\")\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        *[ #8, 9, 10\n",
    "            (\n",
    "                r\"(\" +\n",
    "                f\"{LARGER_BLOCKS_HIERARCHY[i]}\" + r\"\\s*\" + f\"(?:{VALID_ROMAN_NUM}|[0-9]+)\" +\n",
    "                r\"(?:[-–\\.\\s,\" + UPPERCASE_LETTERS_OR_NUM + r\"])+?\" +\n",
    "                r\"(?:\\s*\" +\n",
    "                MARKER_NOISE_START + r\"\" + ALL_BUT_NEWSEG + r\"{,800}?\" + MARKER_NOISE_END +\n",
    "                r\"\\s*\" + f\"{DEBUG_PATTERN}*\" +\n",
    "                r\"\\s*)?\" +\n",
    "                f\"(?={MARKER_VALID}|\" + r\"|\".join(LARGER_BLOCKS_HIERARCHY[i + 1:]) + r\")\" +\n",
    "                r\")\",\n",
    "                regex.IGNORECASE,\n",
    "            )\n",
    "            for i in range(len(LARGER_BLOCKS_HIERARCHY) - 1)\n",
    "        ],\n",
    "        ( #11, Esta lei entra em vigor cento e oitenta dias após a data de sua publicação\n",
    "            r\"(Art\" + ALL_BUT_NEWSEG + r\"{,10}?Est[áàãa]\\s*\" +\n",
    "            r\"(?:lei|EC|Emenda\\s*(?:Constitucional|[àaá\\s]*constitui[cç][aã]o)|resolu[cç][aã]o)\\s*\" +\n",
    "            r\"entr[ea]\\s*em\\s*vigor\\s*\" + ALL_BUT_NEWSEG +\n",
    "            r\"{,100}?\\s*(?:data\\s*de\\s*)sua\\s*publica[cç][aã]o\\s*(?:\\.|$))\",\n",
    "            regex.IGNORECASE,\n",
    "        ),\n",
    "        (r\"(APRECIA[CÇ][AÃ]O\\s*:\" + ALL_BUT_NEWSEG + r\"{,100})$\", 0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "RE_POST_PROCESSING_BLOCKS = (\n",
    "    (PostProcRecurrentNoise, #0\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"),\n",
    "    \n",
    "    (regex.compile( #1\n",
    "        r\"(\" +\n",
    "        f\"[^{UPPERCASE_LETTERS_OR_NUM}{MARKER_VALID}]\" +\n",
    "        r\"[0-9]\" +\n",
    "        r\"[\\]\\)\\s]+\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,120}?\" +\n",
    "        SOURCE_URL +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE | regex.REVERSE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        r\"(?<=\"\n",
    "        r\"(?:^\\s*(?!.{,20}C[ÂA]MARA).{,20}?\\s*|\" +\n",
    "        f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"\\s*\" +\n",
    "        r\")\"+\n",
    "        r\"(\" +\n",
    "        f\"(?:Gabinete\\s*d[oa]|^\\s*|(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*))\" +\n",
    "        r\"\\s*deputad[oa]\\s*(?:federal)?\\s*\" +\n",
    "        f\"{ALL_BUT_NEWSEG}\" + r\"{,200}?\" +\n",
    "        r\")\" +\n",
    "        f\"(?={MARKER_VALID}|{MARKER_NOISE_START})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"({MARKER_VALID}\\s*{DEBUG_PATTERN}*)(\\s*)\" +\n",
    "        f\"(\\s+[{UPPERCASE_LETTERS_OR_NUM}]\" + r\"{1,3}\\s+)\" +\n",
    "        f\"(?=\\s*{MARKER_VALID}|\\s*$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\3\\2\" + f\" {symb_end} {deb} \" + r\"\\1\"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"(?<={MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\" +\n",
    "        r\"(\" + ALL_BUT_NEWSEG +\n",
    "        r\"{,10}?\\s*C[AÂ]MARA\\s*DOS\\s*DEPUTADOS\\s*\" +\n",
    "        ALL_BUT_NEWSEG + r\"{,10}?)\" +\n",
    "        f\"(?={MARKER_VALID}|{MARKER_NOISE_START})\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"(?<=\" +\n",
    "        r\"^\\s*|\" +\n",
    "        r\"(?:\" +\n",
    "        f\"(?:^|{MARKER_VALID})\\s*{DEBUG_PATTERN}*\\s*{ALL_BUT_NEWSEG}\" + r\"{30,}?\" + r\"|\" +\n",
    "        f\"{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*\\s*{ALL_BUT_NEWSEG}\" + r\"{60,}?\" +\n",
    "        f\")\" +\n",
    "        f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*\" +\n",
    "        r\")\" +\n",
    "        r\"([^\" + MARKER_VALID + MARKER_NOISE_START[0] + MARKER_NOISE_END[0] + r\"]{1,90})\"\n",
    "        f\"(?=\" +\n",
    "        r\"\\s*$|\" +\n",
    "        f\"\\s*{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*\\s*\" +\n",
    "        r\"(?:\" +\n",
    "        ALL_BUT_NEWSEG + r\"{30,}?\" + f\"(?:\\s*{DEBUG_PATTERN}*\\s*$|{MARKER_VALID})|\" +\n",
    "        ALL_BUT_NEWSEG + r\"{60,}?\" + MARKER_NOISE_END +\n",
    "        r\")\" +\n",
    "        r\")\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"\n",
    "    )),\n",
    "    \n",
    "    (regex.compile(\n",
    "        f\"({MARKER_VALID}\\s*{DEBUG_PATTERN}*)(\\s*)\" +\n",
    "        f\"(\\s+[{UPPERCASE_LETTERS_OR_NUM}]\" + r\"{1,3}\\s+)\" +\n",
    "        f\"({MARKER_NOISE_START}{ALL_BUT_NEWSEG}*{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*)\"\n",
    "        f\"(?=\\s*{MARKER_VALID}|\\s*$)\",\n",
    "        regex.IGNORECASE,\n",
    "    ),\n",
    "    lambda symb_start, symb_end, deb: (\n",
    "        f\" {symb_start} {deb} \" + r\"\\3\\2\" + f\" {symb_end} {deb} \" + r\"\\4\\1\"\n",
    "    )),\n",
    ")\n",
    "\n",
    "RE_HIGH_PRIORITY_BLOCKS = (\n",
    "    (DetectRecurrentMetadata, #0, Sala das Sessões , em 28 de abril de 2020\n",
    "    lambda symb_start, symb_end, deb: f\" {symb_start} {deb} \" + r\"\\1\" + f\" {symb_end} {deb} \"),\n",
    "    *[\n",
    "        (\n",
    "            regex.compile(f\"(?<={STANDARD_PREFIXES}{PREFIX_EXTENSIONS}?)(?=\\s*{pattern})\", regex.IGNORECASE),\n",
    "            lambda symb, deb: f\" {symb} {deb} \",\n",
    "        )\n",
    "        for pattern in [\n",
    "            r\"Sala\\s*d[ea]s?\\s*(?:sess|comiss|reuni)(?:[õôo\\u0303]+es|[ãa]o)\\s*\" + EOF_OR_DATE,\n",
    "            r\"Senado\\s*Federal\\s*,\\s*\" + EOF_OR_DATE,\n",
    "            r\"C[aâ]mara\\s*dos\\s*Deputados\\s*,\\s*\" + EOF_OR_DATE,\n",
    "            r\"Bras[ií]lia\\s*,\\s*(?:\" + DATE_OR_UNDERSCORES + r\")\\s*\",\n",
    "            r\"(?:Atenciosamente|Respeitosam?ente)\\s*,\",\n",
    "            r\"As?\\s*mesas?\\s*da\\s*c[aâ]mara\\s*dos\\s*deputados\\s*[^:\" + MARKER_VALID + r\"]{,300}?:\",\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "RE_POST_BLOCKS = tuple(\n",
    "    regex.compile(f\"(?<={pattern})\", regex.IGNORECASE)\n",
    "    for pattern in []\n",
    ")\n",
    "COALESCE_NOISE = regex.compile(\n",
    "    f\"{MARKER_NOISE_END}\\s*{DEBUG_PATTERN}*\\s*{MARKER_NOISE_START}\\s*{DEBUG_PATTERN}*\"\n",
    ")\n",
    "\n",
    "def regex_legal_item_anymatch(text: str, debug: bool = False, coalesce_noise: bool = True) -> str:\n",
    "    aid = 0\n",
    "    \n",
    "    for i, (reg, fun) in enumerate(RE_HIGH_PRIORITY_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_HIGH_PTY\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=False)\n",
    "    \n",
    "    for i, reg in enumerate(RE_NOISE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_NOISE\" if debug else \"\"\n",
    "        text = reg.sub(\n",
    "            f\" {MARKER_NOISE_START} {debug_text} \" + r\"\\1\" + f\" {MARKER_NOISE_END} {debug_text} \",\n",
    "            text,\n",
    "            concurrent=False,\n",
    "        )\n",
    "    \n",
    "    for i, (reg, fun, sub_count) in enumerate(RE_SPECIAL, aid):\n",
    "        debug_text = f\"{i}_SPECIAL\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=False, count=sub_count or 0)\n",
    "\n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=False)\n",
    "        \n",
    "    for i, reg in enumerate(RE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POS\" if debug else \"\"\n",
    "        text = reg.sub(f\" {MARKER_VALID} {debug_text} \", text, concurrent=False)\n",
    "        \n",
    "    for i, reg in enumerate(RE_PRE_POST_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_PRE_POS\" if debug else \"\"\n",
    "        text = reg.sub(\n",
    "            f\" {MARKER_VALID} {debug_text} \" + r\"\\1\\2\" + f\" {MARKER_VALID} {debug_text} \",\n",
    "            text,\n",
    "            concurrent=True,\n",
    "        )\n",
    "        \n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    for i, (reg, fun) in enumerate(RE_POST_PROCESSING_BLOCKS, aid):\n",
    "        debug_text = f\"{i}_POST_PROC\" if debug else \"\"\n",
    "        try:\n",
    "            pat = fun(MARKER_VALID, debug_text)\n",
    "            \n",
    "        except TypeError:\n",
    "            pat = fun(MARKER_NOISE_START, MARKER_NOISE_END, debug_text)\n",
    "            \n",
    "        text = reg.sub(pat, text, concurrent=False)\n",
    "        \n",
    "\n",
    "    if coalesce_noise:\n",
    "        text = COALESCE_NOISE.sub(\"\", text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def preprocess_instance(\n",
    "        item, ind, print_preprocessed: bool = False, debug: bool = False, coalesce_noise: bool = True):    \n",
    "    preprocessed_text = seg_model.preprocess_legal_text(item[\"text\"])\n",
    "    preprocessed_text = regex_legal_item_anymatch(preprocessed_text, debug=debug, coalesce_noise=coalesce_noise)\n",
    "    preprocessed_text = preprocessed_text.replace(MARKER_INTENDED_CORRUPTION, \"@\" if debug else \"\")\n",
    "    tokens = nltk.tokenize.word_tokenize(preprocessed_text, language=\"portuguese\")\n",
    "    \n",
    "    if print_preprocessed:\n",
    "        print(colorama.Fore.WHITE, colorama.Style.DIM, preprocessed_text, colorama.Style.RESET_ALL, sep=\"\")\n",
    "    \n",
    "    labels = [0] * len(tokens)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        if tokens[i] in SPECIAL_SYMBOLS:\n",
    "            cur_token = tokens.pop(i)\n",
    "            cur_label = labels.pop(i)\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_START]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_VALID] and cur_token == MARKER_NOISE_END:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i + 1 < len(tokens) and tokens[i + 1] != MARKER_NOISE_END:\n",
    "                    labels[i + 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "                \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_VALID:\n",
    "                labels[i] = SPECIAL_SYMBOLS[MARKER_VALID]\n",
    "                if i > 0 and labels[i - 1] != SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                    labels[i - 1] = SPECIAL_SYMBOLS[MARKER_NOISE_END]\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_START] and cur_token == MARKER_NOISE_END:\n",
    "                # labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            if cur_label == SPECIAL_SYMBOLS[MARKER_NOISE_END] and cur_token == MARKER_NOISE_START:\n",
    "                labels[i] = 0\n",
    "                continue\n",
    "            \n",
    "            labels[i] = SPECIAL_SYMBOLS[cur_token]\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    if labels:\n",
    "        maybe_erase_pool = []\n",
    "        noise_on = False\n",
    "\n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                labels[i] = labels[i + 1] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                maybe_erase_pool.clear()\n",
    "                continue\n",
    "\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                while maybe_erase_pool:\n",
    "                    ind = maybe_erase_pool.pop()\n",
    "                    labels[ind] = 0\n",
    "\n",
    "            if labels[i] > 0:\n",
    "                maybe_erase_pool.append(i)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_START]:\n",
    "                if noise_on:\n",
    "                    labels[i] = 0\n",
    "                else:\n",
    "                    noise_on = True\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END]:\n",
    "                if noise_on:\n",
    "                    noise_on = False\n",
    "                else:\n",
    "                    labels[i] = 0\n",
    "\n",
    "            elif labels[i] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                noise_on = False\n",
    "            \n",
    "        for i in range(len(labels) - 1):\n",
    "            if labels[i] == SPECIAL_SYMBOLS[MARKER_NOISE_END] and labels[i + 1] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "                labels[i] = 0\n",
    "            \n",
    "        while tokens and tokens[0] in SPECIAL_SYMBOLS:\n",
    "            labels.pop(0)\n",
    "            tokens.pop(0)\n",
    "\n",
    "        while tokens and tokens[-1] in SPECIAL_SYMBOLS:\n",
    "            labels.pop()\n",
    "            tokens.pop()\n",
    "        \n",
    "        if labels[0] == SPECIAL_SYMBOLS[MARKER_VALID]:\n",
    "            labels[0] = 0\n",
    "    \n",
    "    ret = {\n",
    "        \"id\": str(ind),\n",
    "        \"labels\": labels,\n",
    "        \"tokens\": tokens,\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "if DEV_RUN:\n",
    "    auxaux = \"\"\"\n",
    "\n",
    "Senhor Presidente , Nos termos do art . 113 , inciso I e §1º , do Regimento Interno da Câmara dos Deputados , requeiro a Vossa Excelência que seja encaminhada ao Poder Executivo a INDICAÇÃO anexa , sugerindo criação do selo ou certificação “ Estabelecimento Clean & Safe ” para empreendimentos turísticos e empresas do setor do turismo . Sala das Sessões , em 28 de abril de 2020 . Deputado PEDRO LUCAS FERNANDES LÍDER DO PTB.\n",
    " \n",
    "kdsfçs\n",
    "\"\"\".replace(\" , \", \", \").replace(\" . \", \". \")\n",
    "    res=preprocess_instance({\"text\": auxaux}, -1, True, debug=True, coalesce_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1511c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:57:42.884539Z",
     "start_time": "2022-03-06T15:55:34.326191Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5b320216a3724f28\n",
      "Reusing dataset csv (../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097832280de14461ba850ba5679cbe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../cache/datasets/csv/default-5b320216a3724f28/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-bb5915d731cb52ba.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c8531d9574215b53dffb176cbb85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44921424c1864e82ada309e32afa8ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=[\"../data/content.txt\"],\n",
    "    header=None,\n",
    "    names=[\"text\"],\n",
    "    cache_dir=\"../cache/datasets\",\n",
    "    skiprows=DATASET_ROW_START if DEV_RUN else None,\n",
    "    nrows=(DATASET_ROW_END - DATASET_ROW_START + 1) if DEV_RUN else None,\n",
    ")\n",
    "\n",
    "RE_JUSTIFICATIVA = regex.compile(\n",
    "    r\"\\s*(?:\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A?\\s*T\\s*I\\s*V\\s*A|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*t\\s*i\\s*v\\s*a\\s+(?=[\" + UPPERCASE_LETTERS + r\"])|\" +\n",
    "    r\"J\\s*U\\s*S\\s*T\\s*I\\s*F\\s*I\\s*C\\s*A\\s*[CÇ]\\s*[AÂÃÀÁ]\\s*O|\" +\n",
    "    r\"J\\s*u\\s*s\\s*t\\s*i\\s*f\\s*i\\s*c\\s*a\\s*[cç]\\s*[aãâàá]\\s*o\\s+(?=[\" + UPPERCASE_LETTERS + r\"])\" +\n",
    "    r\")\"\n",
    ")\n",
    "\n",
    "RE_ANEXO = regex.compile(r\"\\s*A\\s*N\\s*E\\s*X\\s*O\")\n",
    "\n",
    "df = df.filter(lambda item: isinstance(item[\"text\"], str) and 128 <= len(item[\"text\"]) <= 600000)\n",
    "df = df.map(lambda item: {\"text\": RE_JUSTIFICATIVA.split(item[\"text\"])[0]})\n",
    "df = df.map(lambda item: {\"text\": RE_ANEXO.split(item[\"text\"])[0]})\n",
    "\n",
    "df = df.map(preprocess_instance, with_indices=True, num_proc=10, remove_columns=None if DEV_RUN else \"text\")\n",
    "\n",
    "rerun_tests = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e760e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T17:24:45.616588Z",
     "start_time": "2022-03-03T17:24:45.613685Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9df3ef9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T16:22:12.508772Z",
     "start_time": "2022-03-06T16:21:05.560698Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChosen id:\u001b[39m 2660\n",
      "\n",
      "\u001b[37m\u001b[2mREQUERIMENTO\r\n",
      "(Do Sr. Paulo Bengtson)\r\n",
      "Requer o envio de indicação ao Ministério\r\n",
      "do Meio Ambiente, relativa à aplicação de\r\n",
      "recursos  do  Fundo  Amazônia  no\r\n",
      "Município de Trairão, no Estado do Pará.\r\n",
      "Senhor Presidente, \r\n",
      "Nos termos do art. 113, inciso I e § 1º, do Regimento Interno da Câmara\r\n",
      "dos Deputados, requeiro a Vossa Excelência que seja encaminhada ao Poder\r\n",
      "Executivo  a  INDICAÇÃO em anexo,  sugerindo  a  aplicação  de  recursos  do\r\n",
      "Fundo  \r\n",
      "Amazônia no Município de Trairão, no Estado do Pará.\r\n",
      "Sala das sessões, em        de                        de 2020.\r\n",
      "Deputado PAULO BENGTSON\r\n",
      "PTB/PA\r\n",
      "*C\r\n",
      "D2\r\n",
      "07\r\n",
      "92\r\n",
      "65\r\n",
      "96\r\n",
      "30\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r P\r\n",
      "au\r\n",
      "lo\r\n",
      " B\r\n",
      "en\r\n",
      "gt\r\n",
      "so\r\n",
      "n \r\n",
      "(P\r\n",
      "TB\r\n",
      "/P\r\n",
      "A)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "03\r\n",
      "4,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "83\r\n",
      "4/\r\n",
      "20\r\n",
      "20\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 3\r\n",
      "0/\r\n",
      "07\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "14\r\n",
      ":4\r\n",
      "4 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "INDICAÇÃO n.        , de 2020.\r\n",
      "(Do Sr. Paulo Bengtson)\r\n",
      "Sugere  a  aplicação  de  recursos  do\r\n",
      "Fundo Amazônia no Município de Trairão,\r\n",
      "no Estado do Pará.\r\n",
      "Excelentíssimo Senhor Ministro de Estado do Meio Ambiente,\r\n",
      "Cumprimentando-o  cordialmente,  dirijo-me  a  Vossa  Excelência\r\n",
      "para  sugerir  a  aplicação de recursos  do  Fundo Amazônia  no Município  de\r\n",
      "Trairão, no Estado do Pará, pelas razões a seguir apresentadas.\r\n",
      "O Fundo Amazônia, criado por meio do Decreto 6.527, de 2008,\r\n",
      "tem  por  objetivo  a  aplicação  em  ações  de  prevenção,  monitoramento  e\r\n",
      "combate  ao  desmatamento,  além  da  promoção  da  conservação  e  do  uso\r\n",
      "sustentável da Amazônia Legal. \r\n",
      "   Segundo  informações  do  Fundo  Amazônia1,  o  Pará  (segundo\r\n",
      "maior estado brasileiro e mais populoso do bioma Amazônia) registra elevados\r\n",
      "índices  de  desmatamento  da  floresta  amazônica  em  consequência  da\r\n",
      "expansão do extrativismo vegetal, da pecuária e da cultura de soja. \r\n",
      "Dados  do  Instituto  Nacional  de  Pesquisas  Espaciais  –  INPE\r\n",
      "(Plataforma  TerraBrasilis)  sobre  taxas  de  desmatamento  acumulado,\r\n",
      "atualizados em 08/06/2020, mostram que dentre os nove estados que integram\r\n",
      "a  Amazônia  Legal,  o  Estado  do  Pará  ocupa  o  primeiro  lugar  em  taxa  de\r\n",
      "desmatamento (34,16%). \r\n",
      "             Devido aos altos índices de desmatamento, em 2004, o Governo\r\n",
      "lançou  o  Plano  de  ação  para  Prevenção  e  Controle  do  Desmatamento  da\r\n",
      "Amazônia  Legal  (PPCDAm),  responsável  pela  queda de 76% nas taxas de\r\n",
      "desmatamento da região amazônica.\r\n",
      "1 Disponíveis em www.fundoamazonia.gov.br/pt/projeto/Semas-Para/.\r\n",
      "*C\r\n",
      "D2\r\n",
      "07\r\n",
      "92\r\n",
      "65\r\n",
      "96\r\n",
      "30\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r P\r\n",
      "au\r\n",
      "lo\r\n",
      " B\r\n",
      "en\r\n",
      "gt\r\n",
      "so\r\n",
      "n \r\n",
      "(P\r\n",
      "TB\r\n",
      "/P\r\n",
      "A)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "03\r\n",
      "4,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "83\r\n",
      "4/\r\n",
      "20\r\n",
      "20\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 3\r\n",
      "0/\r\n",
      "07\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "14\r\n",
      ":4\r\n",
      "4 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "        Tratando  especificamente  do  Estado  do  Pará,  houve  a\r\n",
      "reestruturação  do  órgão  central  da  política  estadual  de  meio  ambiente\r\n",
      "(Semas/PA), a instituição do Plano de Prevenção, Controle e Alternativas ao\r\n",
      "Desmatamento  do  Estado  do  Pará  (PPCAD-PA),  além  do  lançamento  do\r\n",
      "Programa Municípios Verdes (PMV). \r\n",
      "Com  essas  iniciativas  e  recursos  do  Fundo  Amazônia,  o\r\n",
      "desmatamento no Pará caiu de 8.870km2 em 2004 para 1.741km2 em 2012,\r\n",
      "mantendo baixos índices até 2018,  os quais voltaram a crescer  a  partir  de\r\n",
      "2019, conforme se pode verificar na tabela seguinte: \r\n",
      "Taxa de desmatamento por ano no Estado do Pará\r\n",
      "2004 a 2019(km2)\r\n",
      "Ano Estado do Pará\r\n",
      "2004 8870\r\n",
      "2005 5899\r\n",
      "2006 5659\r\n",
      "2007 5526\r\n",
      "2008 5607\r\n",
      "2009 4281\r\n",
      "2010 3770\r\n",
      "2011 3008\r\n",
      "2012 1741\r\n",
      "2013 2346\r\n",
      "2014 1887\r\n",
      "2015 2153\r\n",
      "2016 2992\r\n",
      "2017 2433\r\n",
      "2018 2744\r\n",
      "2019 4172\r\n",
      "Var. 2019-2018 52%\r\n",
      "Var. 2019-2004 -53%\r\n",
      "Fonte: INPE\r\n",
      "                           Nota: dados atualizados em 15/06/2020.\r\n",
      "         O Estado do Pará, do qual sou representante, era um dos entes\r\n",
      "da federação que vinha recebendo,  ao longo dos anos,  recursos do Fundo\r\n",
      "Amazônia destinados aos municípios, fortalecendo órgãos municipais do meio\r\n",
      "ambiente,  o  que  contribuiu  efetivamente  para  a  queda  nas  taxas  de\r\n",
      "desmatamento. No entanto, com a suspensão dos repasses, o desmatamento\r\n",
      "voltou a crescer, havendo a necessidade de continuação das ações referentes\r\n",
      "à regularização ambiental para que se concretizem os avanços no combate ao\r\n",
      "desmatamento e no uso da terra de forma sustentável. \r\n",
      "*C\r\n",
      "D2\r\n",
      "07\r\n",
      "92\r\n",
      "65\r\n",
      "96\r\n",
      "30\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r P\r\n",
      "au\r\n",
      "lo\r\n",
      " B\r\n",
      "en\r\n",
      "gt\r\n",
      "so\r\n",
      "n \r\n",
      "(P\r\n",
      "TB\r\n",
      "/P\r\n",
      "A)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "03\r\n",
      "4,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "83\r\n",
      "4/\r\n",
      "20\r\n",
      "20\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 3\r\n",
      "0/\r\n",
      "07\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "14\r\n",
      ":4\r\n",
      "4 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "Pelos  motivos  expostos,  sugiro  a  Vossa  Excelência  a  aplicação  de\r\n",
      "recursos do Fundo Amazônia para combate ao desmatamento no Município de\r\n",
      "Trairão, Estado do Pará. \r\n",
      "Certo de poder contar com a compreensão de Vossa Excelência para\r\n",
      "auxiliar  nosso  Estado  no  combate  ao  grave  quadro  de  desmatamento,\r\n",
      "agradeço antecipadamente.\r\n",
      "Sala das Sessões, em         de                        de 2020.\r\n",
      "Deputado PAULO BENGTSON\r\n",
      "PTB/PA\r\n",
      "*C\r\n",
      "D2\r\n",
      "07\r\n",
      "92\r\n",
      "65\r\n",
      "96\r\n",
      "30\r\n",
      "0*\r\n",
      "Do\r\n",
      "cu\r\n",
      "m\r\n",
      "en\r\n",
      "to\r\n",
      " e\r\n",
      "le\r\n",
      "tr\r\n",
      "ôn\r\n",
      "ic\r\n",
      "o \r\n",
      "as\r\n",
      "sin\r\n",
      "ad\r\n",
      "o \r\n",
      "po\r\n",
      "r P\r\n",
      "au\r\n",
      "lo\r\n",
      " B\r\n",
      "en\r\n",
      "gt\r\n",
      "so\r\n",
      "n \r\n",
      "(P\r\n",
      "TB\r\n",
      "/P\r\n",
      "A)\r\n",
      ", a\r\n",
      "tr\r\n",
      "av\r\n",
      "és\r\n",
      " d\r\n",
      "o \r\n",
      "po\r\n",
      "nt\r\n",
      "o \r\n",
      "SD\r\n",
      "R_\r\n",
      "56\r\n",
      "03\r\n",
      "4,\r\n",
      "na\r\n",
      " fo\r\n",
      "rm\r\n",
      "a \r\n",
      "do\r\n",
      " a\r\n",
      "rt\r\n",
      ". 1\r\n",
      "02\r\n",
      ", §\r\n",
      " 1\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "RI\r\n",
      "CD\r\n",
      " c\r\n",
      "/c\r\n",
      " o\r\n",
      " a\r\n",
      "rt\r\n",
      ". 2\r\n",
      "º,\r\n",
      " d\r\n",
      "o \r\n",
      "At\r\n",
      "o\r\n",
      "da\r\n",
      " M\r\n",
      "es\r\n",
      "a \r\n",
      "n.\r\n",
      " 8\r\n",
      "0 \r\n",
      "de\r\n",
      " 2\r\n",
      "01\r\n",
      "6.\r\n",
      "IN\r\n",
      "C \r\n",
      "n.\r\n",
      "83\r\n",
      "4/\r\n",
      "20\r\n",
      "20\r\n",
      "Ap\r\n",
      "re\r\n",
      "se\r\n",
      "nt\r\n",
      "aç\r\n",
      "ão\r\n",
      ": 3\r\n",
      "0/\r\n",
      "07\r\n",
      "/2\r\n",
      "02\r\n",
      "0 \r\n",
      "14\r\n",
      ":4\r\n",
      "4 \r\n",
      "- M\r\n",
      "es\r\n",
      "a\r\n",
      "\n",
      "________________________________________________________________\n",
      "\n",
      "\u001b[0m\u001b[97m 1 \u001b[39m REQUERIMENTO ( Do Sr. Paulo Bengtson )\n",
      "\n",
      "\u001b[97m 2 \u001b[39m Requer o envio de indicação ao Ministério do Meio Ambiente , relativa à aplicação de recursos do Fundo Amazônia no Município de Trairão , no Estado do Pará .\n",
      "\n",
      "\u001b[97m 3 \u001b[39m Senhor Presidente , Nos termos do art . 113 , inciso I e § 1º , do Regimento Interno da Câmara dos Deputados , requeiro a Vossa Excelência que seja encaminhada ao Poder Executivo a INDICAÇÃO em anexo , sugerindo a aplicação de recursos do Fundo Amazônia no Município de Trairão , no Estado do Pará .\n",
      "\n",
      "\u001b[97m 4 \u001b[39m Sala das sessões , em de de 2020 . Deputado PAULO BENGTSON PTB/PA \u001b[31m* C D2 07 92 65 96 30 0 * Do cu m en to e le tr ôn ic o as sin ad o po r P au lo B en gt so n ( P TB /P A ) , a tr av és d o po nt o SD R_ 56 03 4 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 83 4/ 20 20 Ap re se nt aç ão : 3 0/ 07 /2 02 0 14 : 4 4 - M es a\n",
      "\n",
      "\u001b[97m 5 \u001b[39m INDICAÇÃO n. , de 2020 . ( Do Sr. Paulo Bengtson )\n",
      "\n",
      "\u001b[97m 6 \u001b[39m Sugere a aplicação de recursos do Fundo Amazônia no Município de Trairão , no Estado do Pará .\n",
      "\n",
      "\u001b[97m 7 \u001b[39m Excelentíssimo Senhor Ministro de Estado do Meio Ambiente , Cumprimentando-o cordialmente , dirijo-me a Vossa Excelência para sugerir a aplicação de recursos do Fundo Amazônia no Município de Trairão , no Estado do Pará , pelas razões a seguir apresentadas . O Fundo Amazônia , criado por meio do Decreto 6.527 , de 2008 , tem por objetivo a aplicação em ações de prevenção , monitoramento e combate ao desmatamento , além da promoção da conservação e do uso sustentável da Amazônia Legal . Segundo informações do Fundo Amazônia1 , o Pará ( segundo maior estado brasileiro e mais populoso do bioma Amazônia ) registra elevados índices de desmatamento da floresta amazônica em consequência da expansão do extrativismo vegetal , da pecuária e da cultura de soja . Dados do Instituto Nacional de Pesquisas Espaciais – INPE ( Plataforma TerraBrasilis ) sobre taxas de desmatamento acumulado , atualizados em 08/06/2020 , mostram que dentre os nove estados que integram a Amazônia Legal , o Estado do Pará ocupa o primeiro lugar em taxa de desmatamento ( 34,16 % ) . Devido aos altos índices de desmatamento , em 2004 , o Governo lançou o Plano de ação para Prevenção e Controle do Desmatamento da Amazônia Legal ( PPCDAm ) , responsável pela queda de 76 % nas taxas de desmatamento da região amazônica . \u001b[31m1 Disponíveis em www.fundoamazonia.gov.br/pt/projeto/Semas-Para/ . * C D2 07 92 65 96 30 0 * Do cu m en to e le tr ôn ic o as sin ad o po r P au lo B en gt so n ( P TB /P A ) , a tr av és d o po nt o SD R_ 56 03 4 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 83 4/ 20 20 Ap re se nt aç ão : 3 0/ 07 /2 02 0 14 : 4 4 - M es a \u001b[39mTratando especificamente do Estado do Pará , houve a reestruturação do órgão central da política estadual de meio ambiente ( Semas/PA ) , a instituição do Plano de Prevenção , Controle e Alternativas ao Desmatamento do Estado do Pará ( PPCAD-PA ) , além do lançamento do Programa Municípios Verdes ( PMV ) . Com essas iniciativas e recursos do Fundo Amazônia , o desmatamento no Pará caiu de 8.870km2 em 2004 para 1.741km2 em 2012 , mantendo baixos índices até 2018 , os quais voltaram a crescer a partir de 2019 , conforme se pode verificar na tabela seguinte : Taxa de desmatamento por ano no Estado do Pará 2004 a 2019 ( km2 ) Ano Estado do Pará \u001b[31m2004 8870 2005 5899 2006 5659 2007 5526 2008 5607 2009 4281 2010 3770 2011 3008 2012 1741 2013 2346 2014 1887 2015 2153 2016 2992 2017 2433 2018 2744 2019 4172 Var . 2019-2018 52 % Var . 2019-2004 \u001b[39m-53 % Fonte : INPE Nota : dados atualizados em 15/06/2020 . O Estado do Pará , do qual sou representante , era um dos entes da federação que vinha recebendo , ao longo dos anos , recursos do Fundo Amazônia destinados aos municípios , fortalecendo órgãos municipais do meio ambiente , o que contribuiu efetivamente para a queda nas taxas de desmatamento . No entanto , com a suspensão dos repasses , o desmatamento voltou a crescer , havendo a necessidade de continuação das ações referentes à regularização ambiental para que se concretizem os avanços no combate ao desmatamento e no uso da terra de forma sustentável . \u001b[31m* C D2 07 92 65 96 30 0 * Do cu m en to e le tr ôn ic o as sin ad o po r P au lo B en gt so n ( P TB /P A ) , a tr av és d o po nt o SD R_ 56 03 4 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 83 4/ 20 20 Ap re se nt aç ão : 3 0/ 07 /2 02 0 14 : 4 4 - M es a \u001b[39mPelos motivos expostos , sugiro a Vossa Excelência a aplicação de recursos do Fundo Amazônia para combate ao desmatamento no Município de Trairão , Estado do Pará . Certo de poder contar com a compreensão de Vossa Excelência para auxiliar nosso Estado no combate ao grave quadro de desmatamento , agradeço antecipadamente .\n",
      "\n",
      "\u001b[97m 8 \u001b[39m Sala das Sessões , em de de 2020 . Deputado PAULO BENGTSON PTB/PA \u001b[31m* C D2 07 92 65 96 30 0 * Do cu m en to e le tr ôn ic o as sin ad o po r P au lo B en gt so n ( P TB /P A ) , a tr av és d o po nt o SD R_ 56 03 4 , na fo rm a do a rt . 1 02 , § 1 º , d o RI CD c /c o a rt . 2 º , d o At o da M es a n . 8 0 de 2 01 6 . IN C n . 83 4/ 20 20 Ap re se nt aç ão : 3 0/ 07 /2 02 0 14 : 4 4 - M es a\n",
      "\n",
      "\u001b[39m\n",
      "Idx/Segment count, noise count:   2660: 8, 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it correct? [y/N]: y\n",
      "Added to test cases.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    # \n",
    "    id_ = None\n",
    "    \n",
    "    if id_ is not None:\n",
    "        print(tests.TEST_CASES[id_])\n",
    "        tests.print_results(df, id_, print_full_text=True)\n",
    "#         tests.update_test_case(id_, (9, 1))\n",
    "        assert False\n",
    "    \n",
    "    if rerun_tests:\n",
    "        try:\n",
    "            tests.run_tests(df[\"train\"][\"labels\"])\n",
    "            rerun_tests = False\n",
    "\n",
    "        except AssertionError as e:\n",
    "            raise AssertionError from e\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    document_idx = min(204, df[\"train\"].num_rows - 1)\n",
    "    while tests.test_case_exists(document_idx):\n",
    "        document_idx = random.randint(0, df[\"train\"].num_rows)\n",
    "\n",
    "    print(colorama.Fore.YELLOW + \"Chosen id:\" + colorama.Fore.RESET, document_idx, end=\"\\n\\n\")\n",
    "\n",
    "    expected_test_case_values = tests.print_results(df, document_idx, print_full_text=True)\n",
    "    print(\"Is it correct? [y/N]:\", end=\" \")\n",
    "    inp = input()\n",
    "    if inp == \"y\":\n",
    "        tests.update_test_case(document_idx, expected_test_case_values)\n",
    "        print(\"Added to test cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61c5d24a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T16:22:16.598248Z",
     "start_time": "2022-03-06T16:22:16.581041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 81 test cases at './test_cases/110001_120000_registered_test_cases.csv'.\n"
     ]
    }
   ],
   "source": [
    "if DEV_RUN:\n",
    "    tests.dump_registered_cases(test_cases_uri=TEST_CASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:58:27.781802Z",
     "start_time": "2022-02-18T17:58:25.830858Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T21:04:02.703423Z",
     "start_time": "2022-02-18T21:03:51.852099Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # source: https://huggingface.co/docs/transformers/custom_datasets#preprocess\n",
    "    tokenized_inputs = seg_model.tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "df_tokenized = df.map(tokenize_and_align_labels, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:20.163644Z",
     "start_time": "2022-02-15T15:08:20.100565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_train_eval_test = df_tokenized[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=16)\n",
    "df_tokenized_test_eval = df_tokenized_train_eval_test[\"test\"].train_test_split(test_size=0.5, shuffle=False)\n",
    "df_tokenized_split = datasets.DatasetDict({\n",
    "    \"train\": df_tokenized_train_eval_test[\"train\"],\n",
    "    \"eval\": df_tokenized_test_eval[\"train\"],\n",
    "    \"test\": df_tokenized_test_eval[\"test\"],\n",
    "})\n",
    "# df_tokenized_split.save_to_disk(\"../data/df_tokenized_split\")\n",
    "df_tokenized_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec224ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:08:35.091656Z",
     "start_time": "2022-02-15T15:08:35.086936Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tokenized_split[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fedbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T17:49:04.888153Z",
     "start_time": "2022-02-18T17:49:04.814886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"train\"][\"labels\"][49])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
